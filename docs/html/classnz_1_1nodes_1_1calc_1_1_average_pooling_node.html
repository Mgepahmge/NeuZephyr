<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.12.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NeuZephyr: nz::nodes::calc::AveragePoolingNode Class Reference</title>
<link rel="icon" href="NZ_logo2.png" type="image/x-icon" />
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="NZ_logo2.png"/></td>
  <td id="projectalign">
   <div id="projectname">NeuZephyr
   </div>
   <div id="projectbrief">Simple DL Framework</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.12.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>Class&#160;List</span></a></li>
      <li><a href="classes.html"><span>Class&#160;Index</span></a></li>
      <li><a href="inherits.html"><span>Class&#160;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&#160;Members</span></a></li>
    </ul>
  </div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){ initResizable(false); });
/* @license-end */
</script>
<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>nz</b></li><li class="navelem"><a class="el" href="namespacenz_1_1nodes.html">nodes</a></li><li class="navelem"><a class="el" href="namespacenz_1_1nodes_1_1calc.html">calc</a></li><li class="navelem"><a class="el" href="classnz_1_1nodes_1_1calc_1_1_average_pooling_node.html">AveragePoolingNode</a></li>  </ul>
</div>
</div><!-- top -->
<div id="doc-content">
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classnz_1_1nodes_1_1calc_1_1_average_pooling_node-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">nz::nodes::calc::AveragePoolingNode Class Reference</div></div>
</div><!--header-->
<div class="contents">

<p>Implements average pooling operation for spatial downsampling in neural networks.  
 <a href="#details">More...</a></p>
<div class="dynheader">
Inheritance diagram for nz::nodes::calc::AveragePoolingNode:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1nodes_1_1calc_1_1_average_pooling_node__inherit__graph.png" border="0" usemap="#anz_1_1nodes_1_1calc_1_1_average_pooling_node_inherit__map" alt="Inheritance graph"/></div>
<map name="anz_1_1nodes_1_1calc_1_1_average_pooling_node_inherit__map" id="anz_1_1nodes_1_1calc_1_1_average_pooling_node_inherit__map">
<area shape="rect" title="Implements average pooling operation for spatial downsampling in neural networks." alt="" coords="5,80,172,123"/>
<area shape="rect" href="classnz_1_1nodes_1_1_node.html" title="Base class for nodes in a neural network or computational graph." alt="" coords="30,5,147,32"/>
<area shape="poly" title=" " alt="" coords="91,48,91,80,86,80,86,48"/>
</map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for nz::nodes::calc::AveragePoolingNode:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1nodes_1_1calc_1_1_average_pooling_node__coll__graph.png" border="0" usemap="#anz_1_1nodes_1_1calc_1_1_average_pooling_node_coll__map" alt="Collaboration graph"/></div>
<map name="anz_1_1nodes_1_1calc_1_1_average_pooling_node_coll__map" id="anz_1_1nodes_1_1calc_1_1_average_pooling_node_coll__map">
<area shape="rect" title="Implements average pooling operation for spatial downsampling in neural networks." alt="" coords="5,80,172,123"/>
<area shape="rect" href="classnz_1_1nodes_1_1_node.html" title="Base class for nodes in a neural network or computational graph." alt="" coords="30,5,147,32"/>
<area shape="poly" title=" " alt="" coords="91,48,91,80,86,80,86,48"/>
</map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:add1055d87bda108863a4c3bf8dca5055" id="r_add1055d87bda108863a4c3bf8dca5055"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#add1055d87bda108863a4c3bf8dca5055">AveragePoolingNode</a> (<a class="el" href="classnz_1_1nodes_1_1_node.html">Node</a> *input, Tensor::size_type poolSize, Tensor::size_type stride, Tensor::size_type padding)</td></tr>
<tr class="memdesc:add1055d87bda108863a4c3bf8dca5055"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructs an <a class="el" href="classnz_1_1nodes_1_1calc_1_1_average_pooling_node.html" title="Implements average pooling operation for spatial downsampling in neural networks.">AveragePoolingNode</a> object.  <br /></td></tr>
<tr class="separator:add1055d87bda108863a4c3bf8dca5055"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab206cec144b3b88af4a90c0eb0f5733c" id="r_ab206cec144b3b88af4a90c0eb0f5733c"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ab206cec144b3b88af4a90c0eb0f5733c">forward</a> () override</td></tr>
<tr class="memdesc:ab206cec144b3b88af4a90c0eb0f5733c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs the backward pass of the average pooling operation.  <br /></td></tr>
<tr class="separator:ab206cec144b3b88af4a90c0eb0f5733c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a12dcec668190c3f466f5bd5e0b3f96a7" id="r_a12dcec668190c3f466f5bd5e0b3f96a7"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a12dcec668190c3f466f5bd5e0b3f96a7">backward</a> () override</td></tr>
<tr class="memdesc:a12dcec668190c3f466f5bd5e0b3f96a7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs the backward pass of the average pooling operation.  <br /></td></tr>
<tr class="separator:a12dcec668190c3f466f5bd5e0b3f96a7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classnz_1_1nodes_1_1_node"><td colspan="2" onclick="javascript:dynsection.toggleInherit('pub_methods_classnz_1_1nodes_1_1_node')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classnz_1_1nodes_1_1_node.html">nz::nodes::Node</a></td></tr>
<tr class="memitem:a687ee9c34eb61f8f28caa201ca42696e inherit pub_methods_classnz_1_1nodes_1_1_node" id="r_a687ee9c34eb61f8f28caa201ca42696e"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnz_1_1nodes_1_1_node.html#a687ee9c34eb61f8f28caa201ca42696e">print</a> (std::ostream &amp;os) const</td></tr>
<tr class="memdesc:a687ee9c34eb61f8f28caa201ca42696e inherit pub_methods_classnz_1_1nodes_1_1_node"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prints the type, data, and gradient of the node.  <br /></td></tr>
<tr class="separator:a687ee9c34eb61f8f28caa201ca42696e inherit pub_methods_classnz_1_1nodes_1_1_node"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9b85913e12422bb4ac2fff483427bb47 inherit pub_methods_classnz_1_1nodes_1_1_node" id="r_a9b85913e12422bb4ac2fff483427bb47"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnz_1_1nodes_1_1_node.html#a9b85913e12422bb4ac2fff483427bb47">dataInject</a> (Tensor::value_type *data, bool grad=false) const</td></tr>
<tr class="memdesc:a9b85913e12422bb4ac2fff483427bb47 inherit pub_methods_classnz_1_1nodes_1_1_node"><td class="mdescLeft">&#160;</td><td class="mdescRight">Injects data into a relevant tensor object, optionally setting its gradient requirement.  <br /></td></tr>
<tr class="separator:a9b85913e12422bb4ac2fff483427bb47 inherit pub_methods_classnz_1_1nodes_1_1_node"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a609f1730085dd1d31e0ddcbbae48a065 inherit pub_methods_classnz_1_1nodes_1_1_node" id="r_a609f1730085dd1d31e0ddcbbae48a065"><td class="memTemplParams" colspan="2">template&lt;typename Iterator &gt; </td></tr>
<tr class="memitem:a609f1730085dd1d31e0ddcbbae48a065 inherit pub_methods_classnz_1_1nodes_1_1_node"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classnz_1_1nodes_1_1_node.html#a609f1730085dd1d31e0ddcbbae48a065">dataInject</a> (Iterator begin, Iterator end, const bool grad=false) const</td></tr>
<tr class="memdesc:a609f1730085dd1d31e0ddcbbae48a065 inherit pub_methods_classnz_1_1nodes_1_1_node"><td class="mdescLeft">&#160;</td><td class="mdescRight">Injects data from an iterator range into the output tensor of the InputNode, optionally setting its gradient requirement.  <br /></td></tr>
<tr class="separator:a609f1730085dd1d31e0ddcbbae48a065 inherit pub_methods_classnz_1_1nodes_1_1_node"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af8b4bab3271df92ca1f0914f7a97b1e8 inherit pub_methods_classnz_1_1nodes_1_1_node" id="r_af8b4bab3271df92ca1f0914f7a97b1e8"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnz_1_1nodes_1_1_node.html#af8b4bab3271df92ca1f0914f7a97b1e8">dataInject</a> (const std::initializer_list&lt; Tensor::value_type &gt; &amp;data, bool grad=false) const</td></tr>
<tr class="memdesc:af8b4bab3271df92ca1f0914f7a97b1e8 inherit pub_methods_classnz_1_1nodes_1_1_node"><td class="mdescLeft">&#160;</td><td class="mdescRight">Injects data from a std::initializer_list into the output tensor of the <a class="el" href="classnz_1_1nodes_1_1_node.html" title="Base class for nodes in a neural network or computational graph.">Node</a>, optionally setting its gradient requirement.  <br /></td></tr>
<tr class="separator:af8b4bab3271df92ca1f0914f7a97b1e8 inherit pub_methods_classnz_1_1nodes_1_1_node"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Implements average pooling operation for spatial downsampling in neural networks. </p>
<p>This node performs spatial averaging over sliding windows of (poolSize x poolSize) dimensions, reducing feature map resolution while maintaining channel depth. Commonly used for dimensionality reduction and translation invariance in CNNs.</p>
<p>Core functionality and characteristics:</p><ul>
<li><b>Spatial Aggregation</b>: Computes mean values over local receptive fields.</li>
<li><b>Dimensionality Reduction</b>: Reduces H and W dimensions while preserving channel count.</li>
<li><b>Gradient Propagation</b>: Distributes gradients equally across input positions during backward pass.</li>
<li><b>Parameter Control</b>: Configurable window size, stride, and padding.</li>
<li><b>CUDA Acceleration</b>: GPU-optimized implementation for both forward and backward passes.</li>
<li><b>Auto Shape Calculation</b>: Computes output dimensions using pooling parameters.</li>
</ul>
<p>Key implementation aspects:</p><ul>
<li><b>Forward Pass</b>: Applies sliding window averaging with optional zero-padding.</li>
<li><b>Backward Pass</b>: Scatters gradients by assigning 1/(K*K) of output gradient to each input position.</li>
<li><b>Border Handling</b>: Supports padding for controlling output size.</li>
<li><b>Memory Efficiency</b>: Maintains original channel depth for memory layout consistency.</li>
</ul>
<p>Typical use cases:</p><ul>
<li>Reducing computational complexity in deep networks.</li>
<li>Creating translation-invariant feature representations.</li>
<li>Smoothing feature responses in encoder-decoder architectures.</li>
<li>Regularization through spatial information compression.</li>
</ul>
<p>Critical considerations:</p><ul>
<li><b>Information Loss</b>: Over-aggressive pooling may discard important spatial details.</li>
<li><b>Dimension Calculation</b>: Output dimensions follow: Hout = (H + 2*padding - poolSize)/stride + 1</li>
<li><b>Parameter Validation</b>: Requires (H + 2*padding) ≥ poolSize and similar for width.</li>
<li><b>Zero Padding Impact</b>: Padding values affect border region averages.</li>
</ul>
<dl class="section warning"><dt>Warning</dt><dd><ul>
<li>Excessive pooling sizes may produce invalid dimensions.</li>
<li>Small stride values can significantly increase computation cost.</li>
<li>Non-integer output dimensions will cause runtime errors.</li>
</ul>
</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>Output tensor shape: (N, C, Hout, Wout)</li>
<li>For variable height/width pooling, use separate parameters (not supported in current implementation)</li>
<li>Gradient computation requires storing input shape during forward pass</li>
</ul>
</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnz_1_1nodes_1_1calc_1_1_max_pooling_node.html" title="Implements max pooling operation for spatial downsampling with feature preservation.">MaxPoolingNode</a> For maximum value-based pooling alternative</dd></dl>
<h3><a class="anchor" id="autotoc_md109"></a>
Usage Example:</h3>
<div class="fragment"><div class="line"><span class="comment">// Create input node with batch of 16 256x256 RGB images</span></div>
<div class="line">InputNode input({16, 3, 256, 256}, <span class="keyword">true</span>);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Configure 4x4 pooling with stride 2 and padding 1</span></div>
<div class="line"><a class="code hl_class" href="classnz_1_1nodes_1_1calc_1_1_average_pooling_node.html">AveragePoolingNode</a> pool(&amp;input, 4, 2, 1);</div>
<div class="line">pool.forward();</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Output shape becomes (16, 3, 128, 128)</span></div>
<div class="line">std::cout &lt;&lt; <span class="stringliteral">&quot;Pooled shape: &quot;</span> &lt;&lt; pool.output-&gt;shape() &lt;&lt; std::endl;</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Backpropagate through pooling operation</span></div>
<div class="line">pool.backward();</div>
<div class="ttc" id="aclassnz_1_1nodes_1_1calc_1_1_average_pooling_node_html"><div class="ttname"><a href="classnz_1_1nodes_1_1calc_1_1_average_pooling_node.html">nz::nodes::calc::AveragePoolingNode</a></div><div class="ttdoc">Implements average pooling operation for spatial downsampling in neural networks.</div><div class="ttdef"><b>Definition</b> <a href="_nodes_8cuh_source.html#l04088">Nodes.cuh:4088</a></div></div>
</div><!-- fragment --><dl class="section author"><dt>Author</dt><dd>Mgepahmge (<a href="https://github.com/Mgepahmge">https://github.com/Mgepahmge</a>)</dd></dl>
<dl class="section date"><dt>Date</dt><dd>2023/10/19 </dd></dl>

<p class="definition">Definition at line <a class="el" href="_nodes_8cuh_source.html#l04088">4088</a> of file <a class="el" href="_nodes_8cuh_source.html">Nodes.cuh</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="add1055d87bda108863a4c3bf8dca5055" name="add1055d87bda108863a4c3bf8dca5055"></a>
<h2 class="memtitle"><span class="permalink"><a href="#add1055d87bda108863a4c3bf8dca5055">&#9670;&#160;</a></span>AveragePoolingNode()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">nz::nodes::calc::AveragePoolingNode::AveragePoolingNode </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnz_1_1nodes_1_1_node.html">Node</a> *</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor::size_type</td>          <td class="paramname"><span class="paramname"><em>poolSize</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor::size_type</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor::size_type</td>          <td class="paramname"><span class="paramname"><em>padding</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Constructs an <a class="el" href="classnz_1_1nodes_1_1calc_1_1_average_pooling_node.html" title="Implements average pooling operation for spatial downsampling in neural networks.">AveragePoolingNode</a> object. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A pointer to the input node. The memory of this pointer is assumed to be managed externally and is used in a read - only manner within this constructor (host - to - host). </td></tr>
    <tr><td class="paramname">poolSize</td><td>The size of the pooling window. It is a value of type Tensor::size_type and is used to determine the dimensions of the pooling operation. </td></tr>
    <tr><td class="paramname">stride</td><td>The stride value for the pooling operation. It is of type Tensor::size_type and controls how the pooling window moves across the input tensor. </td></tr>
    <tr><td class="paramname">padding</td><td>The padding value applied to the input tensor before the pooling operation. It is of type Tensor::size_type.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None</dd></dl>
<p>This constructor initializes an <a class="el" href="classnz_1_1nodes_1_1calc_1_1_average_pooling_node.html" title="Implements average pooling operation for spatial downsampling in neural networks.">AveragePoolingNode</a> object. It first stores the provided input node pointer in the <code>inputs</code> vector. Then, it creates a new shared pointer to a Tensor object for the <code>output</code> member. The shape of the output tensor is calculated based on the shape of the input tensor, the <code>poolSize</code>, <code>stride</code>, and <code>padding</code> values using the <code>OUTPUT_DIM</code> macro. The <code>requiresGrad</code> flag of the output tensor is set to the same value as that of the input tensor's output. Finally, it sets the <code>type</code> member of the node to "AveragePooling".</p>
<p>Memory management strategy: The constructor does not allocate memory for the input node. It only stores a pointer to it. The output tensor is created using <code>std::make_shared</code>, which manages the memory automatically. Exception handling mechanism: There is no explicit exception handling in this constructor. If the <code>std::make_shared</code> call fails to allocate memory for the output tensor, it may throw a <code>std::bad_alloc</code> exception.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::bad_alloc</td><td>If memory allocation for the output tensor fails.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>Ensure that the input node pointer is valid and points to a properly initialized node.</li>
<li>The performance of this constructor is mainly determined by the memory allocation for the output tensor, which has a time complexity of O(1) for the pointer management and O(m) for the tensor data allocation, where m is the number of elements in the output tensor.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1nodes_1_1_node.html">Node</a>* inputNode = <span class="keyword">new</span> <a class="code hl_class" href="classnz_1_1nodes_1_1_node.html">Node</a>(...);</div>
<div class="line">Tensor::size_type poolSize = 2;</div>
<div class="line">Tensor::size_type stride = 2;</div>
<div class="line">Tensor::size_type padding = 0;</div>
<div class="line"><a class="code hl_class" href="classnz_1_1nodes_1_1calc_1_1_average_pooling_node.html">AveragePoolingNode</a> avgPoolingNode(inputNode, poolSize, stride, padding);</div>
<div class="line">```</div>
<div class="ttc" id="aclassnz_1_1nodes_1_1_node_html"><div class="ttname"><a href="classnz_1_1nodes_1_1_node.html">nz::nodes::Node</a></div><div class="ttdoc">Base class for nodes in a neural network or computational graph.</div><div class="ttdef"><b>Definition</b> <a href="_nodes_8cuh_source.html#l00114">Nodes.cuh:114</a></div></div>
</div><!-- fragment --><dl class="section author"><dt>Author</dt><dd>Mgepahmge(<a href="https://github.com/Mgepahmge">https://github.com/Mgepahmge</a>)</dd></dl>
<dl class="section date"><dt>Date</dt><dd>2024/07/15 </dd></dl>

<p class="definition">Definition at line <a class="el" href="_nodes_8cu_source.html#l00667">667</a> of file <a class="el" href="_nodes_8cu_source.html">Nodes.cu</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a12dcec668190c3f466f5bd5e0b3f96a7" name="a12dcec668190c3f466f5bd5e0b3f96a7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a12dcec668190c3f466f5bd5e0b3f96a7">&#9670;&#160;</a></span>backward()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void nz::nodes::calc::AveragePoolingNode::backward </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs the backward pass of the average pooling operation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">None</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None</dd></dl>
<p>This function conducts the backward pass of the average pooling operation. It first checks if the output tensor of the input node requires gradient computation. If it does, the function calls <code>iAveragePoolingBackward</code>, passing the gradient tensor of the input node's output, the gradient tensor of the output, the pooling size, stride, padding, and the dimensions of the input and output tensors. The <code>iAveragePoolingBackward</code> function computes the gradients and propagates them back to the input.</p>
<p>Memory management strategy: This function does not allocate or deallocate any memory directly. It operates on the existing gradient tensors of the input and output. Exception handling mechanism: There is no explicit exception handling in this function. If the <code>iAveragePoolingBackward</code> function encounters an error, it may throw an exception, and the specific type of exception depends on the implementation of <code>iAveragePoolingBackward</code>.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">[Exception</td><td>type from iAveragePoolingBackward] If the <code>iAveragePoolingBackward</code> function encounters an error during execution.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>Ensure that the gradient tensors of the input node's output and the output tensor of the <a class="el" href="classnz_1_1nodes_1_1calc_1_1_average_pooling_node.html" title="Implements average pooling operation for spatial downsampling in neural networks.">AveragePoolingNode</a> are properly initialized before calling this function.</li>
<li>The performance of this function depends on the implementation of the <code>iAveragePoolingBackward</code> function. If the <code>iAveragePoolingBackward</code> function has a time complexity of O(n), where n is the number of elements in the input or output gradient tensors, then this backward pass also has a time complexity of O(n).</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1nodes_1_1calc_1_1_average_pooling_node.html">AveragePoolingNode</a> avgPoolingNode(...); <span class="comment">// Assume AveragePoolingNode is properly initialized</span></div>
<div class="line">avgPoolingNode.backward();</div>
<div class="line">```</div>
</div><!-- fragment --><dl class="section author"><dt>Author</dt><dd>Mgepahmge(<a href="https://github.com/Mgepahmge">https://github.com/Mgepahmge</a>)</dd></dl>
<dl class="section date"><dt>Date</dt><dd>2024/07/15 </dd></dl>

<p>Implements <a class="el" href="classnz_1_1nodes_1_1_node.html#a0a9ecbaa3d790ba38e8218aca7837fd0">nz::nodes::Node</a>.</p>

<p class="definition">Definition at line <a class="el" href="_nodes_8cu_source.html#l00684">684</a> of file <a class="el" href="_nodes_8cu_source.html">Nodes.cu</a>.</p>

</div>
</div>
<a id="ab206cec144b3b88af4a90c0eb0f5733c" name="ab206cec144b3b88af4a90c0eb0f5733c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab206cec144b3b88af4a90c0eb0f5733c">&#9670;&#160;</a></span>forward()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void nz::nodes::calc::AveragePoolingNode::forward </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs the backward pass of the average pooling operation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">None</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None</dd></dl>
<p>This function conducts the backward pass of the average pooling operation. It first checks if the output tensor of the input node requires gradient computation. If it does, the function calls <code>iAveragePoolingBackward</code>, passing the gradient tensor of the input node's output, the gradient tensor of the output, the pooling size, stride, padding, and the dimensions of the input and output tensors. The <code>iAveragePoolingBackward</code> function computes the gradients and propagates them back to the input.</p>
<p>Memory management strategy: This function does not allocate or deallocate any memory directly. It operates on the existing gradient tensors of the input and output. Exception handling mechanism: There is no explicit exception handling in this function. If the <code>iAveragePoolingBackward</code> function encounters an error, it may throw an exception, and the specific type of exception depends on the implementation of <code>iAveragePoolingBackward</code>.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">[Exception</td><td>type from iAveragePoolingBackward] If the <code>iAveragePoolingBackward</code> function encounters an error during execution.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>Ensure that the gradient tensors of the input node's output and the output tensor of the <a class="el" href="classnz_1_1nodes_1_1calc_1_1_average_pooling_node.html" title="Implements average pooling operation for spatial downsampling in neural networks.">AveragePoolingNode</a> are properly initialized before calling this function.</li>
<li>The performance of this function depends on the implementation of the <code>iAveragePoolingBackward</code> function. If the <code>iAveragePoolingBackward</code> function has a time complexity of O(n), where n is the number of elements in the input or output gradient tensors, then this backward pass also has a time complexity of O(n).</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1nodes_1_1calc_1_1_average_pooling_node.html">AveragePoolingNode</a> avgPoolingNode(...); <span class="comment">// Assume AveragePoolingNode is properly initialized</span></div>
<div class="line">avgPoolingNode.backward();</div>
<div class="line">```</div>
</div><!-- fragment --><dl class="section author"><dt>Author</dt><dd>Mgepahmge(<a href="https://github.com/Mgepahmge">https://github.com/Mgepahmge</a>)</dd></dl>
<dl class="section date"><dt>Date</dt><dd>2024/07/15 </dd></dl>

<p>Implements <a class="el" href="classnz_1_1nodes_1_1_node.html#a8a828c2e91a4aa2a9ab7b94554e4685b">nz::nodes::Node</a>.</p>

<p class="definition">Definition at line <a class="el" href="_nodes_8cu_source.html#l00678">678</a> of file <a class="el" href="_nodes_8cu_source.html">Nodes.cu</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>D:/Users/Mgepahmge/Documents/C Program/NeuZephyr/include/NeuZephyr/<a class="el" href="_nodes_8cuh_source.html">Nodes.cuh</a></li>
<li>D:/Users/Mgepahmge/Documents/C Program/NeuZephyr/src/<a class="el" href="_nodes_8cu_source.html">Nodes.cu</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.12.0
</small></address>
</div><!-- doc-content -->
</body>
</html>
