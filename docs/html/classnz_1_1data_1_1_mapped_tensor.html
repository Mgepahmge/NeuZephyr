<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.12.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NeuZephyr: nz::data::MappedTensor Class Reference</title>
<link rel="icon" href="NZ_logo2.png" type="image/x-icon" />
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="NZ_logo2.png"/></td>
  <td id="projectalign">
   <div id="projectname">NeuZephyr
   </div>
   <div id="projectbrief">Simple DL Framework</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.12.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>Class&#160;List</span></a></li>
      <li><a href="classes.html"><span>Class&#160;Index</span></a></li>
      <li><a href="inherits.html"><span>Class&#160;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&#160;Members</span></a></li>
    </ul>
  </div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){ initResizable(false); });
/* @license-end */
</script>
<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>nz</b></li><li class="navelem"><a class="el" href="namespacenz_1_1data.html">data</a></li><li class="navelem"><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a></li>  </ul>
</div>
</div><!-- top -->
<div id="doc-content">
<div class="header">
  <div class="summary">
<a href="#friends">Friends</a> &#124;
<a href="classnz_1_1data_1_1_mapped_tensor-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">nz::data::MappedTensor Class Reference</div></div>
</div><!--header-->
<div class="contents">

<p>A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible container-like interfaces.  
 <a href="#details">More...</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr><td colspan="2"><div class="groupHeader">Constructors and Destructors</div></td></tr>
<tr class="memitem:a8534e7ba30e0eaab0921ebb9632c5fbd" id="r_a8534e7ba30e0eaab0921ebb9632c5fbd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a8534e7ba30e0eaab0921ebb9632c5fbd">MappedTensor</a> (const <a class="el" href="classnz_1_1data_1_1_dimension.html">shape_type</a> &amp;<a class="el" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, bool requires_grad=false)</td></tr>
<tr class="memdesc:a8534e7ba30e0eaab0921ebb9632c5fbd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructs a <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object.  <br /></td></tr>
<tr class="separator:a8534e7ba30e0eaab0921ebb9632c5fbd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a54475a46dfd208a2ee8c1e403535abc8" id="r_a54475a46dfd208a2ee8c1e403535abc8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a54475a46dfd208a2ee8c1e403535abc8">MappedTensor</a> ()</td></tr>
<tr class="memdesc:a54475a46dfd208a2ee8c1e403535abc8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructs a default <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object.  <br /></td></tr>
<tr class="separator:a54475a46dfd208a2ee8c1e403535abc8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a83cc3f2c2b973e10cea67c234761241d" id="r_a83cc3f2c2b973e10cea67c234761241d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a83cc3f2c2b973e10cea67c234761241d">MappedTensor</a> (const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;other)</td></tr>
<tr class="memdesc:a83cc3f2c2b973e10cea67c234761241d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Copy constructor for the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> class.  <br /></td></tr>
<tr class="separator:a83cc3f2c2b973e10cea67c234761241d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2bff8300e61805bbb3e480417aab3ae8" id="r_a2bff8300e61805bbb3e480417aab3ae8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a2bff8300e61805bbb3e480417aab3ae8">MappedTensor</a> (<a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;&amp;other) noexcept</td></tr>
<tr class="memdesc:a2bff8300e61805bbb3e480417aab3ae8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Move constructor for the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> class.  <br /></td></tr>
<tr class="separator:a2bff8300e61805bbb3e480417aab3ae8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf2087390e5524c8ff6790bd94c78e90" id="r_aaf2087390e5524c8ff6790bd94c78e90"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aaf2087390e5524c8ff6790bd94c78e90">operator=</a> (const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;other)</td></tr>
<tr class="memdesc:aaf2087390e5524c8ff6790bd94c78e90"><td class="mdescLeft">&#160;</td><td class="mdescRight">Copy assignment operator for the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> class.  <br /></td></tr>
<tr class="separator:aaf2087390e5524c8ff6790bd94c78e90"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa3658f80db10a7715aa45d871ef49cdd" id="r_aa3658f80db10a7715aa45d871ef49cdd"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aa3658f80db10a7715aa45d871ef49cdd">operator=</a> (<a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;&amp;other) noexcept(false)</td></tr>
<tr class="memdesc:aa3658f80db10a7715aa45d871ef49cdd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Move assignment operator for the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> class.  <br /></td></tr>
<tr class="separator:aa3658f80db10a7715aa45d871ef49cdd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aee0ad19fbaa29f4a89e99f21bdd4cdf0" id="r_aee0ad19fbaa29f4a89e99f21bdd4cdf0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aee0ad19fbaa29f4a89e99f21bdd4cdf0">~MappedTensor</a> () noexcept(false)</td></tr>
<tr class="memdesc:aee0ad19fbaa29f4a89e99f21bdd4cdf0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destructor for the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> class.  <br /></td></tr>
<tr class="separator:aee0ad19fbaa29f4a89e99f21bdd4cdf0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr><td colspan="2"><div class="groupHeader">Getters and Setters</div></td></tr>
<tr class="memitem:ad76dcba2cd22c53b8c4815da113dcb56" id="r_ad76dcba2cd22c53b8c4815da113dcb56"><td class="memItemLeft" align="right" valign="top">iterator&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ad76dcba2cd22c53b8c4815da113dcb56">begin</a> () const</td></tr>
<tr class="memdesc:ad76dcba2cd22c53b8c4815da113dcb56"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns an iterator pointing to the first element of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.  <br /></td></tr>
<tr class="separator:ad76dcba2cd22c53b8c4815da113dcb56"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac01f432f0ef9b7279630b5b35bc609e0" id="r_ac01f432f0ef9b7279630b5b35bc609e0"><td class="memItemLeft" align="right" valign="top">iterator&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ac01f432f0ef9b7279630b5b35bc609e0">end</a> () const</td></tr>
<tr class="memdesc:ac01f432f0ef9b7279630b5b35bc609e0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns an iterator pointing to the past - the - end element of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.  <br /></td></tr>
<tr class="separator:ac01f432f0ef9b7279630b5b35bc609e0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad9c451d7aa04362e84e0d68d42a8867a" id="r_ad9c451d7aa04362e84e0d68d42a8867a"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ad9c451d7aa04362e84e0d68d42a8867a">requiresGrad</a> () const noexcept</td></tr>
<tr class="memdesc:ad9c451d7aa04362e84e0d68d42a8867a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Checks whether the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> requires gradient computation.  <br /></td></tr>
<tr class="separator:ad9c451d7aa04362e84e0d68d42a8867a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad72562ee8cad3196dc9ffbdd436f74a3" id="r_ad72562ee8cad3196dc9ffbdd436f74a3"><td class="memItemLeft" align="right" valign="top">value_type *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ad72562ee8cad3196dc9ffbdd436f74a3">data</a> () const noexcept</td></tr>
<tr class="memdesc:ad72562ee8cad3196dc9ffbdd436f74a3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Retrieves a pointer to the underlying data array of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.  <br /></td></tr>
<tr class="separator:ad72562ee8cad3196dc9ffbdd436f74a3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa144f9f3b76741e5d3fb3b5df3cc3b42" id="r_aa144f9f3b76741e5d3fb3b5df3cc3b42"><td class="memItemLeft" align="right" valign="top">size_type&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aa144f9f3b76741e5d3fb3b5df3cc3b42">size</a> () const noexcept</td></tr>
<tr class="memdesc:aa144f9f3b76741e5d3fb3b5df3cc3b42"><td class="mdescLeft">&#160;</td><td class="mdescRight">Retrieves the total number of elements in the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.  <br /></td></tr>
<tr class="separator:aa144f9f3b76741e5d3fb3b5df3cc3b42"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf8ddc60a224bc676dd0fad40ad2f43b" id="r_abf8ddc60a224bc676dd0fad40ad2f43b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classnz_1_1data_1_1_dimension.html">shape_type</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> () const noexcept</td></tr>
<tr class="memdesc:abf8ddc60a224bc676dd0fad40ad2f43b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Retrieves the shape of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.  <br /></td></tr>
<tr class="separator:abf8ddc60a224bc676dd0fad40ad2f43b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add503096ece511cc5b44f75271ff424d" id="r_add503096ece511cc5b44f75271ff424d"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#add503096ece511cc5b44f75271ff424d">setRequiresGrad</a> (bool requires_grad)</td></tr>
<tr class="memdesc:add503096ece511cc5b44f75271ff424d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the gradient requirement flag for the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> and manages the associated gradient memory accordingly.  <br /></td></tr>
<tr class="separator:add503096ece511cc5b44f75271ff424d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aefb5c705fc6d224469978cf64ca37e0b" id="r_aefb5c705fc6d224469978cf64ca37e0b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aefb5c705fc6d224469978cf64ca37e0b">setShape</a> (const <a class="el" href="classnz_1_1data_1_1_dimension.html">shape_type</a> &amp;<a class="el" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>)</td></tr>
<tr class="memdesc:aefb5c705fc6d224469978cf64ca37e0b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets a new shape for the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> and adjusts its data and gradient memory accordingly.  <br /></td></tr>
<tr class="separator:aefb5c705fc6d224469978cf64ca37e0b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a34906f06e918a40089db7a8936ee1608" id="r_a34906f06e918a40089db7a8936ee1608"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a34906f06e918a40089db7a8936ee1608">dataInject</a> (float *<a class="el" href="#ad72562ee8cad3196dc9ffbdd436f74a3">data</a>, size_type <a class="el" href="#aa144f9f3b76741e5d3fb3b5df3cc3b42">size</a>, bool isGrad=false) const</td></tr>
<tr class="memdesc:a34906f06e918a40089db7a8936ee1608"><td class="mdescLeft">&#160;</td><td class="mdescRight">Inject data into either the tensor's main data or its gradient.  <br /></td></tr>
<tr class="separator:a34906f06e918a40089db7a8936ee1608"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7f5550020dbf34ae87f208c22a73e28d" id="r_a7f5550020dbf34ae87f208c22a73e28d"><td class="memTemplParams" colspan="2">template&lt;typename Iterator &gt; </td></tr>
<tr class="memitem:a7f5550020dbf34ae87f208c22a73e28d"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="#a7f5550020dbf34ae87f208c22a73e28d">dataInject</a> (Iterator <a class="el" href="#ad76dcba2cd22c53b8c4815da113dcb56">begin</a>, Iterator <a class="el" href="#ac01f432f0ef9b7279630b5b35bc609e0">end</a>, const bool isGrad=false) const</td></tr>
<tr class="memdesc:a7f5550020dbf34ae87f208c22a73e28d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Inject data from an iterator range into either the tensor's data or its gradient.  <br /></td></tr>
<tr class="separator:a7f5550020dbf34ae87f208c22a73e28d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adbbf1cda4d9806c93ad30316ce507630" id="r_adbbf1cda4d9806c93ad30316ce507630"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#adbbf1cda4d9806c93ad30316ce507630">dataInject</a> (const std::initializer_list&lt; value_type &gt; &amp;<a class="el" href="#ad72562ee8cad3196dc9ffbdd436f74a3">data</a>, const bool isGrad=false) const</td></tr>
<tr class="memdesc:adbbf1cda4d9806c93ad30316ce507630"><td class="mdescLeft">&#160;</td><td class="mdescRight">Inject data from a std::initializer_list into either the tensor's data or its gradient.  <br /></td></tr>
<tr class="separator:adbbf1cda4d9806c93ad30316ce507630"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abb30df1c0174d5a8d9fa8911f7b3d3bc" id="r_abb30df1c0174d5a8d9fa8911f7b3d3bc"><td class="memItemLeft" align="right" valign="top">auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#abb30df1c0174d5a8d9fa8911f7b3d3bc">operator[]</a> (size_type index) const -&gt; value_type &amp;</td></tr>
<tr class="memdesc:abb30df1c0174d5a8d9fa8911f7b3d3bc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Overload the [] operator to access an element of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> by index.  <br /></td></tr>
<tr class="separator:abb30df1c0174d5a8d9fa8911f7b3d3bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr><td colspan="2"><div class="groupHeader">Printer</div></td></tr>
<tr class="memitem:a8a42265d7c9f964c41ff43e9d8dc7bf7" id="r_a8a42265d7c9f964c41ff43e9d8dc7bf7"><td class="memItemLeft" align="right" valign="top">std::ostream &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a8a42265d7c9f964c41ff43e9d8dc7bf7">print</a> (std::ostream &amp;os) const</td></tr>
<tr class="memdesc:a8a42265d7c9f964c41ff43e9d8dc7bf7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Print the tensor data in a matrix-like format to an output stream.  <br /></td></tr>
<tr class="separator:a8a42265d7c9f964c41ff43e9d8dc7bf7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab54e80ac0d2ec90442b0a674004cfdbc" id="r_ab54e80ac0d2ec90442b0a674004cfdbc"><td class="memItemLeft" align="right" valign="top">std::ostream &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ab54e80ac0d2ec90442b0a674004cfdbc">printGrad</a> (std::ostream &amp;os) const</td></tr>
<tr class="memdesc:ab54e80ac0d2ec90442b0a674004cfdbc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Print the gradient of the tensor in a matrix-like format to an output stream.  <br /></td></tr>
<tr class="separator:ab54e80ac0d2ec90442b0a674004cfdbc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr><td colspan="2"><div class="groupHeader">Modifiers</div></td></tr>
<tr class="memitem:a0b348f12004c0b5eeb46f8f1d4b0bf53" id="r_a0b348f12004c0b5eeb46f8f1d4b0bf53"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a0b348f12004c0b5eeb46f8f1d4b0bf53">clear</a> () const</td></tr>
<tr class="memdesc:a0b348f12004c0b5eeb46f8f1d4b0bf53"><td class="mdescLeft">&#160;</td><td class="mdescRight">Clear the data stored in the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> by setting all elements to zero.  <br /></td></tr>
<tr class="separator:a0b348f12004c0b5eeb46f8f1d4b0bf53"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8ced8f419ebc96c0a1b58e7d271aaa0a" id="r_a8ced8f419ebc96c0a1b58e7d271aaa0a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a8ced8f419ebc96c0a1b58e7d271aaa0a">clearGrad</a> () const</td></tr>
<tr class="memdesc:a8ced8f419ebc96c0a1b58e7d271aaa0a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Clear the gradient data of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> if it requires gradients.  <br /></td></tr>
<tr class="separator:a8ced8f419ebc96c0a1b58e7d271aaa0a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a54d785fecf6466bd442989545ead6de4" id="r_a54d785fecf6466bd442989545ead6de4"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a54d785fecf6466bd442989545ead6de4">reshape</a> (const <a class="el" href="classnz_1_1data_1_1_dimension.html">shape_type</a> &amp;<a class="el" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>)</td></tr>
<tr class="memdesc:a54d785fecf6466bd442989545ead6de4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Reshape the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> to a new shape.  <br /></td></tr>
<tr class="separator:a54d785fecf6466bd442989545ead6de4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0150ae0b7137a617c598d1f71d69ce1a" id="r_a0150ae0b7137a617c598d1f71d69ce1a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a0150ae0b7137a617c598d1f71d69ce1a">randomize</a> (size_type seed=0, bool isGrad=false) const</td></tr>
<tr class="memdesc:a0150ae0b7137a617c598d1f71d69ce1a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Randomize the data or gradients of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> using a given seed.  <br /></td></tr>
<tr class="separator:a0150ae0b7137a617c598d1f71d69ce1a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acf793cf0d23af29076d18cd46a6d19cf" id="r_acf793cf0d23af29076d18cd46a6d19cf"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#acf793cf0d23af29076d18cd46a6d19cf">fill</a> (value_type value, bool isGrad=false) const</td></tr>
<tr class="memdesc:acf793cf0d23af29076d18cd46a6d19cf"><td class="mdescLeft">&#160;</td><td class="mdescRight">Fill the data or gradients of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> with a given value.  <br /></td></tr>
<tr class="separator:acf793cf0d23af29076d18cd46a6d19cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afae0e7076636cd708762f57f10f03952" id="r_afae0e7076636cd708762f57f10f03952"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#afae0e7076636cd708762f57f10f03952">transpose</a> ()</td></tr>
<tr class="memdesc:afae0e7076636cd708762f57f10f03952"><td class="mdescLeft">&#160;</td><td class="mdescRight">Transpose the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> and its gradients (if required).  <br /></td></tr>
<tr class="separator:afae0e7076636cd708762f57f10f03952"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr><td colspan="2"><div class="groupHeader">Math</div></td></tr>
<tr class="memitem:a42529629ec686811b950f50b84cffd62" id="r_a42529629ec686811b950f50b84cffd62"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a42529629ec686811b950f50b84cffd62">operator+</a> (const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;other) const</td></tr>
<tr class="memdesc:a42529629ec686811b950f50b84cffd62"><td class="mdescLeft">&#160;</td><td class="mdescRight">Perform element-wise addition between two MappedTensors.  <br /></td></tr>
<tr class="separator:a42529629ec686811b950f50b84cffd62"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1346540c19b9ab6f416514cd2164c8b" id="r_ab1346540c19b9ab6f416514cd2164c8b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ab1346540c19b9ab6f416514cd2164c8b">operator-</a> (const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;other) const</td></tr>
<tr class="memdesc:ab1346540c19b9ab6f416514cd2164c8b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Perform element-wise subtraction between two MappedTensors.  <br /></td></tr>
<tr class="separator:ab1346540c19b9ab6f416514cd2164c8b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7a6bc3862735542300e7f3ecd2df887f" id="r_a7a6bc3862735542300e7f3ecd2df887f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a7a6bc3862735542300e7f3ecd2df887f">operator*</a> (const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;other) const</td></tr>
<tr class="memdesc:a7a6bc3862735542300e7f3ecd2df887f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Perform matrix multiplication between two MappedTensors.  <br /></td></tr>
<tr class="separator:a7a6bc3862735542300e7f3ecd2df887f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeb5887e43ba46f43ab2ed5ed78a62de1" id="r_aeb5887e43ba46f43ab2ed5ed78a62de1"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aeb5887e43ba46f43ab2ed5ed78a62de1">operator-</a> () const</td></tr>
<tr class="memdesc:aeb5887e43ba46f43ab2ed5ed78a62de1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Perform element-wise negation on the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.  <br /></td></tr>
<tr class="separator:aeb5887e43ba46f43ab2ed5ed78a62de1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a79064970ec839800d23d8fc890e0d1f9" id="r_a79064970ec839800d23d8fc890e0d1f9"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a79064970ec839800d23d8fc890e0d1f9">operator==</a> (const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;other) const</td></tr>
<tr class="memdesc:a79064970ec839800d23d8fc890e0d1f9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Checks if two <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> objects are equal.  <br /></td></tr>
<tr class="separator:a79064970ec839800d23d8fc890e0d1f9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a96696ca7de5d5d3b7e0ba834a80d541d" id="r_a96696ca7de5d5d3b7e0ba834a80d541d"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a96696ca7de5d5d3b7e0ba834a80d541d">operator!=</a> (const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;other) const</td></tr>
<tr class="memdesc:a96696ca7de5d5d3b7e0ba834a80d541d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Checks if two <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> objects are not equal.  <br /></td></tr>
<tr class="separator:a96696ca7de5d5d3b7e0ba834a80d541d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a51ecfec4ea055d7e4c11c4540c3fd996" id="r_a51ecfec4ea055d7e4c11c4540c3fd996"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a51ecfec4ea055d7e4c11c4540c3fd996">operator/</a> (const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;other) const</td></tr>
<tr class="memdesc:a51ecfec4ea055d7e4c11c4540c3fd996"><td class="mdescLeft">&#160;</td><td class="mdescRight">Perform element-wise division between two MappedTensors.  <br /></td></tr>
<tr class="separator:a51ecfec4ea055d7e4c11c4540c3fd996"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a33ec3056e0ae0d2088aa83a7f31f6cec" id="r_a33ec3056e0ae0d2088aa83a7f31f6cec"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a33ec3056e0ae0d2088aa83a7f31f6cec">recip</a> ()</td></tr>
<tr class="memdesc:a33ec3056e0ae0d2088aa83a7f31f6cec"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute the reciprocal of each element in the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.  <br /></td></tr>
<tr class="separator:a33ec3056e0ae0d2088aa83a7f31f6cec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afabf30bc35435f1101a61afa77b026ad" id="r_afabf30bc35435f1101a61afa77b026ad"><td class="memItemLeft" align="right" valign="top">value_type&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#afabf30bc35435f1101a61afa77b026ad">sum</a> () const</td></tr>
<tr class="memdesc:afabf30bc35435f1101a61afa77b026ad"><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculate the sum of all elements in the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.  <br /></td></tr>
<tr class="separator:afabf30bc35435f1101a61afa77b026ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a75956c8f5cfc2ea1e7e7efe90e13c9c2" id="r_a75956c8f5cfc2ea1e7e7efe90e13c9c2"><td class="memItemLeft" align="right" valign="top">value_type&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a75956c8f5cfc2ea1e7e7efe90e13c9c2">sum</a> (size_t batch, size_t channel) const</td></tr>
<tr class="memdesc:a75956c8f5cfc2ea1e7e7efe90e13c9c2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculate the sum of elements in a specific batch and channel of a <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.  <br /></td></tr>
<tr class="separator:a75956c8f5cfc2ea1e7e7efe90e13c9c2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad4b349b1cbc2fef18f4b450f4d11377a" id="r_ad4b349b1cbc2fef18f4b450f4d11377a"><td class="memItemLeft" align="right" valign="top">value_type&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ad4b349b1cbc2fef18f4b450f4d11377a">expSum</a> () const</td></tr>
<tr class="memdesc:ad4b349b1cbc2fef18f4b450f4d11377a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculate the sum of the exponential values of all elements in the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.  <br /></td></tr>
<tr class="separator:ad4b349b1cbc2fef18f4b450f4d11377a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af9d1b0fa71f9bb7686cc26ae7b32be8d" id="r_af9d1b0fa71f9bb7686cc26ae7b32be8d"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af9d1b0fa71f9bb7686cc26ae7b32be8d">syncGrad</a> () const</td></tr>
<tr class="memdesc:af9d1b0fa71f9bb7686cc26ae7b32be8d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Synchronizes the gradient data if gradient computation is required.  <br /></td></tr>
<tr class="separator:af9d1b0fa71f9bb7686cc26ae7b32be8d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae133d08d4505a30c6bd34e4a7a311f9e" id="r_ae133d08d4505a30c6bd34e4a7a311f9e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ae133d08d4505a30c6bd34e4a7a311f9e">syncData</a> () const</td></tr>
<tr class="memdesc:ae133d08d4505a30c6bd34e4a7a311f9e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Synchronizes the tensor data by waiting for all CUDA stream write operations on it to finish.  <br /></td></tr>
<tr class="separator:ae133d08d4505a30c6bd34e4a7a311f9e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5134b8821da18631dd9a9b9417b0ba5e" id="r_a5134b8821da18631dd9a9b9417b0ba5e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a5134b8821da18631dd9a9b9417b0ba5e">sync</a> () const</td></tr>
<tr class="memdesc:a5134b8821da18631dd9a9b9417b0ba5e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Synchronizes the tensor data and its gradient.  <br /></td></tr>
<tr class="separator:a5134b8821da18631dd9a9b9417b0ba5e"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="friends" name="friends"></a>
Friends</h2></td></tr>
<tr class="memitem:a1cd02ca3d7e7592ba6658b333ff207b4" id="r_a1cd02ca3d7e7592ba6658b333ff207b4"><td class="memItemLeft" align="right" valign="top">DL_API std::ostream &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a1cd02ca3d7e7592ba6658b333ff207b4">operator&lt;&lt;</a> (std::ostream &amp;os, const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;tensor)</td></tr>
<tr class="memdesc:a1cd02ca3d7e7592ba6658b333ff207b4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Overload the &lt;&lt; operator to print a <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object to an output stream.  <br /></td></tr>
<tr class="separator:a1cd02ca3d7e7592ba6658b333ff207b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abaacd16c39a6f16fde32336c7696c94f" id="r_abaacd16c39a6f16fde32336c7696c94f"><td class="memItemLeft" align="right" valign="top">DL_API std::istream &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#abaacd16c39a6f16fde32336c7696c94f">operator&gt;&gt;</a> (std::istream &amp;is, <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;tensor)</td></tr>
<tr class="memdesc:abaacd16c39a6f16fde32336c7696c94f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Overload the &gt;&gt; operator to read data from an input stream into a <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object.  <br /></td></tr>
<tr class="separator:abaacd16c39a6f16fde32336c7696c94f"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible container-like interfaces. </p>
<p>The <code><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a></code> class offers similar functionality to the <code><a class="el" href="classnz_1_1data_1_1_tensor.html" title="A class for representing and manipulating multidimensional arrays (tensors) in GPU memory.">Tensor</a></code> class but with data stored in pinned zero-copy memory. This design enables direct host/device memory access patterns and container-style operations at the cost of reduced computational performance compared to regular GPU memory.</p>
<h3><a class="anchor" id="autotoc_md41"></a>
Type Definitions:</h3>
<ul>
<li><code>size_type</code>: Alias for <code>unsigned long long</code>, supports 64-bit indexing for large tensors.</li>
<li><code>value_type</code>: Alias for <code>float</code>, consistent with standard numerical computation types.</li>
<li><code>shape_type</code>: Alias for <code>std::vector&lt;int&gt;</code>, represents tensor dimensions (e.g., <code>{256, 256}</code> for an image tensor).</li>
<li><code>iterator</code>: Alias for <code>value_type*</code>, provides STL-style iterator access to tensor elements.</li>
</ul>
<h3><a class="anchor" id="autotoc_md42"></a>
Key Differentiators from Tensor:</h3>
<ul>
<li><b>Zero-Copy Memory</b>: Utilizes CUDA pinned memory accessible by both host and device without explicit transfers</li>
<li><b>Host-Side Interoperability</b>: Supports STL-style iterators, range-based loops, and direct data access like <code>std::vector</code></li>
<li><b>Container Compatibility</b>: Works seamlessly with standard algorithms (<code>std::copy</code>, <code>std::transform</code>, etc.)</li>
<li><b>Performance Tradeoff</b>: Optimized for accessibility over speed, suitable for IO-bound operations</li>
</ul>
<h3><a class="anchor" id="autotoc_md43"></a>
Recommended Use Cases:</h3>
<ul>
<li>Frequent host-device data exchange scenarios</li>
<li>Prototyping with direct host-side data manipulation</li>
<li>Situations requiring container semantics with GPU data</li>
</ul>
<h3><a class="anchor" id="autotoc_md44"></a>
Usage Example:</h3>
<div class="fragment"><div class="line"><span class="keyword">using namespace </span><a class="code hl_namespace" href="namespacenz_1_1data.html">nz::data</a>;</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Create mapped tensor with 3x3 shape</span></div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> mtensor({3, 3});</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Host-accessible modification via iterators</span></div>
<div class="line">std::fill(mtensor.begin(), mtensor.end(), 1.0f);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Direct host-side data processing</span></div>
<div class="line"><span class="keywordflow">for</span>(<span class="keyword">auto</span>&amp; val : mtensor) {</div>
<div class="line">    val = std::sqrt(val);</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Seamless GPU computation</span></div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_tensor.html">Tensor</a> result = <a class="code hl_function" href="namespacenz_1_1data.html#a9bcee9a75db3d824b92ed17a59711428">ReLU</a>(mtensor);  <span class="comment">// Works with existing Tensor operations</span></div>
<div class="ttc" id="aclassnz_1_1data_1_1_mapped_tensor_html"><div class="ttname"><a href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a></div><div class="ttdoc">A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...</div><div class="ttdef"><b>Definition</b> <a href="_mapped_tensor_8cuh_source.html#l00066">MappedTensor.cuh:66</a></div></div>
<div class="ttc" id="aclassnz_1_1data_1_1_tensor_html"><div class="ttname"><a href="classnz_1_1data_1_1_tensor.html">nz::data::Tensor</a></div><div class="ttdoc">A class for representing and manipulating multidimensional arrays (tensors) in GPU memory.</div><div class="ttdef"><b>Definition</b> <a href="_tensor_8cuh_source.html#l00134">Tensor.cuh:134</a></div></div>
<div class="ttc" id="anamespacenz_1_1data_html"><div class="ttname"><a href="namespacenz_1_1data.html">nz::data</a></div><div class="ttdoc">Contains data structures and utilities for tensor operations in machine learning workflows.</div><div class="ttdef"><b>Definition</b> <a href="_dimension_8cuh_source.html#l00009">Dimension.cuh:9</a></div></div>
<div class="ttc" id="anamespacenz_1_1data_html_a9bcee9a75db3d824b92ed17a59711428"><div class="ttname"><a href="namespacenz_1_1data.html#a9bcee9a75db3d824b92ed17a59711428">nz::data::ReLU</a></div><div class="ttdeci">T ReLU(T input)</div><div class="ttdoc">Apply the Rectified Linear Unit (ReLU) activation function element-wise to an input tensor.</div><div class="ttdef"><b>Definition</b> <a href="_tensor_operations_8cuh_source.html#l00047">TensorOperations.cuh:47</a></div></div>
</div><!-- fragment --><dl class="section note"><dt>Note</dt><dd><ul>
<li><b>Memory Characteristics</b>: Zero-copy memory typically offers higher allocation latency but unified access</li>
<li><b>Concurrency Considerations</b>: Ensure proper synchronization between host/device accesses</li>
<li><b>Performance Guidance</b>: Prefer <a class="el" href="classnz_1_1data_1_1_tensor.html" title="A class for representing and manipulating multidimensional arrays (tensors) in GPU memory.">Tensor</a> for compute-intensive kernels, use <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> for data pipelines</li>
<li><b>Lifecycle Management</b>: Pinned memory requires careful resource management - prefer RAII patterns</li>
</ul>
</dd></dl>
<dl class="section author"><dt>Author</dt><dd>Mgepahmge(<a href="https://github.com/Mgepahmge">https://github.com/Mgepahmge</a>)</dd></dl>
<dl class="section date"><dt>Date</dt><dd>2024/11/29 </dd></dl>

<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cuh_source.html#l00066">66</a> of file <a class="el" href="_mapped_tensor_8cuh_source.html">MappedTensor.cuh</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a8534e7ba30e0eaab0921ebb9632c5fbd" name="a8534e7ba30e0eaab0921ebb9632c5fbd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8534e7ba30e0eaab0921ebb9632c5fbd">&#9670;&#160;</a></span>MappedTensor() <span class="overload">[1/4]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">nz::data::MappedTensor::MappedTensor </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classnz_1_1data_1_1_dimension.html">shape_type</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>shape</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>requires_grad</em></span><span class="paramdefsep"> = </span><span class="paramdefval">false</span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">explicit</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Constructs a <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">shape</td><td>The shape of the tensor. This is a reference (host-to-host) to the shape_type object which defines the dimensions of the tensor. </td></tr>
    <tr><td class="paramname">requires_grad</td><td>A boolean value indicating whether the tensor requires gradient computation.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None (constructor).</dd></dl>
<p>This constructor initializes the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object with the given shape and gradient requirement. It calculates the size of the tensor based on the provided shape. Memory for the data buffer is allocated using <code>cudaMallocHost</code>. If the <code>requires_grad</code> flag is set to <code>true</code>, memory for the gradient buffer is also allocated using <code>cudaMallocHost</code>. If <code>requires_grad</code> is <code>false</code>, the gradient buffer pointer is set to <code>nullptr</code>. The memory allocated by <code>cudaMallocHost</code> should be freed by the corresponding <code>cudaFreeHost</code> call when it is no longer needed. There is no explicit exception handling in this constructor, but the <code>CHECK</code> macro is assumed to handle errors related to CUDA memory allocation. This constructor is a fundamental part of the <code><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a></code> class and is used to initialize new tensor objects.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The <code>CHECK</code> macro is assumed to handle CUDA errors properly. Ensure that the CUDA environment is properly configured before using this constructor.</li>
</ul>
</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd><ul>
<li>CUDA memory allocation may fail if there is not enough available memory on the host. Ensure that the host system has sufficient memory before creating a <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">true</span>);</div>
<div class="line">```</div>
<div class="ttc" id="aclassnz_1_1data_1_1_dimension_html"><div class="ttname"><a href="classnz_1_1data_1_1_dimension.html">nz::data::Dimension</a></div><div class="ttdoc">Represents a multi - dimensional shape, typically used in deep learning for tensor dimensions.</div><div class="ttdef"><b>Definition</b> <a href="_dimension_8cuh_source.html#l00057">Dimension.cuh:57</a></div></div>
<div class="ttc" id="aclassnz_1_1data_1_1_mapped_tensor_html_abf8ddc60a224bc676dd0fad40ad2f43b"><div class="ttname"><a href="#abf8ddc60a224bc676dd0fad40ad2f43b">nz::data::MappedTensor::shape</a></div><div class="ttdeci">shape_type shape() const noexcept</div><div class="ttdoc">Retrieves the shape of the MappedTensor.</div><div class="ttdef"><b>Definition</b> <a href="_mapped_tensor_8cu_source.html#l00210">MappedTensor.cu:210</a></div></div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00088">88</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>

</div>
</div>
<a id="a54475a46dfd208a2ee8c1e403535abc8" name="a54475a46dfd208a2ee8c1e403535abc8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a54475a46dfd208a2ee8c1e403535abc8">&#9670;&#160;</a></span>MappedTensor() <span class="overload">[2/4]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">nz::data::MappedTensor::MappedTensor </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Constructs a default <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">None</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None (constructor).</dd></dl>
<p>This default constructor initializes the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object by delegating to the parameterized constructor with a shape of {0, 0} and a <code>requires_grad</code> value of <code>false</code>. After the delegation, it explicitly sets the <code>_data</code> and <code>_grad</code> pointers to <code>nullptr</code>. The memory management strategy relies on the parameterized constructor's behavior. Since the shape is {0, 0}, it's likely that no actual memory will be allocated for data and gradient in this case. There is no explicit exception - handling in this constructor, but it depends on the error - handling of the parameterized constructor (presumably through the <code>CHECK</code> macro). This constructor provides a way to create a default - initialized <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>Ensure that the parameterized constructor is implemented correctly as this constructor depends on it.</li>
<li>Since the <code>_data</code> and <code>_grad</code> pointers are set to <code>nullptr</code>, this object may not be suitable for direct use without re - initializing.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor;</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00100">100</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>

</div>
</div>
<a id="a83cc3f2c2b973e10cea67c234761241d" name="a83cc3f2c2b973e10cea67c234761241d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a83cc3f2c2b973e10cea67c234761241d">&#9670;&#160;</a></span>MappedTensor() <span class="overload">[3/4]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">nz::data::MappedTensor::MappedTensor </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>other</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Copy constructor for the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> class. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">other</td><td>A constant reference (host-to-host) to another <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object from which the data and properties will be copied.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None (constructor).</dd></dl>
<p>This copy constructor initializes a new <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object by delegating to the parameterized constructor with the shape and gradient requirement of the <code>other</code> <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It then copies the data from the <code>other</code> object to the newly created object using <code>cudaMemcpy</code>. If the <code>requires_grad</code> flag is set to <code>true</code>, it also copies the gradient data. The memory for the new object is already allocated by the delegated constructor. The <code>cudaMemcpy</code> operations are used to transfer data between device memory locations. There is no explicit exception handling in this constructor, but the <code>CHECK</code> macro is assumed to handle errors related to CUDA memory copy operations. This constructor is important for creating a deep copy of a <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The <code>CHECK</code> macro is assumed to handle CUDA errors properly. Ensure that the CUDA environment is properly configured before using this copy constructor.</li>
<li>The <code>cudaMemcpy</code> operations may fail if there is not enough available memory or if the memory pointers are invalid.</li>
</ul>
</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd><ul>
<li>CUDA memory copy operations may be time - consuming, especially for large tensors. Be aware of the performance implications when using this copy constructor.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> original(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">true</span>);</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> copy(original);</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00105">105</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_a83cc3f2c2b973e10cea67c234761241d_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_a83cc3f2c2b973e10cea67c234761241d_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_a83cc3f2c2b973e10cea67c234761241d_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_a83cc3f2c2b973e10cea67c234761241d_cgraph">
<area shape="rect" title="Copy constructor for the MappedTensor class." alt="" coords="5,39,167,81"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="215,5,400,48"/>
<area shape="poly" title=" " alt="" coords="166,45,199,40,200,46,167,51"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#afa38d5c6db0e6b48c8f74ce8ad0df2bc" title="Asynchronously copies data between CUDA device and host memory based on the specified memory copy kin..." alt="" coords="215,72,400,115"/>
<area shape="poly" title=" " alt="" coords="167,69,200,74,199,80,166,75"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a1de1cf3aadea137faf90a2f9b4b7abe2" title="Acquires CUDA stream from pool using round&#45;robin scheduling." alt="" coords="448,39,633,81"/>
<area shape="poly" title=" " alt="" coords="400,77,432,73,433,78,401,83"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#adb1078a67c6e38932d7d58c2adb05ec0" title="Synchronizes CUDA stream execution until data writes complete." alt="" coords="448,105,633,148"/>
<area shape="poly" title=" " alt="" coords="401,104,433,109,432,114,400,109"/>
</map>
</div>

</div>
</div>
<a id="a2bff8300e61805bbb3e480417aab3ae8" name="a2bff8300e61805bbb3e480417aab3ae8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2bff8300e61805bbb3e480417aab3ae8">&#9670;&#160;</a></span>MappedTensor() <span class="overload">[4/4]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">nz::data::MappedTensor::MappedTensor </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;&amp;</td>          <td class="paramname"><span class="paramname"><em>other</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Move constructor for the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> class. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">other</td><td>An rvalue reference (host-to-host) to a <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object from which resources will be moved.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None (constructor).</dd></dl>
<p>This move constructor transfers ownership of the resources (such as the data and gradient buffers) from the <code>other</code> <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object to the newly constructed object. It copies the shape, size, and <code>requires_grad</code> flag from the <code>other</code> object. Then, it takes over the pointers to the data and gradient buffers, leaving the <code>other</code> object in a valid but empty state. The <code>other</code> object's data and gradient pointers are set to <code>nullptr</code>, its size is set to 0, <code>requires_grad</code> is set to <code>false</code>, and the shape is set to <code>{0, 0}</code>. This operation is noexcept, meaning it does not throw exceptions. The memory management strategy is that the ownership of the previously allocated memory by the <code>other</code> object is transferred, and no new memory is allocated in this constructor. There is no need for explicit exception handling as the operation is guaranteed not to throw. This constructor is useful for efficient resource transfer during operations like returning a <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object from a function.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>After the move operation, the <code>other</code> object should not be used as it is left in a valid but empty state.</li>
<li>This move constructor ensures efficient resource utilization by avoiding unnecessary memory copying.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> original(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">true</span>);</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> moved(std::move(original));</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00114">114</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>

</div>
</div>
<a id="aee0ad19fbaa29f4a89e99f21bdd4cdf0" name="aee0ad19fbaa29f4a89e99f21bdd4cdf0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aee0ad19fbaa29f4a89e99f21bdd4cdf0">&#9670;&#160;</a></span>~MappedTensor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">nz::data::MappedTensor::~MappedTensor </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Destructor for the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> class. </p>
<p>This destructor is responsible for releasing the host memory allocated for the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object.</p>
<ul>
<li>First, it checks if the <code>_requires_grad</code> flag is set to <code>true</code> and the <code>_grad</code> pointer is not <code>nullptr</code>. If so, it uses <code>cudaFreeHost</code> to free the host memory associated with the gradient data. The <code>CHECK</code> macro is assumed to handle any CUDA errors that may occur during this operation.</li>
<li>Then, it checks if the <code>_data</code> pointer is not <code>nullptr</code>. If true, it uses <code>cudaFreeHost</code> to free the host memory associated with the tensor data, again relying on the <code>CHECK</code> macro to handle potential CUDA errors.</li>
</ul>
<p>The memory management strategy of this destructor ensures that any host memory allocated by the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object is properly freed when the object goes out of scope, preventing memory leaks. There is no explicit exception handling in the destructor itself, but the <code>CHECK</code> macro is assumed to manage CUDA - related errors.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The <code>CHECK</code> macro is assumed to handle CUDA errors properly. Ensure that the CUDA environment is properly configured before the destructor is called.</li>
<li>The destructor is automatically called when the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object goes out of scope or is explicitly deleted.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line">{</div>
<div class="line">    <a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line">    <a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">true</span>);</div>
<div class="line">    <span class="comment">// tensor goes out of scope here, and the destructor is called automatically</span></div>
<div class="line">}</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00179">179</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_aee0ad19fbaa29f4a89e99f21bdd4cdf0_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_aee0ad19fbaa29f4a89e99f21bdd4cdf0_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_aee0ad19fbaa29f4a89e99f21bdd4cdf0_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_aee0ad19fbaa29f4a89e99f21bdd4cdf0_cgraph">
<area shape="rect" title="Destructor for the MappedTensor class." alt="" coords="5,39,167,81"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab6803232b9c08d9282b16322a6c7b8a9" title="Frees the pinned host memory pointed to by the given pointer." alt="" coords="215,5,400,48"/>
<area shape="poly" title=" " alt="" coords="166,45,199,40,200,46,167,51"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="215,72,400,115"/>
<area shape="poly" title=" " alt="" coords="167,69,200,74,199,80,166,75"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#abe439fa00c0bd369c0b2345b095ed5af" title="Synchronizes host thread with completion events for a specific data object." alt="" coords="448,5,633,48"/>
<area shape="poly" title=" " alt="" coords="400,24,432,24,432,29,400,29"/>
</map>
</div>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="ad76dcba2cd22c53b8c4815da113dcb56" name="ad76dcba2cd22c53b8c4815da113dcb56"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad76dcba2cd22c53b8c4815da113dcb56">&#9670;&#160;</a></span>begin()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">MappedTensor::iterator nz::data::MappedTensor::begin </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">nodiscard</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns an iterator pointing to the first element of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. </p>
<dl class="section return"><dt>Returns</dt><dd>An iterator (host-to-host) of type <code>MappedTensor::iterator</code> pointing to the first element of the tensor's data.</dd></dl>
<p>This function provides a way to access the first element of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> in a sequential manner. It simply returns the pointer <code>_data</code> as an iterator, allowing users to traverse the tensor's elements using standard iterator operations.</p>
<p>The memory management strategy is to rely on the existing memory allocation of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object. The iterator points to the same memory location as <code>_data</code>, and no new memory is allocated or freed in this function. There is no explicit exception handling in this function, as it is a simple pointer return operation and is not expected to throw exceptions under normal circumstances. This function is often used in combination with other standard library algorithms and range - based for loops to iterate over the tensor's elements.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>Ensure that the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object is properly initialized before calling this function, as an uninitialized object may lead to undefined behavior.</li>
<li>The returned iterator is valid as long as the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object exists and its underlying data is not reallocated or modified in a way that invalidates the pointer.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">false</span>);</div>
<div class="line">nz::data::MappedTensor::iterator it = tensor.begin();</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00188">188</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_ad76dcba2cd22c53b8c4815da113dcb56_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_ad76dcba2cd22c53b8c4815da113dcb56_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_ad76dcba2cd22c53b8c4815da113dcb56_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_ad76dcba2cd22c53b8c4815da113dcb56_cgraph">
<area shape="rect" title="Returns an iterator pointing to the first element of the MappedTensor." alt="" coords="5,39,167,81"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#a5134b8821da18631dd9a9b9417b0ba5e" title="Synchronizes the tensor data and its gradient." alt="" coords="215,39,376,81"/>
<area shape="poly" title=" " alt="" coords="167,57,199,57,199,63,167,63"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#ae133d08d4505a30c6bd34e4a7a311f9e" title="Synchronizes the tensor data by waiting for all CUDA stream write operations on it to finish." alt="" coords="424,5,585,48"/>
<area shape="poly" title=" " alt="" coords="376,44,408,39,409,45,377,50"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#af9d1b0fa71f9bb7686cc26ae7b32be8d" title="Synchronizes the gradient data if gradient computation is required." alt="" coords="424,72,585,115"/>
<area shape="poly" title=" " alt="" coords="377,70,409,75,408,81,376,76"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="633,5,819,48"/>
<area shape="poly" title=" " alt="" coords="586,24,618,24,618,29,586,29"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#abe439fa00c0bd369c0b2345b095ed5af" title="Synchronizes host thread with completion events for a specific data object." alt="" coords="633,72,819,115"/>
<area shape="poly" title=" " alt="" coords="578,46,639,64,637,70,577,51"/>
<area shape="poly" title=" " alt="" coords="577,69,637,50,639,56,578,74"/>
<area shape="poly" title=" " alt="" coords="586,91,618,91,618,96,586,96"/>
</map>
</div>

</div>
</div>
<a id="a0b348f12004c0b5eeb46f8f1d4b0bf53" name="a0b348f12004c0b5eeb46f8f1d4b0bf53"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0b348f12004c0b5eeb46f8f1d4b0bf53">&#9670;&#160;</a></span>clear()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void nz::data::MappedTensor::clear </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Clear the data stored in the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> by setting all elements to zero. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">None</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None</dd></dl>
<p>This function uses CUDA's <code>cudaMemset</code> to set all elements of the <code>_data</code> array to zero. It is designed to quickly reset the tensor's data.</p>
<p>Memory management: The function does not allocate or deallocate memory. It simply modifies the existing data in the <code>_data</code> array. Exception handling: The <code>CHECK</code> macro is used to handle potential CUDA errors. If <code>cudaMemset</code> fails, the <code>CHECK</code> macro will handle the error according to its implementation, which may include logging and terminating the program. Relationship with other components: This function is related to the data management component of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It provides a way to reset the tensor's data to a known state.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">None</td><td>explicitly, but the <code>CHECK</code> macro may handle and report CUDA errors.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The time complexity of this function is O(n), where n is the number of elements in the tensor (<code>_size</code>), as <code>cudaMemset</code> needs to set each element to zero.</li>
<li>Ensure that the CUDA environment is properly initialized before calling this function.</li>
</ul>
</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd><ul>
<li>If the CUDA environment is not set up correctly, <code>cudaMemset</code> may fail, and the <code>CHECK</code> macro will handle the error, which may lead to program termination.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">false</span>);</div>
<div class="line">tensor.dataInject({1, 2, 3, 4, 5, 6}, <span class="keyword">false</span>);</div>
<div class="line">tensor.clear();</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00327">327</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_a0b348f12004c0b5eeb46f8f1d4b0bf53_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_a0b348f12004c0b5eeb46f8f1d4b0bf53_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_a0b348f12004c0b5eeb46f8f1d4b0bf53_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_a0b348f12004c0b5eeb46f8f1d4b0bf53_cgraph">
<area shape="rect" title="Clear the data stored in the MappedTensor by setting all elements to zero." alt="" coords="5,39,167,81"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="215,5,400,48"/>
<area shape="poly" title=" " alt="" coords="166,45,199,40,200,46,167,51"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a71ad766cb2869d3dd6a3931966e81706" title="Asynchronously sets a block of CUDA device memory to a specified value." alt="" coords="215,72,400,115"/>
<area shape="poly" title=" " alt="" coords="167,69,200,74,199,80,166,75"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a1de1cf3aadea137faf90a2f9b4b7abe2" title="Acquires CUDA stream from pool using round&#45;robin scheduling." alt="" coords="448,39,633,81"/>
<area shape="poly" title=" " alt="" coords="400,77,432,73,433,78,401,83"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#adb1078a67c6e38932d7d58c2adb05ec0" title="Synchronizes CUDA stream execution until data writes complete." alt="" coords="448,105,633,148"/>
<area shape="poly" title=" " alt="" coords="401,104,433,109,432,114,400,109"/>
</map>
</div>

</div>
</div>
<a id="a8ced8f419ebc96c0a1b58e7d271aaa0a" name="a8ced8f419ebc96c0a1b58e7d271aaa0a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8ced8f419ebc96c0a1b58e7d271aaa0a">&#9670;&#160;</a></span>clearGrad()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void nz::data::MappedTensor::clearGrad </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Clear the gradient data of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> if it requires gradients. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">None</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None</dd></dl>
<p>This function is used to reset the gradient data of a <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> to zero. It first checks if the tensor requires gradients. If it does, it uses CUDA's <code>cudaMemset</code> to set all elements of the <code>_grad</code> array to zero. Otherwise, it throws a <code>std::runtime_error</code>.</p>
<p>Memory management: The function does not allocate or deallocate memory. It only modifies the existing <code>_grad</code> array. Exception handling: If the tensor does not require gradients, a <code>std::runtime_error</code> is thrown. If <code>cudaMemset</code> fails, the <code>CHECK</code> macro will handle the CUDA error according to its implementation. Relationship with other components: This function is related to the gradient management component of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It provides a way to reset the gradient data for tensors that support gradient computation.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>If the tensor does not require gradients.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The time complexity of this function is O(n), where n is the number of elements in the tensor (<code>_size</code>), as <code>cudaMemset</code> needs to set each element of the gradient array to zero.</li>
<li>Ensure that the CUDA environment is properly initialized before calling this function if the tensor requires gradients.</li>
</ul>
</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd><ul>
<li>Attempting to clear gradients for a tensor that does not require gradients will result in a runtime error.</li>
<li>If the CUDA environment is not set up correctly and the tensor requires gradients, <code>cudaMemset</code> may fail, and the <code>CHECK</code> macro will handle the error, which may lead to program termination.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">true</span>);</div>
<div class="line"><span class="keywordflow">try</span> {</div>
<div class="line">    tensor.clearGrad();</div>
<div class="line">} <span class="keywordflow">catch</span> (<span class="keyword">const</span> std::runtime_error&amp; e) {</div>
<div class="line">    std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;</div>
<div class="line">}</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00331">331</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_a8ced8f419ebc96c0a1b58e7d271aaa0a_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_a8ced8f419ebc96c0a1b58e7d271aaa0a_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_a8ced8f419ebc96c0a1b58e7d271aaa0a_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_a8ced8f419ebc96c0a1b58e7d271aaa0a_cgraph">
<area shape="rect" title="Clear the gradient data of the MappedTensor if it requires gradients." alt="" coords="5,39,167,81"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="215,5,400,48"/>
<area shape="poly" title=" " alt="" coords="166,45,199,40,200,46,167,51"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a71ad766cb2869d3dd6a3931966e81706" title="Asynchronously sets a block of CUDA device memory to a specified value." alt="" coords="215,72,400,115"/>
<area shape="poly" title=" " alt="" coords="167,69,200,74,199,80,166,75"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a1de1cf3aadea137faf90a2f9b4b7abe2" title="Acquires CUDA stream from pool using round&#45;robin scheduling." alt="" coords="448,39,633,81"/>
<area shape="poly" title=" " alt="" coords="400,77,432,73,433,78,401,83"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#adb1078a67c6e38932d7d58c2adb05ec0" title="Synchronizes CUDA stream execution until data writes complete." alt="" coords="448,105,633,148"/>
<area shape="poly" title=" " alt="" coords="401,104,433,109,432,114,400,109"/>
</map>
</div>

</div>
</div>
<a id="ad72562ee8cad3196dc9ffbdd436f74a3" name="ad72562ee8cad3196dc9ffbdd436f74a3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad72562ee8cad3196dc9ffbdd436f74a3">&#9670;&#160;</a></span>data()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">MappedTensor::value_type * nz::data::MappedTensor::data </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">nodiscard</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Retrieves a pointer to the underlying data array of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. </p>
<dl class="section return"><dt>Returns</dt><dd>A pointer (host-to-host) of type <code>value_type*</code> that points to the first element of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>'s data array.</dd></dl>
<p>This function offers direct access to the raw data stored within the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It is useful for operations that require low - level manipulation of the data, such as interacting with external libraries that expect a raw pointer.</p>
<p>The memory management strategy is to return a pointer to the existing memory allocated for the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. No new memory is allocated or freed during this function call. The caller should not attempt to deallocate the returned pointer, as the memory is managed by the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object. There is no exception handling mechanism in this function because it is declared <code>noexcept</code>, meaning it will not throw any exceptions under normal circumstances. This function can be used in combination with other functions that operate on raw data pointers, facilitating seamless integration with other parts of the system.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>This function is a const member function, so it can be called on const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> objects.</li>
<li>The <code>[[nodiscard]]</code> attribute indicates that the return value should not be ignored, as it provides access to the core data of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.</li>
<li>Ensure that the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object is valid when using the returned pointer, as an invalid object may lead to undefined behavior.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">false</span>);</div>
<div class="line">nz::data::MappedTensor::value_type* ptr = tensor.data();</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00202">202</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>

</div>
</div>
<a id="adbbf1cda4d9806c93ad30316ce507630" name="adbbf1cda4d9806c93ad30316ce507630"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adbbf1cda4d9806c93ad30316ce507630">&#9670;&#160;</a></span>dataInject() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void nz::data::MappedTensor::dataInject </td>
          <td>(</td>
          <td class="paramtype">const std::initializer_list&lt; value_type &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>data</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const bool</td>          <td class="paramname"><span class="paramname"><em>isGrad</em></span><span class="paramdefsep"> = </span><span class="paramdefval">false</span>&#160;) const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Inject data from a std::initializer_list into either the tensor's data or its gradient. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">data</td><td>A std::initializer_list&lt;value_type&gt; (host-to-host) containing the data to be injected. </td></tr>
    <tr><td class="paramname">isGrad</td><td>A boolean value (host-to-host) indicating whether to inject the data into the gradient (<code>true</code>) or the tensor data (<code>false</code>).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>void</dd></dl>
<p>This function transfers data from a std::initializer_list to the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. Based on the <code>isGrad</code> flag, it assigns the values from the initializer list to either the tensor's main data or its gradient.</p>
<p>Memory management: The caller is responsible for the memory of the std::initializer_list. The function only reads values from the list and copies them into the tensor's internal memory. It ensures that at most the minimum of the list size and the tensor's size (<code>_size</code>) is copied to prevent out-of-bounds access. Exception handling: If <code>isGrad</code> is <code>true</code> and the tensor does not require gradients (<code>_requires_grad</code> is <code>false</code>), a <code>std::invalid_argument</code> exception is thrown. Relationship with other components: This function interacts with the data storage and gradient management components of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It provides a convenient way to initialize the tensor's data or gradient using an initializer list.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If <code>isGrad</code> is <code>true</code> and the tensor does not require gradients.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The function has a time complexity of O(min(n, _size)), where n is the number of elements in the std::initializer_list, as it iterates over the list to copy the data.</li>
<li>Ensure that the std::initializer_list contains elements of the correct type (<code>value_type</code>).</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">true</span>);</div>
<div class="line">tensor.dataInject({1, 2, 3, 4, 5, 6}, <span class="keyword">false</span>);</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00247">247</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_adbbf1cda4d9806c93ad30316ce507630_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_adbbf1cda4d9806c93ad30316ce507630_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_adbbf1cda4d9806c93ad30316ce507630_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_adbbf1cda4d9806c93ad30316ce507630_cgraph">
<area shape="rect" title="Inject data from a std::initializer_list into either the tensor&#39;s data or its gradient." alt="" coords="5,5,167,48"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#ad72562ee8cad3196dc9ffbdd436f74a3" title="Retrieves a pointer to the underlying data array of the MappedTensor." alt="" coords="215,5,376,48"/>
<area shape="poly" title=" " alt="" coords="167,24,199,24,199,29,167,29"/>
</map>
</div>

</div>
</div>
<a id="a34906f06e918a40089db7a8936ee1608" name="a34906f06e918a40089db7a8936ee1608"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a34906f06e918a40089db7a8936ee1608">&#9670;&#160;</a></span>dataInject() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void nz::data::MappedTensor::dataInject </td>
          <td>(</td>
          <td class="paramtype">float *</td>          <td class="paramname"><span class="paramname"><em>data</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_type</td>          <td class="paramname"><span class="paramname"><em>size</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>isGrad</em></span><span class="paramdefsep"> = </span><span class="paramdefval">false</span>&#160;) const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Inject data into either the tensor's main data or its gradient. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">data</td><td>A pointer to an array of <code>value_type</code> (host-to-device) that contains the data to be injected. </td></tr>
    <tr><td class="paramname">size</td><td>A <code>size_type</code> value (host-to-device) representing the number of elements in the <code>data</code> array. </td></tr>
    <tr><td class="paramname">isGrad</td><td>A boolean value (host-to-device) indicating whether the data should be injected into the gradient (<code>true</code>) or the main tensor data (<code>false</code>).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>void</dd></dl>
<p>This function is designed to inject external data into the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. Depending on the <code>isGrad</code> flag, it will copy the provided data either into the tensor's main data or its gradient.</p>
<p>Memory management: The caller is responsible for allocating and deallocating the memory of the <code>data</code> array on the host side. The function uses <code>cudaMemcpy</code> to transfer the data from the host to the device memory of the tensor or its gradient. It only copies the minimum of <code>size</code> and <code>_size</code> elements to prevent out - of - bounds access. Exception handling: If <code>isGrad</code> is <code>true</code> and the tensor does not require gradients (<code>_requires_grad</code> is <code>false</code>), a <code>std::invalid_argument</code> exception is thrown. Additionally, if the <code>cudaMemcpy</code> operation fails, the <code>CHECK</code> macro is expected to handle the error, potentially throwing an exception or terminating the program. Relationship with other components: This function is closely related to the data storage and gradient management components of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It provides a way to update the tensor's data or gradient values from an external source.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If <code>isGrad</code> is <code>true</code> and the tensor does not require gradients. </td></tr>
    <tr><td class="paramname">An</td><td>exception might be thrown by the <code>CHECK</code> macro if the <code>cudaMemcpy</code> operation fails.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>Ensure that the CUDA runtime environment is properly initialized before calling this function, as it uses <code>cudaMemcpy</code> for data transfer.</li>
<li>The <code>CHECK</code> macro is assumed to handle CUDA errors correctly. Any issues with the CUDA operations will be reported through this macro.</li>
<li>The function only copies the minimum of <code>size</code> and <code>_size</code> elements to avoid out - of - bounds access.</li>
</ul>
</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd><ul>
<li>Incorrect usage of this function can lead to data corruption or CUDA errors. For example, if the CUDA environment is not set up correctly, the <code>cudaMemcpy</code> operation may fail unexpectedly.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">true</span>);</div>
<div class="line">nz::data::MappedTensor::value_type <a class="code hl_function" href="#ad72562ee8cad3196dc9ffbdd436f74a3">data</a>[] = {1, 2, 3, 4, 5, 6};</div>
<div class="line">tensor.dataInject(<a class="code hl_function" href="#ad72562ee8cad3196dc9ffbdd436f74a3">data</a>, 6, <span class="keyword">false</span>);</div>
<div class="line">```</div>
<div class="ttc" id="aclassnz_1_1data_1_1_mapped_tensor_html_ad72562ee8cad3196dc9ffbdd436f74a3"><div class="ttname"><a href="#ad72562ee8cad3196dc9ffbdd436f74a3">nz::data::MappedTensor::data</a></div><div class="ttdeci">value_type * data() const noexcept</div><div class="ttdoc">Retrieves a pointer to the underlying data array of the MappedTensor.</div><div class="ttdef"><b>Definition</b> <a href="_mapped_tensor_8cu_source.html#l00202">MappedTensor.cu:202</a></div></div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00230">230</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_a34906f06e918a40089db7a8936ee1608_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_a34906f06e918a40089db7a8936ee1608_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_a34906f06e918a40089db7a8936ee1608_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_a34906f06e918a40089db7a8936ee1608_cgraph">
<area shape="rect" title="Inject data into either the tensor&#39;s main data or its gradient." alt="" coords="5,105,167,148"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#ad72562ee8cad3196dc9ffbdd436f74a3" title="Retrieves a pointer to the underlying data array of the MappedTensor." alt="" coords="227,5,388,48"/>
<area shape="poly" title=" " alt="" coords="124,103,214,58,227,52,230,57,216,62,127,107"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="215,72,400,115"/>
<area shape="poly" title=" " alt="" coords="166,112,199,107,200,112,167,117"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#afa38d5c6db0e6b48c8f74ce8ad0df2bc" title="Asynchronously copies data between CUDA device and host memory based on the specified memory copy kin..." alt="" coords="215,139,400,181"/>
<area shape="poly" title=" " alt="" coords="167,136,200,141,199,146,166,141"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#aa144f9f3b76741e5d3fb3b5df3cc3b42" title="Retrieves the total number of elements in the MappedTensor." alt="" coords="227,205,388,248"/>
<area shape="poly" title=" " alt="" coords="127,146,216,191,230,197,227,202,214,196,124,151"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a1de1cf3aadea137faf90a2f9b4b7abe2" title="Acquires CUDA stream from pool using round&#45;robin scheduling." alt="" coords="448,105,633,148"/>
<area shape="poly" title=" " alt="" coords="400,144,432,139,433,145,401,149"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#adb1078a67c6e38932d7d58c2adb05ec0" title="Synchronizes CUDA stream execution until data writes complete." alt="" coords="448,172,633,215"/>
<area shape="poly" title=" " alt="" coords="401,171,433,175,432,181,400,176"/>
</map>
</div>

</div>
</div>
<a id="a7f5550020dbf34ae87f208c22a73e28d" name="a7f5550020dbf34ae87f208c22a73e28d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7f5550020dbf34ae87f208c22a73e28d">&#9670;&#160;</a></span>dataInject() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Iterator &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void nz::data::MappedTensor::dataInject </td>
          <td>(</td>
          <td class="paramtype">Iterator</td>          <td class="paramname"><span class="paramname"><em>begin</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Iterator</td>          <td class="paramname"><span class="paramname"><em>end</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const bool</td>          <td class="paramname"><span class="paramname"><em>isGrad</em></span><span class="paramdefsep"> = </span><span class="paramdefval">false</span>&#160;) const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Inject data from an iterator range into either the tensor's data or its gradient. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">Iterator</td><td>The type of the iterator used to access the data source. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">begin</td><td>An iterator (host-to-host) pointing to the start of the data range to be injected. </td></tr>
    <tr><td class="paramname">end</td><td>An iterator (host-to-host) pointing past the end of the data range to be injected. </td></tr>
    <tr><td class="paramname">isGrad</td><td>A boolean value (host-to-host) indicating whether to inject the data into the gradient (<code>true</code>) or the tensor data (<code>false</code>). Defaults to <code>false</code>.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>void</dd></dl>
<p>This function is designed to transfer data from an iterator range into the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It iterates through the given range and assigns the values to either the tensor's main data or its gradient, based on the <code>isGrad</code> flag.</p>
<p>Memory management: The caller is responsible for the memory occupied by the data source pointed to by the iterators. The function only reads values from the iterators and copies them into the tensor's internal memory. It ensures that at most the minimum of the range size and the tensor's size (<code>_size</code>) is copied to prevent out-of-bounds access. Exception handling: If <code>isGrad</code> is <code>true</code> and the tensor does not require gradients (<code>_requires_grad</code> is <code>false</code>), a <code>std::invalid_argument</code> exception is thrown. Additionally, the function assumes that the iterators are valid and well-behaved. If operations on the iterators (such as <code>std::distance</code>, dereferencing, or incrementing) throw exceptions, those exceptions will be propagated. Relationship with other components: This function interacts closely with the data storage and gradient management components of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It provides a flexible way to update the tensor's data or gradient values using different data sources accessible via iterators.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If <code>isGrad</code> is <code>true</code> and the tensor does not require gradients.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>Ensure that the iterators <code>begin</code> and <code>end</code> form a valid range. Using invalid iterators may lead to undefined behavior.</li>
<li>The function has a time complexity of O(min(n, _size)), where n is the number of elements in the iterator range, as it iterates over the range to copy the data.</li>
<li>The data from the iterators is cast to <code>value_type</code> before being assigned to the tensor or its gradient.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><span class="preprocessor">#include &lt;vector&gt;</span></div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">true</span>);</div>
<div class="line">std::vector&lt;nz::data::MappedTensor::value_type&gt; <a class="code hl_function" href="#ad72562ee8cad3196dc9ffbdd436f74a3">data</a> = {1, 2, 3, 4, 5, 6};</div>
<div class="line">tensor.dataInject(<a class="code hl_function" href="#ad72562ee8cad3196dc9ffbdd436f74a3">data</a>.begin(), <a class="code hl_function" href="#ad72562ee8cad3196dc9ffbdd436f74a3">data</a>.end(), <span class="keyword">false</span>);</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cuh_source.html#l00547">547</a> of file <a class="el" href="_mapped_tensor_8cuh_source.html">MappedTensor.cuh</a>.</p>

</div>
</div>
<a id="ac01f432f0ef9b7279630b5b35bc609e0" name="ac01f432f0ef9b7279630b5b35bc609e0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac01f432f0ef9b7279630b5b35bc609e0">&#9670;&#160;</a></span>end()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">MappedTensor::iterator nz::data::MappedTensor::end </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">nodiscard</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns an iterator pointing to the past - the - end element of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. </p>
<dl class="section return"><dt>Returns</dt><dd>An iterator (host-to-host) of type <code>MappedTensor::iterator</code> pointing to the past - the - end element of the tensor's data.</dd></dl>
<p>This function is used to mark the end of the range of elements in the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It calculates the iterator by adding the <code>_size</code> of the tensor to the <code>_data</code> pointer. This allows for standard iteration techniques where the loop continues until the iterator reaches the <code><a class="el" href="#ac01f432f0ef9b7279630b5b35bc609e0" title="Returns an iterator pointing to the past - the - end element of the MappedTensor.">end()</a></code> iterator.</p>
<p>The memory management strategy is to rely on the existing memory allocation of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object. The iterator points to a memory location just past the last element of the tensor's data, and no new memory is allocated or freed in this function. There is no explicit exception handling in this function, as it is a simple pointer arithmetic operation and is not expected to throw exceptions under normal circumstances. This function is commonly used in combination with <code><a class="el" href="#ad76dcba2cd22c53b8c4815da113dcb56" title="Returns an iterator pointing to the first element of the MappedTensor.">begin()</a></code> to iterate over all the elements of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> using standard library algorithms or range - based for loops.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>Ensure that the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object is properly initialized before calling this function, as an uninitialized object may lead to undefined behavior.</li>
<li>The returned iterator is valid as long as the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object exists and its underlying data is not reallocated or modified in a way that invalidates the pointer.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">false</span>);</div>
<div class="line">nz::data::MappedTensor::iterator it_end = tensor.end();</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00193">193</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_ac01f432f0ef9b7279630b5b35bc609e0_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_ac01f432f0ef9b7279630b5b35bc609e0_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_ac01f432f0ef9b7279630b5b35bc609e0_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_ac01f432f0ef9b7279630b5b35bc609e0_cgraph">
<area shape="rect" title="Returns an iterator pointing to the past &#45; the &#45; end element of the MappedTensor." alt="" coords="5,47,196,73"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#a5134b8821da18631dd9a9b9417b0ba5e" title="Synchronizes the tensor data and its gradient." alt="" coords="244,39,405,81"/>
<area shape="poly" title=" " alt="" coords="196,57,228,57,228,63,196,63"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#ae133d08d4505a30c6bd34e4a7a311f9e" title="Synchronizes the tensor data by waiting for all CUDA stream write operations on it to finish." alt="" coords="453,5,614,48"/>
<area shape="poly" title=" " alt="" coords="405,44,437,39,438,45,406,50"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#af9d1b0fa71f9bb7686cc26ae7b32be8d" title="Synchronizes the gradient data if gradient computation is required." alt="" coords="453,72,614,115"/>
<area shape="poly" title=" " alt="" coords="406,70,438,75,437,81,405,76"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="662,5,848,48"/>
<area shape="poly" title=" " alt="" coords="615,24,647,24,647,29,615,29"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#abe439fa00c0bd369c0b2345b095ed5af" title="Synchronizes host thread with completion events for a specific data object." alt="" coords="662,72,848,115"/>
<area shape="poly" title=" " alt="" coords="607,46,668,64,666,70,606,51"/>
<area shape="poly" title=" " alt="" coords="606,69,666,50,668,56,607,74"/>
<area shape="poly" title=" " alt="" coords="615,91,647,91,647,96,615,96"/>
</map>
</div>

</div>
</div>
<a id="ad4b349b1cbc2fef18f4b450f4d11377a" name="ad4b349b1cbc2fef18f4b450f4d11377a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad4b349b1cbc2fef18f4b450f4d11377a">&#9670;&#160;</a></span>expSum()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">MappedTensor::value_type nz::data::MappedTensor::expSum </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">nodiscard</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Calculate the sum of the exponential values of all elements in the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. </p>
<dl class="section return"><dt>Returns</dt><dd>The sum of the exponential values of all elements in the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> as a value of type <code>MappedTensor::value_type</code>.</dd></dl>
<p>This function computes the sum of the exponential values of all elements within the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It first determines the CUDA block and grid dimensions based on the size of the tensor. Then, it allocates pinned host memory using <code>cudaMallocHost</code> to store the intermediate results. The <code><a class="el" href="namespacenz_1_1krnl.html#a51a5ff3c8cc2c3051fddf32de294b467" title="Kernel function to compute the summation of exponentials of each element in the input array.">krnl::SummationExp</a></code> CUDA kernel is launched to calculate the partial sums of the exponential values on the device. After the kernel execution, the function synchronizes the device using <code>cudaDeviceSynchronize</code> to ensure all operations are completed. Finally, it sums up the partial results on the host, frees the allocated pinned host memory, and returns the total sum.</p>
<p>Memory management:</p><ul>
<li>Pinned host memory is allocated for <code>dData</code> using <code>cudaMallocHost</code> and freed using <code>cudaFreeHost</code>.</li>
</ul>
<p>Exception handling:</p><ul>
<li>The <code>CHECK</code> macro is used to handle CUDA API errors. If any CUDA API call fails, the <code>CHECK</code> macro will throw an exception, causing the function to terminate.</li>
</ul>
<p>Relationship with other components:</p><ul>
<li>This function relies on the <code><a class="el" href="namespacenz_1_1krnl.html#a51a5ff3c8cc2c3051fddf32de294b467" title="Kernel function to compute the summation of exponentials of each element in the input array.">krnl::SummationExp</a></code> CUDA kernel to perform partial sums of exponential values on the device.</li>
<li>It also depends on the <code>CHECK</code> macro to handle CUDA API errors and <code>cudaDeviceSynchronize</code> for device synchronization.</li>
</ul>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">[Exception</td><td>type thrown by CHECK macro] If there are CUDA API errors during memory allocation, kernel execution, or memory synchronization.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The time complexity of this function is approximately O(n), where n is the number of elements in the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> (<code>_size</code>). The CUDA kernel parallelizes the partial sum calculation of exponential values, and the final sum on the host is a linear operation over the number of grid blocks.</li>
<li>Ensure that the CUDA device is properly initialized before calling this function.</li>
<li>Pinned host memory allocation may have limitations, so be aware of potential memory constraints.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> mapped_tensor({2, 3}, <span class="keyword">true</span>);</div>
<div class="line"><span class="comment">// Assume mapped_tensor is filled with some values</span></div>
<div class="line">nz::data::MappedTensor::value_type exp_sum_result = mapped_tensor.<a class="code hl_function" href="#ad4b349b1cbc2fef18f4b450f4d11377a">expSum</a>();</div>
<div class="line">```</div>
<div class="ttc" id="aclassnz_1_1data_1_1_mapped_tensor_html_ad4b349b1cbc2fef18f4b450f4d11377a"><div class="ttname"><a href="#ad4b349b1cbc2fef18f4b450f4d11377a">nz::data::MappedTensor::expSum</a></div><div class="ttdeci">value_type expSum() const</div><div class="ttdoc">Calculate the sum of the exponential values of all elements in the MappedTensor.</div><div class="ttdef"><b>Definition</b> <a href="_mapped_tensor_8cu_source.html#l00545">MappedTensor.cu:545</a></div></div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00545">545</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_ad4b349b1cbc2fef18f4b450f4d11377a_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_ad4b349b1cbc2fef18f4b450f4d11377a_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_ad4b349b1cbc2fef18f4b450f4d11377a_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_ad4b349b1cbc2fef18f4b450f4d11377a_cgraph">
<area shape="rect" title="Calculate the sum of the exponential values of all elements in the MappedTensor." alt="" coords="5,89,167,132"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab6803232b9c08d9282b16322a6c7b8a9" title="Frees the pinned host memory pointed to by the given pointer." alt="" coords="215,5,400,48"/>
<area shape="poly" title=" " alt="" coords="143,86,234,51,236,56,145,91"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#abe439fa00c0bd369c0b2345b095ed5af" title="Synchronizes host thread with completion events for a specific data object." alt="" coords="448,27,633,69"/>
<area shape="poly" title=" " alt="" coords="167,97,432,60,433,65,167,102"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="448,115,633,157"/>
<area shape="poly" title=" " alt="" coords="167,112,433,127,433,133,167,118"/>
<area shape="rect" href="namespacenz_1_1krnl.html#a51a5ff3c8cc2c3051fddf32de294b467" title="Kernel function to compute the summation of exponentials of each element in the input array." alt="" coords="227,173,388,200"/>
<area shape="poly" title=" " alt="" coords="151,130,253,165,251,170,150,135"/>
<area shape="poly" title=" " alt="" coords="401,33,433,35,432,41,400,38"/>
<area shape="poly" title=" " alt="" coords="372,170,432,157,433,162,373,175"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a46ce59b45de432842454aadf00b93791" title="Asynchronously submits a CUDA kernel with stream&#45;ordered dependency management." alt="" coords="448,181,633,224"/>
<area shape="poly" title=" " alt="" coords="388,190,433,193,432,198,388,195"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a1de1cf3aadea137faf90a2f9b4b7abe2" title="Acquires CUDA stream from pool using round&#45;robin scheduling." alt="" coords="681,148,867,191"/>
<area shape="poly" title=" " alt="" coords="633,187,665,182,666,187,634,192"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#adb1078a67c6e38932d7d58c2adb05ec0" title="Synchronizes CUDA stream execution until data writes complete." alt="" coords="681,215,867,257"/>
<area shape="poly" title=" " alt="" coords="634,213,666,218,665,223,633,219"/>
</map>
</div>

</div>
</div>
<a id="acf793cf0d23af29076d18cd46a6d19cf" name="acf793cf0d23af29076d18cd46a6d19cf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acf793cf0d23af29076d18cd46a6d19cf">&#9670;&#160;</a></span>fill()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void nz::data::MappedTensor::fill </td>
          <td>(</td>
          <td class="paramtype">value_type</td>          <td class="paramname"><span class="paramname"><em>value</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>isGrad</em></span><span class="paramdefsep"> = </span><span class="paramdefval">false</span>&#160;) const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Fill the data or gradients of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> with a given value. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">value</td><td>The value used to fill the tensor's data or gradients (host-to-device). </td></tr>
    <tr><td class="paramname">isGrad</td><td>A boolean flag indicating whether to fill the gradients or the data. If true, gradients are filled; otherwise, data is filled (host-to-device).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None</dd></dl>
<p>This function fills either the data or the gradients of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> with the specified <code>value</code>. It determines the appropriate CUDA grid and block dimensions based on the size of the tensor, and then invokes the <code><a class="el" href="namespacenz_1_1krnl.html#ad136c8a6560a5305984ce0a31bea71bf" title="Kernel function to fill a data array with a given value.">krnl::Fill</a></code> kernel to perform the filling operation.</p>
<p>Memory management: The function does not allocate or deallocate the tensor's data or gradient memory. It only modifies the existing memory in-place. Exception handling: It is assumed that the <code><a class="el" href="namespacenz_1_1krnl.html#ad136c8a6560a5305984ce0a31bea71bf" title="Kernel function to fill a data array with a given value.">krnl::Fill</a></code> kernel handles its own errors and may throw exceptions in case of issues. If an exception occurs in the kernel, it will propagate up. Relationship with other components: This function depends on the <code><a class="el" href="namespacenz_1_1krnl.html#ad136c8a6560a5305984ce0a31bea71bf" title="Kernel function to fill a data array with a given value.">krnl::Fill</a></code> kernel to perform the actual filling operation. It provides a high - level interface for initializing the tensor's data or gradients.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The time complexity of this function is O(n), where n is the number of elements in the tensor (<code>_size</code>), as it needs to set each element to the given value.</li>
<li>Ensure that the CUDA environment is properly configured and the <code><a class="el" href="namespacenz_1_1krnl.html#ad136c8a6560a5305984ce0a31bea71bf" title="Kernel function to fill a data array with a given value.">krnl::Fill</a></code> kernel is correctly implemented before calling this function.</li>
</ul>
</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd><ul>
<li>If the CUDA device is not properly initialized or the <code><a class="el" href="namespacenz_1_1krnl.html#ad136c8a6560a5305984ce0a31bea71bf" title="Kernel function to fill a data array with a given value.">krnl::Fill</a></code> kernel has implementation issues, this function may fail.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">true</span>);</div>
<div class="line">tensor.fill(1.0f, <span class="keyword">false</span>);</div>
<div class="line">tensor.fill(0.0f, <span class="keyword">true</span>);</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00390">390</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_acf793cf0d23af29076d18cd46a6d19cf_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_acf793cf0d23af29076d18cd46a6d19cf_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_acf793cf0d23af29076d18cd46a6d19cf_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_acf793cf0d23af29076d18cd46a6d19cf_cgraph">
<area shape="rect" title="Fill the data or gradients of the MappedTensor with a given value." alt="" coords="5,39,167,81"/>
<area shape="rect" href="namespacenz_1_1krnl.html#ad136c8a6560a5305984ce0a31bea71bf" title="Kernel function to fill a data array with a given value." alt="" coords="215,47,304,73"/>
<area shape="poly" title=" " alt="" coords="167,57,199,57,199,63,167,63"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="352,5,537,48"/>
<area shape="poly" title=" " alt="" coords="304,49,336,44,337,49,305,55"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a46ce59b45de432842454aadf00b93791" title="Asynchronously submits a CUDA kernel with stream&#45;ordered dependency management." alt="" coords="352,72,537,115"/>
<area shape="poly" title=" " alt="" coords="305,65,337,71,336,76,304,71"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a1de1cf3aadea137faf90a2f9b4b7abe2" title="Acquires CUDA stream from pool using round&#45;robin scheduling." alt="" coords="585,39,771,81"/>
<area shape="poly" title=" " alt="" coords="537,77,569,73,570,78,538,83"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#adb1078a67c6e38932d7d58c2adb05ec0" title="Synchronizes CUDA stream execution until data writes complete." alt="" coords="585,105,771,148"/>
<area shape="poly" title=" " alt="" coords="538,104,570,109,569,114,537,109"/>
</map>
</div>

</div>
</div>
<a id="a96696ca7de5d5d3b7e0ba834a80d541d" name="a96696ca7de5d5d3b7e0ba834a80d541d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a96696ca7de5d5d3b7e0ba834a80d541d">&#9670;&#160;</a></span>operator!=()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">bool nz::data::MappedTensor::operator!= </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>other</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Checks if two <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> objects are not equal. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">other</td><td>The other <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object to compare with. Memory flow: direct access from host memory (as the underlying <code>operator==</code> function accesses data in host memory).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Returns true if the two <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> objects are not equal, false otherwise.</dd></dl>
<p>This function determines the non - equality of two <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> objects. It achieves this by negating the result of the <code>operator==</code> function. Thus, its behavior is entirely dependent on the implementation of the <code>operator==</code> function for <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.</p>
<p><b>Memory Management Strategy</b>:</p><ul>
<li>This function does not allocate or free any memory. All memory - related operations are handled by the <code>operator==</code> function.</li>
</ul>
<p><b>Exception Handling Mechanism</b>:</p><ul>
<li>Any exceptions that may occur during the comparison are handled by the <code>operator==</code> function. This function does not have its own exception - handling logic.</li>
</ul>
<p><b>Relationship with Other Components</b>:</p><ul>
<li>It depends solely on the <code>operator==</code> function of the <code><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a></code> class.</li>
</ul>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The time complexity of this function is the same as that of the <code>operator==</code> function, which is O(n), where n is the number of elements in the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.</li>
<li>Ensure that the <code>operator==</code> function of <code><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a></code> is correctly implemented, as this function relies on it for the comparison.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> tensor1; <span class="comment">// Assume MappedTensor1 is properly initialized</span></div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> tensor2; <span class="comment">// Assume MappedTensor2 is properly initialized</span></div>
<div class="line"><span class="keywordtype">bool</span> isNotEqual = tensor1 != tensor2;</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00490">490</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>

</div>
</div>
<a id="a7a6bc3862735542300e7f3ecd2df887f" name="a7a6bc3862735542300e7f3ecd2df887f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7a6bc3862735542300e7f3ecd2df887f">&#9670;&#160;</a></span>operator*()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> nz::data::MappedTensor::operator* </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>other</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Perform matrix multiplication between two MappedTensors. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">other</td><td>The <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> to be multiplied with the current <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> (host-to-host).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> containing the result of the matrix multiplication.</dd></dl>
<p>This function performs matrix multiplication between the current <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> and another <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It first checks if the number of columns in the current tensor is equal to the number of rows in the other tensor. If not, it throws a <code>std::invalid_argument</code> exception. Then, it creates a new <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> with the appropriate shape for the result and sets the gradient requirement based on the current tensor. Next, it calculates the CUDA grid and block dimensions according to the shape of the result tensor and invokes the <code><a class="el" href="namespacenz_1_1krnl.html#ae30a6e1de69588aa0c6eb8a5b8e6e826" title="Kernel function to perform single-precision matrix multiplication on GPU using CUDA cores.">krnl::GeneralMatrixMul</a></code> kernel to perform the actual matrix multiplication. Finally, it synchronizes the CUDA device and returns the resulting <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.</p>
<p>Memory management: A new <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> is created to store the result, and its memory is managed automatically by the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> class. The input tensors' memory remains unchanged. Exception handling: If the matrix shapes do not match for multiplication, a <code>std::invalid_argument</code> exception is thrown. The <code>CHECK</code> macro is used to handle CUDA errors, and if a CUDA operation fails, it will throw an appropriate exception. Relationship with other components: This function depends on the <code><a class="el" href="namespacenz_1_1krnl.html#ae30a6e1de69588aa0c6eb8a5b8e6e826" title="Kernel function to perform single-precision matrix multiplication on GPU using CUDA cores.">krnl::GeneralMatrixMul</a></code> kernel to perform the matrix multiplication and the <code>CHECK</code> macro to handle CUDA errors.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If the number of columns in the current <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> is not equal to the number of rows in the other <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. </td></tr>
    <tr><td class="paramname">[Exception</td><td>type thrown by CHECK macro] If a CUDA operation fails.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The time complexity of this function is O(m * n * k), where m is the number of rows in the current tensor, n is the number of columns in the other tensor, and k is the number of columns in the current tensor (which is equal to the number of rows in the other tensor).</li>
</ul>
</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd><ul>
<li>If the CUDA device runs out of memory during the operation, the function may fail.</li>
<li>Incorrect implementation of the <code><a class="el" href="namespacenz_1_1krnl.html#ae30a6e1de69588aa0c6eb8a5b8e6e826" title="Kernel function to perform single-precision matrix multiplication on GPU using CUDA cores.">krnl::GeneralMatrixMul</a></code> kernel may lead to incorrect multiplication results.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> shape1 = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> shape2 = {3, 4};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor1(shape1, <span class="keyword">true</span>);</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor2(shape2, <span class="keyword">false</span>);</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> result = tensor1 * tensor2;</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00451">451</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>

</div>
</div>
<a id="a42529629ec686811b950f50b84cffd62" name="a42529629ec686811b950f50b84cffd62"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a42529629ec686811b950f50b84cffd62">&#9670;&#160;</a></span>operator+()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> nz::data::MappedTensor::operator+ </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>other</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Perform element-wise addition between two MappedTensors. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">other</td><td>The <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> to be added to the current <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> (host-to-host).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> containing the result of the element-wise addition.</dd></dl>
<p>This function performs an element-wise addition between the current <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> and another <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It first checks if the shapes of the two tensors are equal; if not, it throws a <code>std::invalid_argument</code> exception. Then, it creates a new <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> with the same shape and the appropriate gradient requirement based on the two input tensors. After that, it calculates the CUDA grid and block dimensions according to the size of the tensors and invokes the <code><a class="el" href="namespacenz_1_1krnl.html#a97cda6dfc6545efaee2b686eed9ae766" title="Kernel function to perform matrix addition on GPU.">krnl::MatrixAdd</a></code> kernel to perform the actual addition operation. Finally, it synchronizes the CUDA device and returns the resulting <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.</p>
<p>Memory management: A new <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> is created to store the result, and its memory is managed automatically by the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> class. The input tensors' memory remains unchanged. Exception handling: If the shapes of the two input tensors are not equal, a <code>std::invalid_argument</code> exception is thrown. The <code>CHECK</code> macro is used to handle CUDA errors, and if a CUDA operation fails, it will throw an appropriate exception. Relationship with other components: This function depends on the <code><a class="el" href="namespacenz_1_1krnl.html#a97cda6dfc6545efaee2b686eed9ae766" title="Kernel function to perform matrix addition on GPU.">krnl::MatrixAdd</a></code> kernel to perform the element-wise addition and the <code>CHECK</code> macro to handle CUDA errors.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If the shapes of the two MappedTensors are not equal. </td></tr>
    <tr><td class="paramname">[Exception</td><td>type thrown by CHECK macro] If a CUDA operation fails.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The time complexity of this function is O(n), where n is the number of elements in the tensors (<code>_size</code>), as it needs to perform an addition operation for each element.</li>
<li>Ensure that the CUDA environment is properly configured and the <code><a class="el" href="namespacenz_1_1krnl.html#a97cda6dfc6545efaee2b686eed9ae766" title="Kernel function to perform matrix addition on GPU.">krnl::MatrixAdd</a></code> kernel is correctly implemented before calling this function.</li>
</ul>
</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd><ul>
<li>If the CUDA device runs out of memory during the operation, the function may fail.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor1(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">true</span>);</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor2(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">false</span>);</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> result = tensor1 + tensor2;</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00439">439</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>

</div>
</div>
<a id="aeb5887e43ba46f43ab2ed5ed78a62de1" name="aeb5887e43ba46f43ab2ed5ed78a62de1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aeb5887e43ba46f43ab2ed5ed78a62de1">&#9670;&#160;</a></span>operator-() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> nz::data::MappedTensor::operator- </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Perform element-wise negation on the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. </p>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> containing the element-wise negation of the current <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.</dd></dl>
<p>This function performs an element-wise negation operation on the current <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It first calculates the CUDA grid and block dimensions based on the size of the tensor. Then, it creates a new <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> with the same shape and gradient requirement as the current one. After that, it invokes the <code><a class="el" href="namespacenz_1_1krnl.html#af7069a420e81babb49b1bc009333d053" title="Kernel function to negate each element of a matrix on the GPU.">krnl::Negation</a></code> kernel to perform the negation operation on each element of the tensor. Finally, it synchronizes the CUDA device and returns the resulting <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.</p>
<p>Memory management: A new <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> is created to store the result, and its memory is managed by the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> class. The memory of the current <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> remains unchanged. Exception handling: The <code>CHECK</code> macro is used to handle CUDA errors. If a CUDA operation fails, it will throw an appropriate exception. Relationship with other components: This function depends on the <code><a class="el" href="namespacenz_1_1krnl.html#af7069a420e81babb49b1bc009333d053" title="Kernel function to negate each element of a matrix on the GPU.">krnl::Negation</a></code> kernel for the negation operation and the <code>CHECK</code> macro for CUDA error handling.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">[Exception</td><td>type thrown by CHECK macro] If a CUDA operation fails.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The time complexity of this function is O(n), where n is the number of elements in the tensor (<code>_size</code>), as it needs to perform a negation for each element.</li>
<li>Ensure that the CUDA environment is properly configured and the <code><a class="el" href="namespacenz_1_1krnl.html#af7069a420e81babb49b1bc009333d053" title="Kernel function to negate each element of a matrix on the GPU.">krnl::Negation</a></code> kernel is correctly implemented before using this function.</li>
</ul>
</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd><ul>
<li>If the CUDA device runs out of memory during the operation, the function may fail.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">true</span>);</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> negatedTensor = -tensor;</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00460">460</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_aeb5887e43ba46f43ab2ed5ed78a62de1_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_aeb5887e43ba46f43ab2ed5ed78a62de1_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_aeb5887e43ba46f43ab2ed5ed78a62de1_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_aeb5887e43ba46f43ab2ed5ed78a62de1_cgraph">
<area shape="rect" title="Perform element&#45;wise negation on the MappedTensor." alt="" coords="5,39,167,81"/>
<area shape="rect" href="namespacenz_1_1krnl.html#af7069a420e81babb49b1bc009333d053" title="Kernel function to negate each element of a matrix on the GPU." alt="" coords="215,47,339,73"/>
<area shape="poly" title=" " alt="" coords="167,57,199,57,199,63,167,63"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="387,5,572,48"/>
<area shape="poly" title=" " alt="" coords="339,47,371,42,372,47,340,52"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a46ce59b45de432842454aadf00b93791" title="Asynchronously submits a CUDA kernel with stream&#45;ordered dependency management." alt="" coords="387,72,572,115"/>
<area shape="poly" title=" " alt="" coords="340,68,372,73,371,78,339,73"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a1de1cf3aadea137faf90a2f9b4b7abe2" title="Acquires CUDA stream from pool using round&#45;robin scheduling." alt="" coords="620,39,806,81"/>
<area shape="poly" title=" " alt="" coords="572,77,604,73,605,78,573,83"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#adb1078a67c6e38932d7d58c2adb05ec0" title="Synchronizes CUDA stream execution until data writes complete." alt="" coords="620,105,806,148"/>
<area shape="poly" title=" " alt="" coords="573,104,605,109,604,114,572,109"/>
</map>
</div>

</div>
</div>
<a id="ab1346540c19b9ab6f416514cd2164c8b" name="ab1346540c19b9ab6f416514cd2164c8b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab1346540c19b9ab6f416514cd2164c8b">&#9670;&#160;</a></span>operator-() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> nz::data::MappedTensor::operator- </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>other</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Perform element-wise subtraction between two MappedTensors. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">other</td><td>The <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> to be subtracted from the current <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> (host-to-host).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> containing the result of the element-wise subtraction.</dd></dl>
<p>This function conducts an element-wise subtraction between the current <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> and another <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It first verifies that the shapes of the two tensors are equal; if not, it throws a <code>std::invalid_argument</code> exception. Then, it constructs a new <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> with the same shape and an appropriate gradient requirement based on the input tensors. Subsequently, it calculates the CUDA grid and block dimensions according to the tensor size and invokes the <code><a class="el" href="namespacenz_1_1krnl.html#ad18a2b0efc0cdfc9cb861396ad4da53f" title="Kernel function to perform matrix subtraction on GPU.">krnl::MatrixSub</a></code> kernel to carry out the subtraction operation. Finally, it synchronizes the CUDA device and returns the resulting <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.</p>
<p>Memory management: A new <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> is created to store the result, and its memory is managed by the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> class. The memory of the input tensors remains untouched. Exception handling: Throws a <code>std::invalid_argument</code> if the shapes of the two MappedTensors do not match. The <code>CHECK</code> macro is used to handle CUDA errors; if a CUDA operation fails, it will throw an appropriate exception. Relationship with other components: Depends on the <code><a class="el" href="namespacenz_1_1krnl.html#ad18a2b0efc0cdfc9cb861396ad4da53f" title="Kernel function to perform matrix subtraction on GPU.">krnl::MatrixSub</a></code> kernel for the subtraction operation and the <code>CHECK</code> macro for CUDA error handling.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If the shapes of the two MappedTensors are not equal. </td></tr>
    <tr><td class="paramname">[Exception</td><td>type thrown by CHECK macro] If a CUDA operation fails.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The time complexity of this function is O(n), where n is the number of elements in the tensors (<code>_size</code>), as it needs to perform a subtraction for each element.</li>
<li>Ensure that the CUDA environment is properly configured and the <code><a class="el" href="namespacenz_1_1krnl.html#ad18a2b0efc0cdfc9cb861396ad4da53f" title="Kernel function to perform matrix subtraction on GPU.">krnl::MatrixSub</a></code> kernel is correctly implemented before using this function.</li>
</ul>
</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd><ul>
<li>If the CUDA device runs out of memory during the operation, the function may fail.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor1(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">true</span>);</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor2(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">false</span>);</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> result = tensor1 - tensor2;</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00445">445</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>

</div>
</div>
<a id="a51ecfec4ea055d7e4c11c4540c3fd996" name="a51ecfec4ea055d7e4c11c4540c3fd996"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a51ecfec4ea055d7e4c11c4540c3fd996">&#9670;&#160;</a></span>operator/()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> nz::data::MappedTensor::operator/ </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>other</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Perform element-wise division between two MappedTensors. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">other</td><td>The <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> to divide the current <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> by (host-to-host).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> containing the result of the element-wise division.</dd></dl>
<p>This function performs element-wise division between the current <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> and another <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It first checks if the shapes of the two tensors are equal. If not, it throws a <code>std::invalid_argument</code> exception. Then, it calculates the CUDA grid and block dimensions based on the size of the tensors. A new <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> with the same shape and gradient requirement as the current tensor is created. The <code><a class="el" href="namespacenz_1_1krnl.html#aa61cded4977bb2dc3720f7057cc2fb47" title="Kernel function to perform element-wise division of two arrays.">krnl::ElementwiseDivide</a></code> kernel is invoked to perform the division operation on each corresponding element of the two tensors. Finally, the CUDA device is synchronized, and the resulting <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> is returned.</p>
<p>Memory management: A new <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> is created to store the result, and its memory is managed by the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> class. The memory of the input tensors remains unchanged. Exception handling: If the shapes of the two tensors are not equal, a <code>std::invalid_argument</code> exception is thrown. The <code>CHECK</code> macro is used to handle CUDA errors, and if a CUDA operation fails, an appropriate exception is thrown. Relationship with other components: This function depends on the <code><a class="el" href="namespacenz_1_1krnl.html#aa61cded4977bb2dc3720f7057cc2fb47" title="Kernel function to perform element-wise division of two arrays.">krnl::ElementwiseDivide</a></code> kernel for the division operation and the <code>CHECK</code> macro for CUDA error handling.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If the shapes of the two MappedTensors are not equal. </td></tr>
    <tr><td class="paramname">[Exception</td><td>type thrown by CHECK macro] If a CUDA operation fails.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The time complexity of this function is O(n), where n is the number of elements in the tensors (<code>_size</code>), as it needs to perform a division for each pair of corresponding elements.</li>
</ul>
</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd><ul>
<li>If the CUDA device runs out of memory during the operation, the function may fail.</li>
<li>Incorrect implementation of the <code><a class="el" href="namespacenz_1_1krnl.html#aa61cded4977bb2dc3720f7057cc2fb47" title="Kernel function to perform element-wise division of two arrays.">krnl::ElementwiseDivide</a></code> kernel may lead to incorrect division results.</li>
<li>Division by zero in the <code><a class="el" href="namespacenz_1_1krnl.html#aa61cded4977bb2dc3720f7057cc2fb47" title="Kernel function to perform element-wise division of two arrays.">krnl::ElementwiseDivide</a></code> kernel may lead to undefined behavior.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor1(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">true</span>);</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor2(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">false</span>);</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> result = tensor1 / tensor2;</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00494">494</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>

</div>
</div>
<a id="aaf2087390e5524c8ff6790bd94c78e90" name="aaf2087390e5524c8ff6790bd94c78e90"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaf2087390e5524c8ff6790bd94c78e90">&#9670;&#160;</a></span>operator=() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp; nz::data::MappedTensor::operator= </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>other</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Copy assignment operator for the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> class. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">other</td><td>A constant reference (host-to-host) to a <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object from which data and properties will be copied.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A reference to the modified <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object (host-to-host).</dd></dl>
<p>This copy assignment operator first checks if the object is not being assigned to itself. If not, it releases the previously allocated memory for the <code>_data</code> and, if <code>_requires_grad</code> is true, for the <code>_grad</code> using <code>cudaFreeHost</code>. Then it copies the shape, size, and <code>_requires_grad</code> flag from the <code>other</code> object. Next, it allocates new host memory for <code>_data</code> and, if <code>_requires_grad</code> is true, for <code>_grad</code> using <code>cudaMallocHost</code>. If <code>_requires_grad</code> is false, the <code>_grad</code> pointer is set to <code>nullptr</code>. Finally, it copies the data and, if applicable, the gradient from the <code>other</code> object using <code>cudaMemcpy</code>. The memory management strategy involves deallocating existing memory before re - allocating and copying new data. There is no explicit exception handling in this operator, but the <code>CHECK</code> macro is assumed to handle errors related to CUDA memory operations. This operator is used to assign the state of one <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object to another.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The <code>CHECK</code> macro is assumed to handle CUDA errors properly. Ensure that the CUDA environment is properly configured before using this operator.</li>
<li>The CUDA memory operations may fail if there is not enough available memory or if the memory pointers are invalid.</li>
</ul>
</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd><ul>
<li>CUDA memory operations, such as <code>cudaMallocHost</code> and <code>cudaMemcpy</code>, can be time - consuming, especially for large tensors. Be aware of the performance implications when using this operator.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor1(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">true</span>);</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor2(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">false</span>);</div>
<div class="line">tensor2 = tensor1;</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00127">127</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_aaf2087390e5524c8ff6790bd94c78e90_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_aaf2087390e5524c8ff6790bd94c78e90_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_aaf2087390e5524c8ff6790bd94c78e90_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_aaf2087390e5524c8ff6790bd94c78e90_cgraph">
<area shape="rect" title="Copy assignment operator for the MappedTensor class." alt="" coords="5,72,167,115"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab6803232b9c08d9282b16322a6c7b8a9" title="Frees the pinned host memory pointed to by the given pointer." alt="" coords="215,5,400,48"/>
<area shape="poly" title=" " alt="" coords="158,69,219,50,220,56,160,74"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="215,72,400,115"/>
<area shape="poly" title=" " alt="" coords="167,91,199,91,199,96,167,96"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#afa38d5c6db0e6b48c8f74ce8ad0df2bc" title="Asynchronously copies data between CUDA device and host memory based on the specified memory copy kin..." alt="" coords="215,139,400,181"/>
<area shape="poly" title=" " alt="" coords="160,113,220,131,219,136,158,118"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#abe439fa00c0bd369c0b2345b095ed5af" title="Synchronizes host thread with completion events for a specific data object." alt="" coords="448,5,633,48"/>
<area shape="poly" title=" " alt="" coords="400,24,432,24,432,29,400,29"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a1de1cf3aadea137faf90a2f9b4b7abe2" title="Acquires CUDA stream from pool using round&#45;robin scheduling." alt="" coords="448,105,633,148"/>
<area shape="poly" title=" " alt="" coords="400,144,432,139,433,145,401,149"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#adb1078a67c6e38932d7d58c2adb05ec0" title="Synchronizes CUDA stream execution until data writes complete." alt="" coords="448,172,633,215"/>
<area shape="poly" title=" " alt="" coords="401,171,433,175,432,181,400,176"/>
</map>
</div>

</div>
</div>
<a id="aa3658f80db10a7715aa45d871ef49cdd" name="aa3658f80db10a7715aa45d871ef49cdd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa3658f80db10a7715aa45d871ef49cdd">&#9670;&#160;</a></span>operator=() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp; nz::data::MappedTensor::operator= </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;&amp;</td>          <td class="paramname"><span class="paramname"><em>other</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Move assignment operator for the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> class. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">other</td><td>An rvalue reference (host-to-host) to a <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object from which resources will be moved.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A reference to the modified <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object (host-to-host).</dd></dl>
<p>This move assignment operator first checks if the object is not being assigned to itself. If so, it releases the existing host memory allocated for <code>_data</code> and, if <code>_requires_grad</code> is true and <code>_grad</code> is not null, for <code>_grad</code> using <code>cudaFreeHost</code>. Then, it transfers the ownership of resources from the <code>other</code> <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object to the current one. It moves the shape using <code>std::move</code>, copies the size and <code>_requires_grad</code> flag, and takes over the pointers to the data and gradient buffers from <code>other</code>. After that, it sets the <code>other</code> object's data and gradient pointers to <code>nullptr</code>, its size to 0, <code>_requires_grad</code> to <code>false</code>, and the shape to <code>{0, 0}</code>. This operation is marked as <code>noexcept</code>, meaning it does not throw exceptions. The memory management strategy involves freeing the current object's existing memory before taking over the memory from <code>other</code>, thus ensuring no memory leaks. There is no need for explicit exception handling as the operation is guaranteed not to throw. This operator is useful for efficiently reusing resources during assignment operations.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>After the move operation, the <code>other</code> object should not be used as it is left in a valid but empty state.</li>
<li>The <code>CHECK</code> macro is assumed to handle CUDA errors properly. Ensure that the CUDA environment is properly configured before using this operator.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor1(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">true</span>);</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor2(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">false</span>);</div>
<div class="line">tensor2 = std::move(tensor1);</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00156">156</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_aa3658f80db10a7715aa45d871ef49cdd_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_aa3658f80db10a7715aa45d871ef49cdd_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_aa3658f80db10a7715aa45d871ef49cdd_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_aa3658f80db10a7715aa45d871ef49cdd_cgraph">
<area shape="rect" title="Move assignment operator for the MappedTensor class." alt="" coords="5,39,167,81"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab6803232b9c08d9282b16322a6c7b8a9" title="Frees the pinned host memory pointed to by the given pointer." alt="" coords="215,5,400,48"/>
<area shape="poly" title=" " alt="" coords="166,45,199,40,200,46,167,51"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="215,72,400,115"/>
<area shape="poly" title=" " alt="" coords="167,69,200,74,199,80,166,75"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#abe439fa00c0bd369c0b2345b095ed5af" title="Synchronizes host thread with completion events for a specific data object." alt="" coords="448,5,633,48"/>
<area shape="poly" title=" " alt="" coords="400,24,432,24,432,29,400,29"/>
</map>
</div>

</div>
</div>
<a id="a79064970ec839800d23d8fc890e0d1f9" name="a79064970ec839800d23d8fc890e0d1f9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a79064970ec839800d23d8fc890e0d1f9">&#9670;&#160;</a></span>operator==()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">bool nz::data::MappedTensor::operator== </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>other</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Checks if two <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> objects are equal. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">other</td><td>The other <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object to compare with. Memory flow: direct access from host memory.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Returns true if the two <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> objects are equal, false otherwise.</dd></dl>
<p>This function compares two <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> objects for equality. First, it checks if the <code>_requires_grad</code> flags of the two MappedTensors are the same. If they differ, the function immediately returns false. Then, it compares the shapes of the two MappedTensors. If the shapes are not equal, the function also returns false.</p>
<p>After that, it compares each element of the data arrays of the two MappedTensors one by one. If any element in the data differs, it returns false.</p>
<p>If the <code>_requires_grad</code> flag is set to true, it repeats the same process for the gradients of the MappedTensors. If any element in the gradients differs, it returns false.</p>
<p>Finally, if all comparisons pass, it returns true.</p>
<p><b>Memory Management Strategy</b>:</p><ul>
<li>This function does not allocate or free any memory. It directly accesses the <code>_data</code> and <code>_grad</code> arrays of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> objects.</li>
</ul>
<p><b>Exception Handling Mechanism</b>:</p><ul>
<li>This function does not have a specific exception handling mechanism. It assumes that the <code>_data</code> and <code>_grad</code> arrays are properly initialized and have the correct size.</li>
</ul>
<p><b>Relationship with Other Components</b>:</p><ul>
<li>Depends on the <code>_requires_grad</code>, <code>_shape</code>, <code>_size</code>, <code>_data</code>, and <code>_grad</code> members of the <code><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a></code> class.</li>
</ul>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>Ensure that the <code>_data</code> and <code>_grad</code> arrays of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> objects are properly initialized before calling this function.</li>
<li>The function has a time complexity of O(n), where n is the number of elements in the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>, due to the element - by - element comparison.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> tensor1; <span class="comment">// Assume MappedTensor1 is properly initialized</span></div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> tensor2; <span class="comment">// Assume MappedTensor2 is properly initialized</span></div>
<div class="line"><span class="keywordtype">bool</span> isEqual = tensor1 == tensor2;</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00468">468</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>

</div>
</div>
<a id="abb30df1c0174d5a8d9fa8911f7b3d3bc" name="abb30df1c0174d5a8d9fa8911f7b3d3bc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abb30df1c0174d5a8d9fa8911f7b3d3bc">&#9670;&#160;</a></span>operator[]()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">auto nz::data::MappedTensor::operator[] </td>
          <td>(</td>
          <td class="paramtype">size_type</td>          <td class="paramname"><span class="paramname"><em>index</em></span></td><td>)</td>
          <td> const -&gt; value_type&amp;</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Overload the [] operator to access an element of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> by index. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">index</td><td>The index of the element to access (host-to-host). It should be a non-negative integer.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A reference to the value at the specified index in the tensor's data.</dd></dl>
<p>This function allows users to access individual elements of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> using the [] operator. It first checks if the given index is within the valid range of the tensor's size. If the index is out of range, it throws a <code>std::out_of_range</code> exception. Otherwise, it returns a reference to the corresponding element in the internal data array <code>_data</code>.</p>
<p>Memory management: The function does not allocate or deallocate any memory. It only accesses the existing internal data array <code>_data</code>. Exception handling: If the provided index is greater than or equal to the size of the tensor (<code>_size</code>), a <code>std::out_of_range</code> exception is thrown. Relationship with other components: This function is related to the data access component of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It provides a convenient way for users to access individual elements of the tensor.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::out_of_range</td><td>If the provided index is out of the valid range (i.e., <code>index &gt;= _size</code>).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The time complexity of this function is O(1) because it directly accesses the element in the internal data array using the given index.</li>
<li>Ensure that the index is within the valid range to avoid exceptions.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">false</span>);</div>
<div class="line">tensor.dataInject({1, 2, 3, 4, 5, 6}, <span class="keyword">false</span>);</div>
<div class="line">nz::data::MappedTensor::value_type value = tensor[2];</div>
<div class="line">std::cout &lt;&lt; value &lt;&lt; std::endl;</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00319">319</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>

</div>
</div>
<a id="a8a42265d7c9f964c41ff43e9d8dc7bf7" name="a8a42265d7c9f964c41ff43e9d8dc7bf7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8a42265d7c9f964c41ff43e9d8dc7bf7">&#9670;&#160;</a></span>print()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::ostream &amp; nz::data::MappedTensor::print </td>
          <td>(</td>
          <td class="paramtype">std::ostream &amp;</td>          <td class="paramname"><span class="paramname"><em>os</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Print the tensor data in a matrix-like format to an output stream. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">os</td><td>An output stream (host-to-host) where the tensor data will be printed.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A reference to the output stream <code>os</code> after printing the tensor data.</dd></dl>
<p>This function is used to display the tensor data in a matrix-like structure. It iterates over the rows of the tensor and prints each row as a sequence of values separated by a space, enclosed in square brackets.</p>
<p>Memory management: The function does not allocate or deallocate any memory. It only reads the tensor's internal data (<code>_data</code>) for printing. Exception handling: The function assumes that the <code>_shape</code> and <code>_data</code> members of the tensor are properly initialized. If there are issues with these members (e.g., invalid shape dimensions), the behavior may be undefined. The operations on the output stream (<code>os</code>) are assumed to be well - behaved, and any exceptions thrown by the stream operations will be propagated. Relationship with other components: This function is mainly related to the data presentation component of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It provides a user - friendly way to view the tensor's data.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The function has a time complexity of O(m * n), where m is the number of rows (<code>_shape[0]</code>) and n is the number of columns (<code>_shape[1]</code>) of the tensor, as it iterates over all elements in the tensor.</li>
<li>Ensure that the output stream <code>os</code> is in a valid state before calling this function.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">false</span>);</div>
<div class="line">tensor.dataInject({1, 2, 3, 4, 5, 6}, <span class="keyword">false</span>);</div>
<div class="line">tensor.print(std::cout);</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00261">261</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_a8a42265d7c9f964c41ff43e9d8dc7bf7_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_a8a42265d7c9f964c41ff43e9d8dc7bf7_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_a8a42265d7c9f964c41ff43e9d8dc7bf7_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_a8a42265d7c9f964c41ff43e9d8dc7bf7_cgraph">
<area shape="rect" title="Print the tensor data in a matrix&#45;like format to an output stream." alt="" coords="5,56,167,99"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#ad76dcba2cd22c53b8c4815da113dcb56" title="Returns an iterator pointing to the first element of the MappedTensor." alt="" coords="229,115,390,157"/>
<area shape="poly" title=" " alt="" coords="168,96,215,108,213,114,166,101"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#ae133d08d4505a30c6bd34e4a7a311f9e" title="Synchronizes the tensor data by waiting for all CUDA stream write operations on it to finish." alt="" coords="662,5,824,48"/>
<area shape="poly" title=" " alt="" coords="167,57,214,49,331,38,447,30,647,24,647,30,448,36,331,43,215,55,168,62"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#ac01f432f0ef9b7279630b5b35bc609e0" title="Returns an iterator pointing to the past &#45; the &#45; end element of the MappedTensor." alt="" coords="215,64,405,91"/>
<area shape="poly" title=" " alt="" coords="167,75,199,75,199,80,167,80"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#a5134b8821da18631dd9a9b9417b0ba5e" title="Synchronizes the tensor data and its gradient." alt="" coords="453,68,614,111"/>
<area shape="poly" title=" " alt="" coords="390,117,437,107,438,112,392,122"/>
<area shape="poly" title=" " alt="" coords="607,65,654,50,656,55,608,70"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#af9d1b0fa71f9bb7686cc26ae7b32be8d" title="Synchronizes the gradient data if gradient computation is required." alt="" coords="662,72,824,115"/>
<area shape="poly" title=" " alt="" coords="615,88,647,89,647,94,615,94"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="872,5,1057,48"/>
<area shape="poly" title=" " alt="" coords="824,24,856,24,856,29,824,29"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#abe439fa00c0bd369c0b2345b095ed5af" title="Synchronizes host thread with completion events for a specific data object." alt="" coords="872,72,1057,115"/>
<area shape="poly" title=" " alt="" coords="817,46,877,64,876,70,815,51"/>
<area shape="poly" title=" " alt="" coords="815,69,876,50,877,56,817,74"/>
<area shape="poly" title=" " alt="" coords="824,91,856,91,856,96,824,96"/>
<area shape="poly" title=" " alt="" coords="406,80,437,82,437,87,405,85"/>
</map>
</div>

</div>
</div>
<a id="ab54e80ac0d2ec90442b0a674004cfdbc" name="ab54e80ac0d2ec90442b0a674004cfdbc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab54e80ac0d2ec90442b0a674004cfdbc">&#9670;&#160;</a></span>printGrad()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::ostream &amp; nz::data::MappedTensor::printGrad </td>
          <td>(</td>
          <td class="paramtype">std::ostream &amp;</td>          <td class="paramname"><span class="paramname"><em>os</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Print the gradient of the tensor in a matrix-like format to an output stream. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">os</td><td>An output stream (host-to-host) where the tensor gradient will be printed.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A reference to the output stream <code>os</code> after printing the tensor gradient.</dd></dl>
<p>This function is designed to display the gradient of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> in a matrix-like structure. It iterates over the rows of the gradient data and prints each row as a sequence of values separated by a space, enclosed in square brackets.</p>
<p>Memory management: The function does not allocate or deallocate any memory. It only reads the tensor's internal gradient data (<code>_grad</code>) for printing. Exception handling: If the tensor does not require gradients (<code>_requires_grad</code> is <code>false</code>), a <code>std::invalid_argument</code> exception is thrown. The operations on the output stream (<code>os</code>) are assumed to be well - behaved, and any exceptions thrown by the stream operations will be propagated. Relationship with other components: This function is related to the gradient management and data presentation components of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It provides a way to view the gradient values of the tensor.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If the tensor does not require gradients.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The function has a time complexity of O(m * n), where m is the number of rows (<code>_shape[0]</code>) and n is the number of columns (<code>_shape[1]</code>) of the tensor's gradient, as it iterates over all elements in the gradient.</li>
<li>Ensure that the output stream <code>os</code> is in a valid state before calling this function.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">true</span>);</div>
<div class="line">tensor.dataInject({1, 2, 3, 4, 5, 6}, <span class="keyword">true</span>);</div>
<div class="line">tensor.printGrad(std::cout);</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00289">289</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_ab54e80ac0d2ec90442b0a674004cfdbc_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_ab54e80ac0d2ec90442b0a674004cfdbc_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_ab54e80ac0d2ec90442b0a674004cfdbc_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_ab54e80ac0d2ec90442b0a674004cfdbc_cgraph">
<area shape="rect" title="Print the gradient of the tensor in a matrix&#45;like format to an output stream." alt="" coords="5,56,167,99"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#ad76dcba2cd22c53b8c4815da113dcb56" title="Returns an iterator pointing to the first element of the MappedTensor." alt="" coords="229,56,390,99"/>
<area shape="poly" title=" " alt="" coords="167,75,214,75,214,80,167,80"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#af9d1b0fa71f9bb7686cc26ae7b32be8d" title="Synchronizes the gradient data if gradient computation is required." alt="" coords="662,115,824,157"/>
<area shape="poly" title=" " alt="" coords="161,97,215,108,331,122,447,130,647,135,647,140,447,135,330,127,214,113,160,102"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#ac01f432f0ef9b7279630b5b35bc609e0" title="Returns an iterator pointing to the past &#45; the &#45; end element of the MappedTensor." alt="" coords="215,5,405,32"/>
<area shape="poly" title=" " alt="" coords="166,54,241,34,243,39,168,59"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#a5134b8821da18631dd9a9b9417b0ba5e" title="Synchronizes the tensor data and its gradient." alt="" coords="453,52,614,95"/>
<area shape="poly" title=" " alt="" coords="391,73,437,72,437,78,391,79"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#ae133d08d4505a30c6bd34e4a7a311f9e" title="Synchronizes the tensor data by waiting for all CUDA stream write operations on it to finish." alt="" coords="662,48,824,91"/>
<area shape="poly" title=" " alt="" coords="615,69,647,69,647,74,615,74"/>
<area shape="poly" title=" " alt="" coords="608,93,656,107,654,112,607,98"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="872,48,1057,91"/>
<area shape="poly" title=" " alt="" coords="824,67,856,67,856,72,824,72"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#abe439fa00c0bd369c0b2345b095ed5af" title="Synchronizes host thread with completion events for a specific data object." alt="" coords="872,115,1057,157"/>
<area shape="poly" title=" " alt="" coords="817,89,877,107,876,112,815,94"/>
<area shape="poly" title=" " alt="" coords="815,112,876,93,877,98,817,117"/>
<area shape="poly" title=" " alt="" coords="824,133,856,133,856,139,824,139"/>
<area shape="poly" title=" " alt="" coords="368,30,439,47,437,53,367,35"/>
</map>
</div>

</div>
</div>
<a id="a0150ae0b7137a617c598d1f71d69ce1a" name="a0150ae0b7137a617c598d1f71d69ce1a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0150ae0b7137a617c598d1f71d69ce1a">&#9670;&#160;</a></span>randomize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void nz::data::MappedTensor::randomize </td>
          <td>(</td>
          <td class="paramtype">size_type</td>          <td class="paramname"><span class="paramname"><em>seed</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>isGrad</em></span><span class="paramdefsep"> = </span><span class="paramdefval">false</span>&#160;) const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Randomize the data or gradients of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> using a given seed. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">seed</td><td>The seed value used to initialize the random number generator (host-to-device). If 0, the current system time will be used as the seed. </td></tr>
    <tr><td class="paramname">isGrad</td><td>A boolean flag indicating whether to randomize the gradients or the data. If true, gradients are randomized; otherwise, data is randomized (host-to-device).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None</dd></dl>
<p>This function provides the ability to randomize either the data or the gradients of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It first checks if gradient randomization is valid for the tensor. If the <code>seed</code> is 0, it uses the current system time as the seed. Then, it initializes a CURAND pseudo - random number generator, sets the seed, and fills the appropriate memory (data or gradients) with uniformly distributed random numbers in the range [0, 1).</p>
<p>Memory management: The function does not allocate or deallocate the tensor's data or gradient memory. It only modifies the existing memory in - place. Exception handling: If the tensor does not require gradients and <code>isGrad</code> is true, a <code>std::invalid_argument</code> is thrown. If any of the CURAND operations (creating the generator, setting the seed, or generating random numbers) fail, a <code>std::runtime_error</code> is thrown. Relationship with other components: This function is related to the data and gradient initialization components of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It offers a way to initialize the tensor's data or gradients with random values.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If gradient randomization is attempted on a tensor that does not require gradients. </td></tr>
    <tr><td class="paramname">std::runtime_error</td><td>If CURAND fails to create the generator, set the seed, or generate random numbers.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The time complexity of this function is O(n), where n is the number of elements in the tensor (<code>_size</code>), as it needs to generate a random number for each element.</li>
<li>Ensure that the CUDA and CURAND libraries are properly initialized and configured before calling this function.</li>
</ul>
</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd><ul>
<li>If the CURAND library is not installed or configured correctly, this function will throw an exception.</li>
<li>Reusing the same seed will result in the same sequence of random numbers being generated.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">true</span>);</div>
<div class="line"><span class="keywordflow">try</span> {</div>
<div class="line">    tensor.randomize(42, <span class="keyword">false</span>);</div>
<div class="line">    tensor.randomize(0, <span class="keyword">true</span>);</div>
<div class="line">} <span class="keywordflow">catch</span> (<span class="keyword">const</span> std::exception&amp; e) {</div>
<div class="line">    std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;</div>
<div class="line">}</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00367">367</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>

</div>
</div>
<a id="a33ec3056e0ae0d2088aa83a7f31f6cec" name="a33ec3056e0ae0d2088aa83a7f31f6cec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a33ec3056e0ae0d2088aa83a7f31f6cec">&#9670;&#160;</a></span>recip()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void nz::data::MappedTensor::recip </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Compute the reciprocal of each element in the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. </p>
<p>This function computes the reciprocal (1/x) of each element in the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It first calculates the CUDA grid and block dimensions based on the size of the tensor. Then, it allocates host memory for a temporary buffer to store the reciprocal values. The <code><a class="el" href="namespacenz_1_1krnl.html#adc047e65307dbc711235f637227b7d10" title="Kernel function to compute the reciprocal of each element of a matrix on the GPU.">krnl::Recip</a></code> kernel is invoked to compute the reciprocals of the elements in the tensor and store the results in the temporary buffer. After the kernel execution, the CUDA device is synchronized. Finally, the original device memory of the tensor is freed, and the pointer is updated to point to the temporary buffer.</p>
<p>Memory management: Host memory is allocated for the temporary buffer using <code>cudaMallocHost</code>. The original device memory of the tensor is freed using <code>cudaFreeHost</code>. The ownership of the data is transferred to the <code>_data</code> member of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. Exception handling: The <code>CHECK</code> macro is used to handle CUDA errors. If any CUDA operation fails, an appropriate exception will be thrown. Relationship with other components: This function depends on the <code><a class="el" href="namespacenz_1_1krnl.html#adc047e65307dbc711235f637227b7d10" title="Kernel function to compute the reciprocal of each element of a matrix on the GPU.">krnl::Recip</a></code> kernel for computing the reciprocals and the <code>CHECK</code> macro for CUDA error handling.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">[Exception</td><td>type thrown by CHECK macro] If a CUDA operation fails.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The time complexity of this function is O(n), where n is the number of elements in the tensor (<code>_size</code>), as it needs to compute the reciprocal for each element.</li>
<li>Ensure that the CUDA environment is properly configured and the <code><a class="el" href="namespacenz_1_1krnl.html#adc047e65307dbc711235f637227b7d10" title="Kernel function to compute the reciprocal of each element of a matrix on the GPU.">krnl::Recip</a></code> kernel is correctly implemented before using this function.</li>
</ul>
</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd><ul>
<li>If the CUDA device runs out of memory during the operation, the function may fail.</li>
<li>Division by zero in the <code><a class="el" href="namespacenz_1_1krnl.html#adc047e65307dbc711235f637227b7d10" title="Kernel function to compute the reciprocal of each element of a matrix on the GPU.">krnl::Recip</a></code> kernel may lead to undefined behavior.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">true</span>);</div>
<div class="line">tensor.recip();</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00500">500</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_a33ec3056e0ae0d2088aa83a7f31f6cec_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_a33ec3056e0ae0d2088aa83a7f31f6cec_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_a33ec3056e0ae0d2088aa83a7f31f6cec_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_a33ec3056e0ae0d2088aa83a7f31f6cec_cgraph">
<area shape="rect" title="Compute the reciprocal of each element in the MappedTensor." alt="" coords="5,68,167,111"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab6803232b9c08d9282b16322a6c7b8a9" title="Frees the pinned host memory pointed to by the given pointer." alt="" coords="215,8,400,51"/>
<area shape="poly" title=" " alt="" coords="166,65,211,53,212,58,168,70"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="448,72,633,115"/>
<area shape="poly" title=" " alt="" coords="167,87,433,90,433,95,167,93"/>
<area shape="rect" href="namespacenz_1_1krnl.html#adc047e65307dbc711235f637227b7d10" title="Kernel function to compute the reciprocal of each element of a matrix on the GPU." alt="" coords="254,127,360,153"/>
<area shape="poly" title=" " alt="" coords="167,105,240,122,239,127,166,110"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#abe439fa00c0bd369c0b2345b095ed5af" title="Synchronizes host thread with completion events for a specific data object." alt="" coords="448,5,633,48"/>
<area shape="poly" title=" " alt="" coords="400,26,432,25,432,31,401,31"/>
<area shape="poly" title=" " alt="" coords="360,127,432,112,433,118,362,132"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a46ce59b45de432842454aadf00b93791" title="Asynchronously submits a CUDA kernel with stream&#45;ordered dependency management." alt="" coords="448,139,633,181"/>
<area shape="poly" title=" " alt="" coords="361,142,432,148,432,153,361,147"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a1de1cf3aadea137faf90a2f9b4b7abe2" title="Acquires CUDA stream from pool using round&#45;robin scheduling." alt="" coords="681,105,867,148"/>
<area shape="poly" title=" " alt="" coords="633,144,665,139,666,145,634,149"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#adb1078a67c6e38932d7d58c2adb05ec0" title="Synchronizes CUDA stream execution until data writes complete." alt="" coords="681,172,867,215"/>
<area shape="poly" title=" " alt="" coords="634,171,666,175,665,181,633,176"/>
</map>
</div>

</div>
</div>
<a id="ad9c451d7aa04362e84e0d68d42a8867a" name="ad9c451d7aa04362e84e0d68d42a8867a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad9c451d7aa04362e84e0d68d42a8867a">&#9670;&#160;</a></span>requiresGrad()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool nz::data::MappedTensor::requiresGrad </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">nodiscard</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Checks whether the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> requires gradient computation. </p>
<dl class="section return"><dt>Returns</dt><dd>A boolean value (host-to-host) indicating whether the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> requires gradient computation. <code>true</code> means it requires gradient computation, and <code>false</code> means it does not.</dd></dl>
<p>This function provides a simple way to query the gradient requirement status of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It is a read - only operation that accesses the internal state of the object.</p>
<p>The memory management strategy is straightforward. No new memory is allocated or freed during this function call. It simply reads the internal state of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object. There is no exception handling mechanism in this function because it is declared <code>noexcept</code>, which means it will not throw any exceptions under normal circumstances. This function can be used in various parts of the codebase to determine whether certain gradient - related operations should be performed on the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>This function is a const member function, so it can be called on const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> objects.</li>
<li>The <code>[[nodiscard]]</code> attribute indicates that the return value should not be ignored, as it conveys important information about the gradient requirement of the tensor.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">true</span>);</div>
<div class="line"><span class="keywordtype">bool</span> grad_required = tensor.requiresGrad();</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00198">198</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>

</div>
</div>
<a id="a54d785fecf6466bd442989545ead6de4" name="a54d785fecf6466bd442989545ead6de4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a54d785fecf6466bd442989545ead6de4">&#9670;&#160;</a></span>reshape()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void nz::data::MappedTensor::reshape </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classnz_1_1data_1_1_dimension.html">shape_type</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>shape</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Reshape the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> to a new shape. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">shape</td><td>The new shape of the tensor (host-to-device).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None</dd></dl>
<p>This function reshapes the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> to the specified new shape. It allocates a new memory block for the data and, if the tensor requires gradients, for the gradients as well. It then copies the existing data and gradients (up to the minimum of the old and new sizes) to the new memory blocks and frees the old memory. Finally, it updates the tensor's shape and size information.</p>
<p>Memory management: The function allocates new host memory for the data and gradients using <code>cudaMallocHost</code> and frees the old host memory using <code>cudaFreeHost</code>. Exception handling: The <code>CHECK</code> macro is used to handle potential CUDA errors during memory allocation, memory setting, and memory copying operations. If any of these operations fail, the <code>CHECK</code> macro will handle the error according to its implementation, which may include logging and terminating the program. Relationship with other components: This function is related to the data and gradient management components of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It provides a way to change the shape of the tensor and adjust its internal memory accordingly.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">None</td><td>explicitly, but the <code>CHECK</code> macro may handle and report CUDA errors.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The time complexity of this function is O(n), where n is the minimum of the old and new sizes of the tensor, as the data and gradients are copied element by element.</li>
<li>Ensure that the CUDA environment is properly initialized before calling this function.</li>
<li>The new shape should be compatible with the intended use of the tensor.</li>
</ul>
</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd><ul>
<li>If the CUDA environment is not set up correctly, memory allocation, setting, or copying operations may fail, and the <code>CHECK</code> macro will handle the error, which may lead to program termination.</li>
<li>Changing the shape of a tensor may affect the interpretation of its data in subsequent operations.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> oldShape = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> newShape = {3, 2};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(oldShape, <span class="keyword">false</span>);</div>
<div class="line">tensor.reshape(newShape);</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00340">340</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_a54d785fecf6466bd442989545ead6de4_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_a54d785fecf6466bd442989545ead6de4_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_a54d785fecf6466bd442989545ead6de4_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_a54d785fecf6466bd442989545ead6de4_cgraph">
<area shape="rect" title="Reshape the MappedTensor to a new shape." alt="" coords="5,139,167,181"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab6803232b9c08d9282b16322a6c7b8a9" title="Frees the pinned host memory pointed to by the given pointer." alt="" coords="215,5,400,48"/>
<area shape="poly" title=" " alt="" coords="108,136,155,97,213,58,224,52,226,57,216,62,158,101,112,140"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="215,72,400,115"/>
<area shape="poly" title=" " alt="" coords="158,136,219,117,220,122,160,141"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#afa38d5c6db0e6b48c8f74ce8ad0df2bc" title="Asynchronously copies data between CUDA device and host memory based on the specified memory copy kin..." alt="" coords="215,205,400,248"/>
<area shape="poly" title=" " alt="" coords="160,179,220,198,219,203,158,184"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a71ad766cb2869d3dd6a3931966e81706" title="Asynchronously sets a block of CUDA device memory to a specified value." alt="" coords="215,139,400,181"/>
<area shape="poly" title=" " alt="" coords="167,157,199,157,199,163,167,163"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#abf8ddc60a224bc676dd0fad40ad2f43b" title="Retrieves the shape of the MappedTensor." alt="" coords="227,272,388,315"/>
<area shape="poly" title=" " alt="" coords="112,180,158,219,216,258,226,263,224,268,213,262,155,223,108,184"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#abe439fa00c0bd369c0b2345b095ed5af" title="Synchronizes host thread with completion events for a specific data object." alt="" coords="448,5,633,48"/>
<area shape="poly" title=" " alt="" coords="400,24,432,24,432,29,400,29"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a1de1cf3aadea137faf90a2f9b4b7abe2" title="Acquires CUDA stream from pool using round&#45;robin scheduling." alt="" coords="448,205,633,248"/>
<area shape="poly" title=" " alt="" coords="400,224,432,224,432,229,400,229"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#adb1078a67c6e38932d7d58c2adb05ec0" title="Synchronizes CUDA stream execution until data writes complete." alt="" coords="448,139,633,181"/>
<area shape="poly" title=" " alt="" coords="383,202,448,184,449,189,385,207"/>
<area shape="poly" title=" " alt="" coords="385,179,449,198,448,203,383,184"/>
<area shape="poly" title=" " alt="" coords="400,157,432,157,432,163,400,163"/>
</map>
</div>

</div>
</div>
<a id="add503096ece511cc5b44f75271ff424d" name="add503096ece511cc5b44f75271ff424d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#add503096ece511cc5b44f75271ff424d">&#9670;&#160;</a></span>setRequiresGrad()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void nz::data::MappedTensor::setRequiresGrad </td>
          <td>(</td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>requires_grad</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Sets the gradient requirement flag for the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> and manages the associated gradient memory accordingly. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">requires_grad</td><td>A boolean value (host-to-host) indicating whether the tensor should require gradient computation.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>void</dd></dl>
<p>This function is responsible for updating the <code>_requires_grad</code> flag of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. If the flag is being changed from <code>true</code> to <code>false</code>, it frees the memory allocated for the gradient (<code>_grad</code>). Conversely, if the flag is being changed from <code>false</code> to <code>true</code>, it allocates memory for the gradient using <code>cudaMallocHost</code>.</p>
<p>The memory management strategy is as follows: When <code>requires_grad</code> is set to <code>false</code> and the tensor previously required gradients, the gradient memory is freed using <code>cudaFreeHost</code>. When <code>requires_grad</code> is set to <code>true</code> and the tensor did not previously require gradients, new memory is allocated using <code>cudaMallocHost</code>. The size of the allocated memory is based on the total number of elements (<code>_size</code>) in the tensor multiplied by the size of each element (<code>sizeof(size_type)</code>). The exception handling mechanism relies on the <code>CHECK</code> macro. If the <code>cudaFreeHost</code> or <code>cudaMallocHost</code> operations fail, the <code>CHECK</code> macro is expected to handle the error appropriately, potentially throwing an exception or terminating the program. This function is closely related to the gradient computation mechanism of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It ensures that the memory for gradients is allocated and freed as needed, which is crucial for efficient gradient calculation and memory management in a CUDA - enabled environment.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">An</td><td>exception might be thrown by the <code>CHECK</code> macro if the <code>cudaFreeHost</code> or <code>cudaMallocHost</code> operations fail.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>Ensure that the CUDA runtime environment is properly initialized before calling this function, as it uses CUDA memory management functions.</li>
<li>The <code>CHECK</code> macro is assumed to handle CUDA errors correctly. Any issues with the CUDA operations will be reported through this macro.</li>
</ul>
</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd><ul>
<li>Incorrect usage of this function can lead to memory leaks or segmentation faults. For example, if the CUDA environment is not set up correctly, the memory allocation or deallocation operations may fail unexpectedly.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">false</span>);</div>
<div class="line">tensor.setRequiresGrad(<span class="keyword">true</span>);</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00214">214</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_add503096ece511cc5b44f75271ff424d_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_add503096ece511cc5b44f75271ff424d_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_add503096ece511cc5b44f75271ff424d_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_add503096ece511cc5b44f75271ff424d_cgraph">
<area shape="rect" title="Sets the gradient requirement flag for the MappedTensor and manages the associated gradient memory ac..." alt="" coords="5,39,167,81"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab6803232b9c08d9282b16322a6c7b8a9" title="Frees the pinned host memory pointed to by the given pointer." alt="" coords="215,5,400,48"/>
<area shape="poly" title=" " alt="" coords="166,45,199,40,200,46,167,51"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="215,72,400,115"/>
<area shape="poly" title=" " alt="" coords="167,69,200,74,199,80,166,75"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#abe439fa00c0bd369c0b2345b095ed5af" title="Synchronizes host thread with completion events for a specific data object." alt="" coords="448,5,633,48"/>
<area shape="poly" title=" " alt="" coords="400,24,432,24,432,29,400,29"/>
</map>
</div>

</div>
</div>
<a id="aefb5c705fc6d224469978cf64ca37e0b" name="aefb5c705fc6d224469978cf64ca37e0b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aefb5c705fc6d224469978cf64ca37e0b">&#9670;&#160;</a></span>setShape()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void nz::data::MappedTensor::setShape </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classnz_1_1data_1_1_dimension.html">shape_type</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>shape</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Sets a new shape for the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> and adjusts its data and gradient memory accordingly. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">shape</td><td>A reference to a <code>shape_type</code> object (host-to-host) that represents the new shape of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>void</dd></dl>
<p>This function is used to change the shape of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It allocates new memory for the tensor's data based on the new shape, initializes the new memory to zero, copies the data from the old memory to the new memory, and then frees the old memory. If the tensor requires gradient computation (<code>_requires_grad</code> is <code>true</code>), it performs similar operations for the gradient memory.</p>
<p>The memory management strategy involves multiple steps. First, new memory is allocated using <code>cudaMallocHost</code> for the data and gradient (if required). Then, the new memory is initialized to zero using <code>cudaMemset</code>. Next, the data is copied from the old memory to the new memory using <code>cudaMemcpy</code> with the <code>cudaMemcpyDeviceToDevice</code> flag. Finally, the old memory is freed using <code>cudaFreeHost</code>. The exception handling mechanism relies on the <code>CHECK</code> macro. If any of the CUDA operations (<code>cudaMallocHost</code>, <code>cudaMemset</code>, <code>cudaMemcpy</code>, <code>cudaFreeHost</code>) fail, the <code>CHECK</code> macro is expected to handle the error, potentially throwing an exception or terminating the program. This function is closely related to the data storage and gradient management components of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It ensures that the tensor's data and gradient are properly adjusted when the shape changes, which is crucial for maintaining data consistency during tensor operations.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">An</td><td>exception might be thrown by the <code>CHECK</code> macro if any of the CUDA operations fail.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>Ensure that the CUDA runtime environment is properly initialized before calling this function, as it uses CUDA memory management and data transfer functions.</li>
<li>The <code>CHECK</code> macro is assumed to handle CUDA errors correctly. Any issues with the CUDA operations will be reported through this macro.</li>
<li>The function assumes that the <code>shape_type</code> object has at least two elements, as it accesses <code>shape[0]</code> and <code>shape[1]</code> to calculate the new size.</li>
</ul>
</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd><ul>
<li>Incorrect usage of this function can lead to memory leaks or segmentation faults. For example, if the CUDA environment is not set up correctly, the memory allocation, initialization, or deallocation operations may fail unexpectedly.</li>
<li>If the new shape has a smaller size than the old shape, data beyond the new size will be discarded. If the new shape has a larger size, the additional memory will be initialized to zero.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> oldShape = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(oldShape, <span class="keyword">false</span>);</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> newShape = {3, 2};</div>
<div class="line">tensor.setShape(newShape);</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00226">226</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_aefb5c705fc6d224469978cf64ca37e0b_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_aefb5c705fc6d224469978cf64ca37e0b_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_aefb5c705fc6d224469978cf64ca37e0b_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_aefb5c705fc6d224469978cf64ca37e0b_cgraph">
<area shape="rect" title="Sets a new shape for the MappedTensor and adjusts its data and gradient memory accordingly." alt="" coords="5,5,167,48"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#abf8ddc60a224bc676dd0fad40ad2f43b" title="Retrieves the shape of the MappedTensor." alt="" coords="215,5,376,48"/>
<area shape="poly" title=" " alt="" coords="167,24,199,24,199,29,167,29"/>
</map>
</div>

</div>
</div>
<a id="abf8ddc60a224bc676dd0fad40ad2f43b" name="abf8ddc60a224bc676dd0fad40ad2f43b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abf8ddc60a224bc676dd0fad40ad2f43b">&#9670;&#160;</a></span>shape()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classnz_1_1data_1_1_dimension.html">MappedTensor::shape_type</a> nz::data::MappedTensor::shape </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">nodiscard</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Retrieves the shape of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. </p>
<dl class="section return"><dt>Returns</dt><dd>A value of type <code>shape_type</code> (host-to-host) representing the shape of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. The shape is a container that holds the size of each dimension of the tensor.</dd></dl>
<p>This function allows users to obtain the dimensional information of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. The shape provides crucial details about how the elements are organized in the tensor, which is essential for many tensor operations.</p>
<p>The memory management strategy involves returning a copy of the internal shape representation of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. The caller is responsible for managing the memory of the returned <code>shape_type</code> object, but the original shape data within the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> remains intact. No new memory is allocated for the tensor's internal shape data during this call. There is no exception handling mechanism in this function because it is declared <code>noexcept</code>, meaning it will not throw any exceptions under normal circumstances. This function can be used in combination with other functions that require knowledge of the tensor's shape, such as reshaping operations or accessing specific elements based on multi - dimensional indices.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>This function is a const member function, so it can be called on const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> objects.</li>
<li>The <code>[[nodiscard]]</code> attribute indicates that the return value should not be ignored, as the shape information is vital for working with the tensor.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> inputShape = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(inputShape, <span class="keyword">false</span>);</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> tensorShape = tensor.shape();</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00210">210</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>

</div>
</div>
<a id="aa144f9f3b76741e5d3fb3b5df3cc3b42" name="aa144f9f3b76741e5d3fb3b5df3cc3b42"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa144f9f3b76741e5d3fb3b5df3cc3b42">&#9670;&#160;</a></span>size()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">MappedTensor::size_type nz::data::MappedTensor::size </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">nodiscard</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Retrieves the total number of elements in the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. </p>
<dl class="section return"><dt>Returns</dt><dd>A value of type <code>size_type</code> (host-to-host) representing the total number of elements in the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.</dd></dl>
<p>This function is used to obtain the size of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>, which is the product of the dimensions of its shape. It provides a quick way to know the quantity of elements stored in the tensor.</p>
<p>The memory management strategy is straightforward. No new memory is allocated or freed during this function call. It simply returns the pre - calculated size of the tensor. There is no exception handling mechanism in this function because it is declared <code>noexcept</code>, meaning it will not throw any exceptions under normal circumstances. This function can be used in various scenarios, such as loop iterations over all elements of the tensor or to allocate appropriate memory when transferring data to another structure.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>This function is a const member function, so it can be called on const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> objects.</li>
<li>The <code>[[nodiscard]]</code> attribute indicates that the return value should not be ignored, as it gives important information about the size of the tensor.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">false</span>);</div>
<div class="line">nz::data::MappedTensor::size_type tensorSize = tensor.size();</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00206">206</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>

</div>
</div>
<a id="afabf30bc35435f1101a61afa77b026ad" name="afabf30bc35435f1101a61afa77b026ad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afabf30bc35435f1101a61afa77b026ad">&#9670;&#160;</a></span>sum() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">MappedTensor::value_type nz::data::MappedTensor::sum </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">nodiscard</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Calculate the sum of all elements in the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. </p>
<dl class="section return"><dt>Returns</dt><dd>The sum of all elements in the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> as a value of type <code>MappedTensor::value_type</code>.</dd></dl>
<p>This function computes the sum of all elements within the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It utilizes CUDA parallel processing to perform the summation efficiently. First, it determines the block and grid dimensions for the CUDA kernel. Then, it allocates pinned host memory for storing the intermediate results using <code>cudaMallocHost</code>. The <code><a class="el" href="namespacenz_1_1krnl.html#a1ae846a65c2f5b83cd1b9fc61b877854" title="Kernel function to perform element-wise summation of two arrays.">krnl::Summation</a></code> CUDA kernel is launched to calculate partial sums on the device. After the kernel execution, the function synchronizes the device using <code>cudaDeviceSynchronize</code> to ensure that all operations are completed. Finally, it sums up the partial results on the host, frees the allocated pinned host memory, and returns the total sum.</p>
<p>Memory management:</p><ul>
<li>Pinned host memory is allocated for <code>dData</code> using <code>cudaMallocHost</code> and freed using <code>cudaFreeHost</code>.</li>
</ul>
<p>Exception handling:</p><ul>
<li>The <code>CHECK</code> macro is used to handle CUDA API errors. If any CUDA API call fails, the <code>CHECK</code> macro will throw an exception, causing the function to terminate.</li>
</ul>
<p>Relationship with other components:</p><ul>
<li>This function relies on the <code><a class="el" href="namespacenz_1_1krnl.html#a1ae846a65c2f5b83cd1b9fc61b877854" title="Kernel function to perform element-wise summation of two arrays.">krnl::Summation</a></code> CUDA kernel to perform partial sums on the device.</li>
<li>It also depends on the <code>CHECK</code> macro to handle CUDA API errors and <code>cudaDeviceSynchronize</code> for device synchronization.</li>
</ul>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">[Exception</td><td>type thrown by CHECK macro] If there are CUDA API errors during memory allocation, kernel execution, or memory synchronization.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The time complexity of this function is approximately O(n), where n is the number of elements in the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> (<code>_size</code>). The CUDA kernel parallelizes the partial sum calculation, and the final sum on the host is a linear operation over the number of grid blocks.</li>
<li>Ensure that the CUDA device is properly initialized before calling this function.</li>
<li>Pinned host memory allocation may have limitations, so be aware of potential memory constraints.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> mapped_tensor({2, 3}, <span class="keyword">true</span>);</div>
<div class="line"><span class="comment">// Assume mapped_tensor is filled with some values</span></div>
<div class="line">nz::data::MappedTensor::value_type sum_result = mapped_tensor.<a class="code hl_function" href="#afabf30bc35435f1101a61afa77b026ad">sum</a>();</div>
<div class="line">```</div>
<div class="ttc" id="aclassnz_1_1data_1_1_mapped_tensor_html_afabf30bc35435f1101a61afa77b026ad"><div class="ttname"><a href="#afabf30bc35435f1101a61afa77b026ad">nz::data::MappedTensor::sum</a></div><div class="ttdeci">value_type sum() const</div><div class="ttdoc">Calculate the sum of all elements in the MappedTensor.</div><div class="ttdef"><b>Definition</b> <a href="_mapped_tensor_8cu_source.html#l00510">MappedTensor.cu:510</a></div></div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00510">510</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_afabf30bc35435f1101a61afa77b026ad_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_afabf30bc35435f1101a61afa77b026ad_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_afabf30bc35435f1101a61afa77b026ad_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_afabf30bc35435f1101a61afa77b026ad_cgraph">
<area shape="rect" title="Calculate the sum of all elements in the MappedTensor." alt="" coords="5,97,200,124"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab6803232b9c08d9282b16322a6c7b8a9" title="Frees the pinned host memory pointed to by the given pointer." alt="" coords="248,5,433,48"/>
<area shape="poly" title=" " alt="" coords="142,94,262,51,264,56,144,99"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#abe439fa00c0bd369c0b2345b095ed5af" title="Synchronizes host thread with completion events for a specific data object." alt="" coords="481,27,666,69"/>
<area shape="poly" title=" " alt="" coords="199,95,465,60,466,65,200,100"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="481,115,666,157"/>
<area shape="poly" title=" " alt="" coords="200,113,466,128,465,133,200,119"/>
<area shape="rect" href="namespacenz_1_1krnl.html#a1ae846a65c2f5b83cd1b9fc61b877854" title="Kernel function to perform element&#45;wise summation of two arrays." alt="" coords="271,173,410,200"/>
<area shape="poly" title=" " alt="" coords="148,122,282,166,281,171,146,127"/>
<area shape="poly" title=" " alt="" coords="434,33,466,35,465,41,433,38"/>
<area shape="poly" title=" " alt="" coords="405,170,465,157,466,162,406,175"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a46ce59b45de432842454aadf00b93791" title="Asynchronously submits a CUDA kernel with stream&#45;ordered dependency management." alt="" coords="481,181,666,224"/>
<area shape="poly" title=" " alt="" coords="410,189,466,193,465,198,409,194"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a1de1cf3aadea137faf90a2f9b4b7abe2" title="Acquires CUDA stream from pool using round&#45;robin scheduling." alt="" coords="714,148,900,191"/>
<area shape="poly" title=" " alt="" coords="666,187,698,182,699,187,667,192"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#adb1078a67c6e38932d7d58c2adb05ec0" title="Synchronizes CUDA stream execution until data writes complete." alt="" coords="714,215,900,257"/>
<area shape="poly" title=" " alt="" coords="667,213,699,218,698,223,666,219"/>
</map>
</div>

</div>
</div>
<a id="a75956c8f5cfc2ea1e7e7efe90e13c9c2" name="a75956c8f5cfc2ea1e7e7efe90e13c9c2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a75956c8f5cfc2ea1e7e7efe90e13c9c2">&#9670;&#160;</a></span>sum() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">MappedTensor::value_type nz::data::MappedTensor::sum </td>
          <td>(</td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>batch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>channel</em></span>&#160;) const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">nodiscard</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Calculate the sum of elements in a specific batch and channel of a <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">batch</td><td>The index of the batch. Memory flow: host-to-host (used for index calculation on the host side). </td></tr>
    <tr><td class="paramname">channel</td><td>The index of the channel. Memory flow: host-to-host (used for index calculation on the host side).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The sum of elements in the specified batch and channel of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>.</dd></dl>
<p>This function first validates the provided <code>batch</code> and <code>channel</code> indices. If they are out of the valid range of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>'s shape, it throws a <code>std::invalid_argument</code> exception. Then, it calculates the size of the region to be summed. It allocates pinned host memory for intermediate results using <code>cudaMallocHost</code>. After that, it determines the offset in the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>'s data based on the <code>batch</code> and <code>channel</code> indices. The <code><a class="el" href="namespacenz_1_1krnl.html#a1ae846a65c2f5b83cd1b9fc61b877854" title="Kernel function to perform element-wise summation of two arrays.">krnl::Summation</a></code> kernel is launched to perform the partial summation. Finally, it sums up all the intermediate results on the host, frees the allocated pinned host memory, and returns the final sum.</p>
<p><b>Memory Management Strategy</b>:</p><ul>
<li>Pinned host memory for <code>dData</code> is allocated using <code>cudaMallocHost</code> and freed using <code><a class="el" href="classnz_1_1cu_strm_1_1_stream_manager.html" title="Centralized CUDA stream and resource management system with automatic dependency tracking.">cuStrm::StreamManager</a>&lt;value_type&gt;::Instance().freeHost</code>.</li>
</ul>
<p><b>Exception Handling Mechanism</b>:</p><ul>
<li>Throws a <code>std::invalid_argument</code> exception if the provided <code>batch</code> or <code>channel</code> indices are out of the valid range of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>'s shape.</li>
<li>CUDA memory allocation operations may return error codes indicating failures. It is assumed that the calling code or the CUDA runtime will handle these errors appropriately.</li>
</ul>
<p><b>Relationship with Other Components</b>:</p><ul>
<li>Depends on the <code>_shape</code> member of the <code><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a></code> class to get the shape information and strides.</li>
<li>Uses the <code><a class="el" href="namespacenz_1_1krnl.html#a1ae846a65c2f5b83cd1b9fc61b877854" title="Kernel function to perform element-wise summation of two arrays.">krnl::Summation</a></code> kernel to perform the partial summation.</li>
<li>Relies on <code><a class="el" href="classnz_1_1cu_strm_1_1_stream_manager.html" title="Centralized CUDA stream and resource management system with automatic dependency tracking.">cuStrm::StreamManager</a>&lt;value_type&gt;::Instance()</code> for freeing the pinned host memory.</li>
</ul>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If the provided <code>batch</code> or <code>channel</code> indices are out of the valid range of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>'s shape.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>Ensure that the provided <code>batch</code> and <code>channel</code> indices are within the valid range of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>'s shape to avoid exceptions.</li>
<li>Be aware of potential CUDA errors during memory allocation operations and handle them appropriately in the calling code.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> mappedTensor; <span class="comment">// Assume MappedTensor is properly initialized</span></div>
<div class="line"><span class="keywordtype">size_t</span> batch = 0;</div>
<div class="line"><span class="keywordtype">size_t</span> channel = 1;</div>
<div class="line">MappedTensor::value_type sumResult = mappedTensor.<a class="code hl_function" href="#afabf30bc35435f1101a61afa77b026ad">sum</a>(batch, channel);</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00525">525</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_a75956c8f5cfc2ea1e7e7efe90e13c9c2_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_a75956c8f5cfc2ea1e7e7efe90e13c9c2_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_a75956c8f5cfc2ea1e7e7efe90e13c9c2_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_a75956c8f5cfc2ea1e7e7efe90e13c9c2_cgraph">
<area shape="rect" title="Calculate the sum of elements in a specific batch and channel of a MappedTensor." alt="" coords="5,123,200,149"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab6803232b9c08d9282b16322a6c7b8a9" title="Frees the pinned host memory pointed to by the given pointer." alt="" coords="248,5,433,48"/>
<area shape="poly" title=" " alt="" coords="131,120,247,64,273,52,275,57,249,69,133,125"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#abe439fa00c0bd369c0b2345b095ed5af" title="Synchronizes host thread with completion events for a specific data object." alt="" coords="481,48,666,91"/>
<area shape="poly" title=" " alt="" coords="199,120,465,82,466,87,200,125"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="481,132,666,175"/>
<area shape="poly" title=" " alt="" coords="200,137,466,147,465,152,200,142"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#aa144f9f3b76741e5d3fb3b5df3cc3b42" title="Retrieves the total number of elements in the MappedTensor." alt="" coords="260,173,421,216"/>
<area shape="poly" title=" " alt="" coords="160,147,245,168,244,174,159,152"/>
<area shape="rect" href="namespacenz_1_1krnl.html#a1ae846a65c2f5b83cd1b9fc61b877854" title="Kernel function to perform element&#45;wise summation of two arrays." alt="" coords="271,240,410,267"/>
<area shape="poly" title=" " alt="" coords="123,148,178,186,249,226,265,232,263,237,247,230,175,190,120,152"/>
<area shape="poly" title=" " alt="" coords="434,41,466,47,465,52,433,46"/>
<area shape="poly" title=" " alt="" coords="398,237,432,226,479,204,522,180,525,185,481,209,434,230,400,242"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a46ce59b45de432842454aadf00b93791" title="Asynchronously submits a CUDA kernel with stream&#45;ordered dependency management." alt="" coords="481,232,666,275"/>
<area shape="poly" title=" " alt="" coords="410,251,465,251,465,256,410,256"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a1de1cf3aadea137faf90a2f9b4b7abe2" title="Acquires CUDA stream from pool using round&#45;robin scheduling." alt="" coords="714,199,900,241"/>
<area shape="poly" title=" " alt="" coords="666,237,698,233,699,238,667,243"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#adb1078a67c6e38932d7d58c2adb05ec0" title="Synchronizes CUDA stream execution until data writes complete." alt="" coords="714,265,900,308"/>
<area shape="poly" title=" " alt="" coords="667,264,699,269,698,274,666,269"/>
</map>
</div>

</div>
</div>
<a id="a5134b8821da18631dd9a9b9417b0ba5e" name="a5134b8821da18631dd9a9b9417b0ba5e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5134b8821da18631dd9a9b9417b0ba5e">&#9670;&#160;</a></span>sync()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void nz::data::MappedTensor::sync </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Synchronizes the tensor data and its gradient. </p>
<p>This function first calls the <code>syncData</code> method of the <code>cuStrm::streamManagerFP32</code> object, passing the <code>_data</code> member of the <code><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a></code> class. This is to ensure that all CUDA stream write operations on the tensor data are completed by blocking the host. Then it calls the <code>syncGrad</code> method to synchronize the gradient data if gradient computation is required.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">None</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None</dd></dl>
<p>There is no explicit memory allocation or deallocation in this function. Memory management for the <code>_data</code> and <code>_grad</code> data is assumed to be handled elsewhere. The function does not have an explicit exception - handling mechanism. It relies on the <code>cuStrm::streamManagerFP32.syncData</code> method and the <code>syncGrad</code> method to manage any errors during the synchronization process.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The time complexity of this function depends on the time it takes for the CUDA stream write operations on <code>_data</code> and <code>_grad</code> (if applicable) to complete. In the worst - case scenario, if there are long - running write operations, it could take a significant amount of time.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><span class="comment">// Assume MappedTensor is defined and an instance is created</span></div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> mappedTensor;</div>
<div class="line">mappedTensor.<a class="code hl_function" href="#a5134b8821da18631dd9a9b9417b0ba5e">sync</a>();</div>
<div class="line">```</div>
<div class="ttc" id="aclassnz_1_1data_1_1_mapped_tensor_html_a5134b8821da18631dd9a9b9417b0ba5e"><div class="ttname"><a href="#a5134b8821da18631dd9a9b9417b0ba5e">nz::data::MappedTensor::sync</a></div><div class="ttdeci">void sync() const</div><div class="ttdoc">Synchronizes the tensor data and its gradient.</div><div class="ttdef"><b>Definition</b> <a href="_mapped_tensor_8cu_source.html#l00590">MappedTensor.cu:590</a></div></div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00590">590</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_a5134b8821da18631dd9a9b9417b0ba5e_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_a5134b8821da18631dd9a9b9417b0ba5e_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_a5134b8821da18631dd9a9b9417b0ba5e_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_a5134b8821da18631dd9a9b9417b0ba5e_cgraph">
<area shape="rect" title="Synchronizes the tensor data and its gradient." alt="" coords="5,39,167,81"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#ae133d08d4505a30c6bd34e4a7a311f9e" title="Synchronizes the tensor data by waiting for all CUDA stream write operations on it to finish." alt="" coords="215,5,376,48"/>
<area shape="poly" title=" " alt="" coords="167,44,199,39,200,45,168,50"/>
<area shape="rect" href="classnz_1_1data_1_1_mapped_tensor.html#af9d1b0fa71f9bb7686cc26ae7b32be8d" title="Synchronizes the gradient data if gradient computation is required." alt="" coords="215,72,376,115"/>
<area shape="poly" title=" " alt="" coords="168,70,200,75,199,81,167,76"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="424,5,609,48"/>
<area shape="poly" title=" " alt="" coords="376,24,408,24,408,29,376,29"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#abe439fa00c0bd369c0b2345b095ed5af" title="Synchronizes host thread with completion events for a specific data object." alt="" coords="424,72,609,115"/>
<area shape="poly" title=" " alt="" coords="369,46,430,64,428,70,367,51"/>
<area shape="poly" title=" " alt="" coords="367,69,428,50,430,56,369,74"/>
<area shape="poly" title=" " alt="" coords="376,91,408,91,408,96,376,96"/>
</map>
</div>

</div>
</div>
<a id="ae133d08d4505a30c6bd34e4a7a311f9e" name="ae133d08d4505a30c6bd34e4a7a311f9e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae133d08d4505a30c6bd34e4a7a311f9e">&#9670;&#160;</a></span>syncData()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void nz::data::MappedTensor::syncData </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Synchronizes the tensor data by waiting for all CUDA stream write operations on it to finish. </p>
<p>This function invokes the <code>syncData</code> method of the <code>cuStrm::streamManagerFP32</code> object, passing the <code>_data</code> member of the <code><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a></code> class. It blocks the host until all CUDA stream write operations on the <code>_data</code> are completed.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">None</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None</dd></dl>
<p>Memory management for the <code>_data</code> is assumed to be handled elsewhere. There is no memory allocation or deallocation within this function. This function does not have an explicit exception - handling mechanism. It depends on the <code>cuStrm::streamManagerFP32.syncData</code> method to handle any errors during the synchronization process.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The time complexity of this function depends on the time taken for the CUDA stream write operations on <code>_data</code> to complete. In the worst - case scenario, it could take a long time if there are long - running write operations.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><span class="comment">// Assume MappedTensor is defined and an instance is created</span></div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> mappedTensor;</div>
<div class="line">mappedTensor.<a class="code hl_function" href="#ae133d08d4505a30c6bd34e4a7a311f9e">syncData</a>();</div>
<div class="line">```</div>
<div class="ttc" id="aclassnz_1_1data_1_1_mapped_tensor_html_ae133d08d4505a30c6bd34e4a7a311f9e"><div class="ttname"><a href="#ae133d08d4505a30c6bd34e4a7a311f9e">nz::data::MappedTensor::syncData</a></div><div class="ttdeci">void syncData() const</div><div class="ttdoc">Synchronizes the tensor data by waiting for all CUDA stream write operations on it to finish.</div><div class="ttdef"><b>Definition</b> <a href="_mapped_tensor_8cu_source.html#l00586">MappedTensor.cu:586</a></div></div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00586">586</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_ae133d08d4505a30c6bd34e4a7a311f9e_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_ae133d08d4505a30c6bd34e4a7a311f9e_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_ae133d08d4505a30c6bd34e4a7a311f9e_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_ae133d08d4505a30c6bd34e4a7a311f9e_cgraph">
<area shape="rect" title="Synchronizes the tensor data by waiting for all CUDA stream write operations on it to finish." alt="" coords="5,39,167,81"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="215,5,400,48"/>
<area shape="poly" title=" " alt="" coords="166,45,199,40,200,46,167,51"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#abe439fa00c0bd369c0b2345b095ed5af" title="Synchronizes host thread with completion events for a specific data object." alt="" coords="215,72,400,115"/>
<area shape="poly" title=" " alt="" coords="167,69,200,74,199,80,166,75"/>
</map>
</div>

</div>
</div>
<a id="af9d1b0fa71f9bb7686cc26ae7b32be8d" name="af9d1b0fa71f9bb7686cc26ae7b32be8d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af9d1b0fa71f9bb7686cc26ae7b32be8d">&#9670;&#160;</a></span>syncGrad()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void nz::data::MappedTensor::syncGrad </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Synchronizes the gradient data if gradient computation is required. </p>
<p>This function checks the <code>_requires_grad</code> flag. If the flag is set to <code>true</code>, it calls the <code>syncData</code> method of the <code>cuStrm::streamManagerFP32</code> object, passing the <code>_grad</code> data. The <code>syncData</code> method blocks the host until all CUDA stream write operations on the input data are completed.</p>
<dl class="section return"><dt>Returns</dt><dd>None</dd></dl>
<p>There is no explicit memory allocation or deallocation in this function. Memory management for the <code>_grad</code> data is assumed to be handled elsewhere. The function does not have an explicit exception - handling mechanism. It relies on the <code>cuStrm::streamManagerFP32.syncData</code> method to manage any errors during the synchronization process.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The time complexity of this function depends on the time it takes for the CUDA stream write operations on <code>_grad</code> to complete. In the worst - case scenario, if there are long - running write operations, it could take a significant amount of time.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><span class="comment">// Assume MappedTensor is defined and an instance is created</span></div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> mappedTensor;</div>
<div class="line">mappedTensor.<a class="code hl_function" href="#af9d1b0fa71f9bb7686cc26ae7b32be8d">syncGrad</a>();</div>
<div class="line">```</div>
<div class="ttc" id="aclassnz_1_1data_1_1_mapped_tensor_html_af9d1b0fa71f9bb7686cc26ae7b32be8d"><div class="ttname"><a href="#af9d1b0fa71f9bb7686cc26ae7b32be8d">nz::data::MappedTensor::syncGrad</a></div><div class="ttdeci">void syncGrad() const</div><div class="ttdoc">Synchronizes the gradient data if gradient computation is required.</div><div class="ttdef"><b>Definition</b> <a href="_mapped_tensor_8cu_source.html#l00580">MappedTensor.cu:580</a></div></div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00580">580</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_af9d1b0fa71f9bb7686cc26ae7b32be8d_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_af9d1b0fa71f9bb7686cc26ae7b32be8d_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_af9d1b0fa71f9bb7686cc26ae7b32be8d_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_af9d1b0fa71f9bb7686cc26ae7b32be8d_cgraph">
<area shape="rect" title="Synchronizes the gradient data if gradient computation is required." alt="" coords="5,39,167,81"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="215,5,400,48"/>
<area shape="poly" title=" " alt="" coords="166,45,199,40,200,46,167,51"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#abe439fa00c0bd369c0b2345b095ed5af" title="Synchronizes host thread with completion events for a specific data object." alt="" coords="215,72,400,115"/>
<area shape="poly" title=" " alt="" coords="167,69,200,74,199,80,166,75"/>
</map>
</div>

</div>
</div>
<a id="afae0e7076636cd708762f57f10f03952" name="afae0e7076636cd708762f57f10f03952"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afae0e7076636cd708762f57f10f03952">&#9670;&#160;</a></span>transpose()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void nz::data::MappedTensor::transpose </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Transpose the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> and its gradients (if required). </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">None</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None</dd></dl>
<p>This function transposes the data of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. If the tensor requires gradients, it also transposes the gradients. It first calculates the CUDA grid and block dimensions based on the tensor's shape and a predefined tile size. Then, it allocates host memory for a temporary buffer, invokes the <code><a class="el" href="namespacenz_1_1krnl.html#afe3f38f788c735b7eb718443eb0fd094" title="Kernel function to transpose a matrix on the GPU.">krnl::Transpose</a></code> kernel to perform the transpose operation, and synchronizes the device. After that, it frees the original data memory and assigns the temporary buffer as the new data. If gradients are required, the same process is repeated for the gradients. Finally, it swaps the shape dimensions of the tensor.</p>
<p>Memory management: The function allocates host memory for temporary buffers using <code>cudaMallocHost</code> and frees the original data and gradient memory using <code>cudaFreeHost</code>. Exception handling: The <code>CHECK</code> macro is used to handle CUDA errors. If a CUDA operation fails, the <code>CHECK</code> macro will throw an appropriate exception. Relationship with other components: This function depends on the <code><a class="el" href="namespacenz_1_1krnl.html#afe3f38f788c735b7eb718443eb0fd094" title="Kernel function to transpose a matrix on the GPU.">krnl::Transpose</a></code> kernel to perform the actual transpose operation. It also interacts with the CUDA memory management functions.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">[Exception</td><td>type thrown by CHECK macro] [Thrown when a CUDA operation fails]</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The time complexity of this function is O(n), where n is the number of elements in the tensor (<code>_size</code>), as it needs to process each element during the transpose operation.</li>
<li>Ensure that the CUDA environment is properly configured and the <code><a class="el" href="namespacenz_1_1krnl.html#afe3f38f788c735b7eb718443eb0fd094" title="Kernel function to transpose a matrix on the GPU.">krnl::Transpose</a></code> kernel is correctly implemented before calling this function.</li>
<li>The <code>TILE_SIZE</code> must be properly defined for the CUDA kernel to work correctly.</li>
</ul>
</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd><ul>
<li>If the CUDA device runs out of memory during the memory allocation, the function will fail.</li>
<li>Incorrect implementation of the <code><a class="el" href="namespacenz_1_1krnl.html#afe3f38f788c735b7eb718443eb0fd094" title="Kernel function to transpose a matrix on the GPU.">krnl::Transpose</a></code> kernel may lead to incorrect transpose results.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">true</span>);</div>
<div class="line">tensor.transpose();</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00414">414</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1data_1_1_mapped_tensor_afae0e7076636cd708762f57f10f03952_cgraph.png" border="0" usemap="#aclassnz_1_1data_1_1_mapped_tensor_afae0e7076636cd708762f57f10f03952_cgraph" alt=""/></div>
<map name="aclassnz_1_1data_1_1_mapped_tensor_afae0e7076636cd708762f57f10f03952_cgraph" id="aclassnz_1_1data_1_1_mapped_tensor_afae0e7076636cd708762f57f10f03952_cgraph">
<area shape="rect" title="Transpose the MappedTensor and its gradients (if required)." alt="" coords="5,68,167,111"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab6803232b9c08d9282b16322a6c7b8a9" title="Frees the pinned host memory pointed to by the given pointer." alt="" coords="215,8,400,51"/>
<area shape="poly" title=" " alt="" coords="166,65,211,53,212,58,168,70"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="448,72,633,115"/>
<area shape="poly" title=" " alt="" coords="167,87,433,90,433,95,167,93"/>
<area shape="rect" href="namespacenz_1_1krnl.html#afe3f38f788c735b7eb718443eb0fd094" title="Kernel function to transpose a matrix on the GPU." alt="" coords="241,127,374,153"/>
<area shape="poly" title=" " alt="" coords="167,105,232,120,230,125,166,110"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#abe439fa00c0bd369c0b2345b095ed5af" title="Synchronizes host thread with completion events for a specific data object." alt="" coords="448,5,633,48"/>
<area shape="poly" title=" " alt="" coords="400,26,432,25,432,31,401,31"/>
<area shape="poly" title=" " alt="" coords="374,124,432,112,433,117,375,129"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a46ce59b45de432842454aadf00b93791" title="Asynchronously submits a CUDA kernel with stream&#45;ordered dependency management." alt="" coords="448,139,633,181"/>
<area shape="poly" title=" " alt="" coords="374,143,433,148,432,153,374,148"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a1de1cf3aadea137faf90a2f9b4b7abe2" title="Acquires CUDA stream from pool using round&#45;robin scheduling." alt="" coords="681,105,867,148"/>
<area shape="poly" title=" " alt="" coords="633,144,665,139,666,145,634,149"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#adb1078a67c6e38932d7d58c2adb05ec0" title="Synchronizes CUDA stream execution until data writes complete." alt="" coords="681,172,867,215"/>
<area shape="poly" title=" " alt="" coords="634,171,666,175,665,181,633,176"/>
</map>
</div>

</div>
</div>
<h2 class="groupheader">Friends And Related Symbol Documentation</h2>
<a id="a1cd02ca3d7e7592ba6658b333ff207b4" name="a1cd02ca3d7e7592ba6658b333ff207b4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1cd02ca3d7e7592ba6658b333ff207b4">&#9670;&#160;</a></span>operator&lt;&lt;</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">DL_API std::ostream &amp; operator&lt;&lt; </td>
          <td>(</td>
          <td class="paramtype">std::ostream &amp;</td>          <td class="paramname"><span class="paramname"><em>os</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">friend</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Overload the &lt;&lt; operator to print a <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object to an output stream. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">os</td><td>An output stream (host-to-host) where the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> data and gradient will be printed. </td></tr>
    <tr><td class="paramname">tensor</td><td>A constant reference (host-to-host) to the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object to be printed.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A reference to the output stream <code>os</code> after printing the tensor data and possibly its gradient.</dd></dl>
<p>This function provides a convenient way to print a <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object using the &lt;&lt; operator. It first calls the <code>print</code> method of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> to print the tensor's data. If the tensor requires gradients, it then prints a header "Gradient: " followed by the gradient data using the <code>printGrad</code> method.</p>
<p>Memory management: The function does not allocate or deallocate any memory. It relies on the <code>print</code> and <code>printGrad</code> methods of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>, which also do not perform memory allocation. Exception handling: If the tensor requires gradients and an exception occurs during the <code>printGrad</code> call (e.g., due to an invalid state of the output stream or incorrect internal data), the exception will be propagated. If the tensor does not require gradients, the <code>printGrad</code> call is skipped, and no exception related to gradient printing will be thrown. Relationship with other components: This function is related to the data presentation component of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It integrates the <code>print</code> and <code>printGrad</code> methods to provide a unified way of printing the tensor and its gradient.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>Propagated from the <code>printGrad</code> method if the tensor requires gradients and there is an issue with gradient printing.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The overall time complexity of this function is O(m * n) if the tensor does not require gradients and O(2 * m * n) if it does, where m is the number of rows (<code>_shape[0]</code>) and n is the number of columns (<code>_shape[1]</code>) of the tensor, as it iterates over the tensor data and possibly the gradient data.</li>
<li>Ensure that the output stream <code>os</code> is in a valid state before calling this function.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">true</span>);</div>
<div class="line">tensor.dataInject({1, 2, 3, 4, 5, 6}, <span class="keyword">false</span>);</div>
<div class="line">tensor.dataInject({7, 8, 9, 10, 11, 12}, <span class="keyword">true</span>);</div>
<div class="line">std::cout &lt;&lt; tensor;</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00045">45</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>

</div>
</div>
<a id="abaacd16c39a6f16fde32336c7696c94f" name="abaacd16c39a6f16fde32336c7696c94f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abaacd16c39a6f16fde32336c7696c94f">&#9670;&#160;</a></span>operator&gt;&gt;</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">DL_API std::istream &amp; operator&gt;&gt; </td>
          <td>(</td>
          <td class="paramtype">std::istream &amp;</td>          <td class="paramname"><span class="paramname"><em>is</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnz_1_1data_1_1_mapped_tensor.html">MappedTensor</a> &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">friend</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Overload the &gt;&gt; operator to read data from an input stream into a <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">is</td><td>An input stream (host-to-host) from which the data will be read. </td></tr>
    <tr><td class="paramname">tensor</td><td>A reference (host-to-host) to the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object where the data will be stored.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A reference to the input stream <code>is</code> after the reading operation.</dd></dl>
<p>This function provides a convenient way to populate a <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> object with data from an input stream. It iterates through the elements of the tensor and reads values from the input stream one by one, until either all elements of the tensor have been filled or the input stream fails to provide more data.</p>
<p>Memory management: The function does not allocate or deallocate any memory. It assumes that the <code>_data</code> array of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a> has already been allocated with the appropriate size (<code>_size</code>). Exception handling: If the input stream fails to provide data (e.g., due to end-of-file or an invalid input format), the loop will terminate, and the function will return the input stream in its current state. No exceptions are thrown by this function itself, but the <code>&gt;&gt;</code> operator on the input stream may throw exceptions depending on its implementation. Relationship with other components: This function is related to the data input component of the <a class="el" href="classnz_1_1data_1_1_mapped_tensor.html" title="A class for representing multidimensional arrays in CUDA zero-copy memory, providing host-accessible ...">MappedTensor</a>. It integrates with the standard input stream to allow easy data population.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The time complexity of this function is O(n), where n is the size of the tensor (<code>_size</code>), as it iterates through each element of the tensor once.</li>
<li>Ensure that the input stream contains valid data in the correct format to avoid unexpected behavior.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_dimension.html">nz::data::MappedTensor::shape_type</a> <a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a> = {2, 3};</div>
<div class="line"><a class="code hl_class" href="classnz_1_1data_1_1_mapped_tensor.html">nz::data::MappedTensor</a> tensor(<a class="code hl_function" href="#abf8ddc60a224bc676dd0fad40ad2f43b">shape</a>, <span class="keyword">false</span>);</div>
<div class="line">std::istringstream iss(<span class="stringliteral">&quot;1 2 3 4 5 6&quot;</span>);</div>
<div class="line">iss &gt;&gt; tensor;</div>
<div class="line">```</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="_mapped_tensor_8cu_source.html#l00081">81</a> of file <a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>D:/Users/Mgepahmge/Documents/C Program/NeuZephyr/include/NeuZephyr/<a class="el" href="_mapped_tensor_8cuh_source.html">MappedTensor.cuh</a></li>
<li>D:/Users/Mgepahmge/Documents/C Program/NeuZephyr/src/<a class="el" href="_mapped_tensor_8cu_source.html">MappedTensor.cu</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.12.0
</small></address>
</div><!-- doc-content -->
</body>
</html>
