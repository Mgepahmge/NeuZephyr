<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.12.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NeuZephyr: nz::nodes::calc::ExpandNode Class Reference</title>
<link rel="icon" href="NZ_logo2.png" type="image/x-icon" />
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="NZ_logo2.png"/></td>
  <td id="projectalign">
   <div id="projectname">NeuZephyr
   </div>
   <div id="projectbrief">Simple DL Framework</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.12.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>Class&#160;List</span></a></li>
      <li><a href="classes.html"><span>Class&#160;Index</span></a></li>
      <li><a href="inherits.html"><span>Class&#160;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&#160;Members</span></a></li>
    </ul>
  </div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){ initResizable(false); });
/* @license-end */
</script>
<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>nz</b></li><li class="navelem"><a class="el" href="namespacenz_1_1nodes.html">nodes</a></li><li class="navelem"><a class="el" href="namespacenz_1_1nodes_1_1calc.html">calc</a></li><li class="navelem"><a class="el" href="classnz_1_1nodes_1_1calc_1_1_expand_node.html">ExpandNode</a></li>  </ul>
</div>
</div><!-- top -->
<div id="doc-content">
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classnz_1_1nodes_1_1calc_1_1_expand_node-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">nz::nodes::calc::ExpandNode Class Reference</div></div>
</div><!--header-->
<div class="contents">

<p>Expands tensors with batch size 1 to arbitrary batch dimensions through data replication.  
 <a href="#details">More...</a></p>
<div class="dynheader">
Inheritance diagram for nz::nodes::calc::ExpandNode:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1nodes_1_1calc_1_1_expand_node__inherit__graph.png" border="0" usemap="#anz_1_1nodes_1_1calc_1_1_expand_node_inherit__map" alt="Inheritance graph"/></div>
<map name="anz_1_1nodes_1_1calc_1_1_expand_node_inherit__map" id="anz_1_1nodes_1_1calc_1_1_expand_node_inherit__map">
<area shape="rect" title="Expands tensors with batch size 1 to arbitrary batch dimensions through data replication." alt="" coords="5,80,199,107"/>
<area shape="rect" href="classnz_1_1nodes_1_1_node.html" title="Base class for nodes in a neural network or computational graph." alt="" coords="43,5,161,32"/>
<area shape="poly" title=" " alt="" coords="105,48,105,80,99,80,99,48"/>
</map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for nz::nodes::calc::ExpandNode:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1nodes_1_1calc_1_1_expand_node__coll__graph.png" border="0" usemap="#anz_1_1nodes_1_1calc_1_1_expand_node_coll__map" alt="Collaboration graph"/></div>
<map name="anz_1_1nodes_1_1calc_1_1_expand_node_coll__map" id="anz_1_1nodes_1_1calc_1_1_expand_node_coll__map">
<area shape="rect" title="Expands tensors with batch size 1 to arbitrary batch dimensions through data replication." alt="" coords="5,80,199,107"/>
<area shape="rect" href="classnz_1_1nodes_1_1_node.html" title="Base class for nodes in a neural network or computational graph." alt="" coords="43,5,161,32"/>
<area shape="poly" title=" " alt="" coords="105,48,105,80,99,80,99,48"/>
</map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a78874b46ee54a4a11f5d0ae2f79409c0" id="r_a78874b46ee54a4a11f5d0ae2f79409c0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a78874b46ee54a4a11f5d0ae2f79409c0">ExpandNode</a> (<a class="el" href="classnz_1_1nodes_1_1_node.html">Node</a> *input, Tensor::size_type newBatch)</td></tr>
<tr class="memdesc:a78874b46ee54a4a11f5d0ae2f79409c0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructs an <a class="el" href="classnz_1_1nodes_1_1calc_1_1_expand_node.html" title="Expands tensors with batch size 1 to arbitrary batch dimensions through data replication.">ExpandNode</a> object.  <br /></td></tr>
<tr class="separator:a78874b46ee54a4a11f5d0ae2f79409c0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a883419ee48eca406c2deb6939aa1a546" id="r_a883419ee48eca406c2deb6939aa1a546"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a883419ee48eca406c2deb6939aa1a546">forward</a> () override</td></tr>
<tr class="memdesc:a883419ee48eca406c2deb6939aa1a546"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs the forward propagation for the <a class="el" href="classnz_1_1nodes_1_1calc_1_1_expand_node.html" title="Expands tensors with batch size 1 to arbitrary batch dimensions through data replication.">ExpandNode</a>.  <br /></td></tr>
<tr class="separator:a883419ee48eca406c2deb6939aa1a546"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aac692ee5bf79df2148b9595030b46585" id="r_aac692ee5bf79df2148b9595030b46585"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aac692ee5bf79df2148b9595030b46585">backward</a> () override</td></tr>
<tr class="memdesc:aac692ee5bf79df2148b9595030b46585"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs the backward propagation for the <a class="el" href="classnz_1_1nodes_1_1calc_1_1_expand_node.html" title="Expands tensors with batch size 1 to arbitrary batch dimensions through data replication.">ExpandNode</a>.  <br /></td></tr>
<tr class="separator:aac692ee5bf79df2148b9595030b46585"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classnz_1_1nodes_1_1_node"><td colspan="2" onclick="javascript:dynsection.toggleInherit('pub_methods_classnz_1_1nodes_1_1_node')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classnz_1_1nodes_1_1_node.html">nz::nodes::Node</a></td></tr>
<tr class="memitem:a687ee9c34eb61f8f28caa201ca42696e inherit pub_methods_classnz_1_1nodes_1_1_node" id="r_a687ee9c34eb61f8f28caa201ca42696e"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnz_1_1nodes_1_1_node.html#a687ee9c34eb61f8f28caa201ca42696e">print</a> (std::ostream &amp;os) const</td></tr>
<tr class="memdesc:a687ee9c34eb61f8f28caa201ca42696e inherit pub_methods_classnz_1_1nodes_1_1_node"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prints the type, data, and gradient of the node.  <br /></td></tr>
<tr class="separator:a687ee9c34eb61f8f28caa201ca42696e inherit pub_methods_classnz_1_1nodes_1_1_node"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9b85913e12422bb4ac2fff483427bb47 inherit pub_methods_classnz_1_1nodes_1_1_node" id="r_a9b85913e12422bb4ac2fff483427bb47"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnz_1_1nodes_1_1_node.html#a9b85913e12422bb4ac2fff483427bb47">dataInject</a> (Tensor::value_type *data, bool grad=false) const</td></tr>
<tr class="memdesc:a9b85913e12422bb4ac2fff483427bb47 inherit pub_methods_classnz_1_1nodes_1_1_node"><td class="mdescLeft">&#160;</td><td class="mdescRight">Injects data into a relevant tensor object, optionally setting its gradient requirement.  <br /></td></tr>
<tr class="separator:a9b85913e12422bb4ac2fff483427bb47 inherit pub_methods_classnz_1_1nodes_1_1_node"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a609f1730085dd1d31e0ddcbbae48a065 inherit pub_methods_classnz_1_1nodes_1_1_node" id="r_a609f1730085dd1d31e0ddcbbae48a065"><td class="memTemplParams" colspan="2">template&lt;typename Iterator &gt; </td></tr>
<tr class="memitem:a609f1730085dd1d31e0ddcbbae48a065 inherit pub_methods_classnz_1_1nodes_1_1_node"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classnz_1_1nodes_1_1_node.html#a609f1730085dd1d31e0ddcbbae48a065">dataInject</a> (Iterator begin, Iterator end, const bool grad=false) const</td></tr>
<tr class="memdesc:a609f1730085dd1d31e0ddcbbae48a065 inherit pub_methods_classnz_1_1nodes_1_1_node"><td class="mdescLeft">&#160;</td><td class="mdescRight">Injects data from an iterator range into the output tensor of the InputNode, optionally setting its gradient requirement.  <br /></td></tr>
<tr class="separator:a609f1730085dd1d31e0ddcbbae48a065 inherit pub_methods_classnz_1_1nodes_1_1_node"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af8b4bab3271df92ca1f0914f7a97b1e8 inherit pub_methods_classnz_1_1nodes_1_1_node" id="r_af8b4bab3271df92ca1f0914f7a97b1e8"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnz_1_1nodes_1_1_node.html#af8b4bab3271df92ca1f0914f7a97b1e8">dataInject</a> (const std::initializer_list&lt; Tensor::value_type &gt; &amp;data, bool grad=false) const</td></tr>
<tr class="memdesc:af8b4bab3271df92ca1f0914f7a97b1e8 inherit pub_methods_classnz_1_1nodes_1_1_node"><td class="mdescLeft">&#160;</td><td class="mdescRight">Injects data from a std::initializer_list into the output tensor of the <a class="el" href="classnz_1_1nodes_1_1_node.html" title="Base class for nodes in a neural network or computational graph.">Node</a>, optionally setting its gradient requirement.  <br /></td></tr>
<tr class="separator:af8b4bab3271df92ca1f0914f7a97b1e8 inherit pub_methods_classnz_1_1nodes_1_1_node"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Expands tensors with batch size 1 to arbitrary batch dimensions through data replication. </p>
<p>The <code><a class="el" href="classnz_1_1nodes_1_1calc_1_1_expand_node.html" title="Expands tensors with batch size 1 to arbitrary batch dimensions through data replication.">ExpandNode</a></code> class enables batch dimension expansion by replicating single-instance input data across the batch dimension. This operation is particularly useful for converting single-sample processing networks into batch-processing configurations without modifying core network architecture.</p>
<p>Core operational characteristics:</p><ul>
<li><b>Batch Dimension Expansion</b>: Duplicates input data along batch dimension to create specified batch size.</li>
<li><b>Memory Efficiency</b>: Shares underlying data storage through tensor views where possible.</li>
<li><b>Gradient Aggregation</b>: Implements gradient summation across batch dimension during backward pass.</li>
<li><b>Device Consistency</b>: Maintains computation device context (CPU/GPU) during expansion operations.</li>
<li><b>Input Validation</b>: Enforces pre-condition of batch_size=1 for input tensors.</li>
</ul>
<p>Implementation mechanics:</p><ul>
<li><b>Forward Propagation</b>: Creates tensor view with expanded batch dimensions through broadcasting.</li>
<li><b>Backward Propagation</b>: Accumulates gradients across expanded batch dimension via summation.</li>
<li><b>CUDA Optimization</b>: Leverages CUDA tensor broadcasting for efficient batch replication on GPU.</li>
<li><b>Shape Preservation</b>: Maintains non-batch dimensions identical to input tensor.</li>
</ul>
<p>Common application scenarios:</p><ul>
<li>Converting single-sample inference networks to batch processing mode.</li>
<li>Data augmentation through batch-wise replication of prototype samples.</li>
<li><a class="el" href="classnz_1_1_model.html" title="Base class for constructing neural network models with automatic computation graph management.">Model</a> ensemble techniques requiring multiple copies of base input.</li>
</ul>
<p>Critical operational constraints:</p><ul>
<li><b>Input Batch Requirement</b>: Input tensor must have batch_size=1 (first dimension size=1).</li>
<li><b>Memory Considerations</b>: Creates virtual views rather than physical copies in forward pass.</li>
<li><b>Gradient Scaling</b>: Backward pass gradients are scaled by batch size due to summation aggregation.</li>
<li><b>Device Compatibility</b>: Input tensor and expansion operation must reside on same computation device.</li>
</ul>
<dl class="section warning"><dt>Warning</dt><dd><ul>
<li>Input validation failure occurs if input batch size != 1, throwing runtime_error.</li>
<li>Physical memory consumption increases proportionally with new_batch in backward pass.</li>
</ul>
</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>Actual data replication occurs lazily during memory access operations.</li>
<li>For physical data duplication, combine with CopyNode before <a class="el" href="classnz_1_1nodes_1_1calc_1_1_expand_node.html" title="Expands tensors with batch size 1 to arbitrary batch dimensions through data replication.">ExpandNode</a>.</li>
<li>Gradient computation maintains mathematical equivalence to manual batch duplication.</li>
</ul>
</dd></dl>
<dl class="section see"><dt>See also</dt><dd>RepeatNode For non-batch dimension replication operations </dd>
<dd>
Tensor::expand() Underlying tensor expansion mechanism</dd></dl>
<h3><a class="anchor" id="autotoc_md106"></a>
Usage Example:</h3>
<div class="fragment"><div class="line"><span class="comment">// Create single-sample input node</span></div>
<div class="line">InputNode input({1, 1, 256, 256}, <span class="keyword">true</span>); <span class="comment">// Batch 1, 256x256 image</span></div>
<div class="line"> </div>
<div class="line"><span class="comment">// Expand to batch size 16</span></div>
<div class="line"><a class="code hl_class" href="classnz_1_1nodes_1_1calc_1_1_expand_node.html">ExpandNode</a> expander(&amp;input, 16);</div>
<div class="line">expander.forward();</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Verify expanded shape</span></div>
<div class="line">std::cout &lt;&lt; <span class="stringliteral">&quot;Expanded tensor shape: &quot;</span></div>
<div class="line">          &lt;&lt; expander.output-&gt;shape() &lt;&lt; std::endl; <span class="comment">// [16, 1, 256, 256]</span></div>
<div class="line"> </div>
<div class="line"><span class="comment">// Backward pass handling</span></div>
<div class="line">expander.backward();</div>
<div class="ttc" id="aclassnz_1_1nodes_1_1calc_1_1_expand_node_html"><div class="ttname"><a href="classnz_1_1nodes_1_1calc_1_1_expand_node.html">nz::nodes::calc::ExpandNode</a></div><div class="ttdoc">Expands tensors with batch size 1 to arbitrary batch dimensions through data replication.</div><div class="ttdef"><b>Definition</b> <a href="_nodes_8cuh_source.html#l03536">Nodes.cuh:3536</a></div></div>
</div><!-- fragment --><dl class="section author"><dt>Author</dt><dd>Mgepahmge (<a href="https://github.com/Mgepahmge">https://github.com/Mgepahmge</a>)</dd></dl>
<dl class="section date"><dt>Date</dt><dd>2023/10/16 </dd></dl>

<p class="definition">Definition at line <a class="el" href="_nodes_8cuh_source.html#l03536">3536</a> of file <a class="el" href="_nodes_8cuh_source.html">Nodes.cuh</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a78874b46ee54a4a11f5d0ae2f79409c0" name="a78874b46ee54a4a11f5d0ae2f79409c0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a78874b46ee54a4a11f5d0ae2f79409c0">&#9670;&#160;</a></span>ExpandNode()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">nz::nodes::calc::ExpandNode::ExpandNode </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnz_1_1nodes_1_1_node.html">Node</a> *</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Tensor::size_type</td>          <td class="paramname"><span class="paramname"><em>newBatch</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Constructs an <a class="el" href="classnz_1_1nodes_1_1calc_1_1_expand_node.html" title="Expands tensors with batch size 1 to arbitrary batch dimensions through data replication.">ExpandNode</a> object. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A pointer to the input <a class="el" href="classnz_1_1nodes_1_1_node.html" title="Base class for nodes in a neural network or computational graph.">Node</a>. Memory location: host. </td></tr>
    <tr><td class="paramname">newBatch</td><td>The new batch size for the output tensor. Memory location: host.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None</dd></dl>
<p>This function constructs an <a class="el" href="classnz_1_1nodes_1_1calc_1_1_expand_node.html" title="Expands tensors with batch size 1 to arbitrary batch dimensions through data replication.">ExpandNode</a> object. It first checks if the batch size of the input tensor is 1. If not, it throws an <code>std::invalid_argument</code> exception. Then, it adds the input node to the list of inputs, creates a new output tensor with the specified new batch size and the same dimensions as the input tensor except for the batch size, and sets the node type to "Expand".</p>
<p>Memory management strategy: The function allocates memory for the output tensor using <code>std::make_shared</code>. The memory will be automatically managed by the smart pointer and freed when it goes out of scope. Exception handling mechanism: If the batch size of the input tensor is not 1, the function throws an <code>std::invalid_argument</code> exception with an appropriate error message.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If the input tensor's batch size is not 1.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>Ensure that the input node pointer is valid and points to a properly initialized node.</li>
<li>The new batch size should be a valid non - negative value.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1nodes_1_1_node.html">Node</a>* inputNode = <span class="keyword">new</span> <a class="code hl_class" href="classnz_1_1nodes_1_1_node.html">Node</a>();</div>
<div class="line">Tensor::size_type newBatchSize = 10;</div>
<div class="line"><a class="code hl_class" href="classnz_1_1nodes_1_1calc_1_1_expand_node.html">ExpandNode</a> expandNode(inputNode, newBatchSize);</div>
<div class="line">```</div>
<div class="ttc" id="aclassnz_1_1nodes_1_1_node_html"><div class="ttname"><a href="classnz_1_1nodes_1_1_node.html">nz::nodes::Node</a></div><div class="ttdoc">Base class for nodes in a neural network or computational graph.</div><div class="ttdef"><b>Definition</b> <a href="_nodes_8cuh_source.html#l00114">Nodes.cuh:114</a></div></div>
</div><!-- fragment --><dl class="section author"><dt>Author</dt><dd>Mgepahmge(<a href="https://github.com/Mgepahmge">https://github.com/Mgepahmge</a>)</dd></dl>
<dl class="section date"><dt>Date</dt><dd>2024/07/15 </dd></dl>

<p class="definition">Definition at line <a class="el" href="_nodes_8cu_source.html#l00573">573</a> of file <a class="el" href="_nodes_8cu_source.html">Nodes.cu</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="aac692ee5bf79df2148b9595030b46585" name="aac692ee5bf79df2148b9595030b46585"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aac692ee5bf79df2148b9595030b46585">&#9670;&#160;</a></span>backward()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void nz::nodes::calc::ExpandNode::backward </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs the backward propagation for the <a class="el" href="classnz_1_1nodes_1_1calc_1_1_expand_node.html" title="Expands tensors with batch size 1 to arbitrary batch dimensions through data replication.">ExpandNode</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">None</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None</dd></dl>
<p>This function performs the backward propagation of the <a class="el" href="classnz_1_1nodes_1_1calc_1_1_expand_node.html" title="Expands tensors with batch size 1 to arbitrary batch dimensions through data replication.">ExpandNode</a>. It first checks if the input tensor requires gradient computation. If it does, it calculates the size of a single element in the input tensor (excluding the batch dimension) and the total number of elements in the output tensor. Then, it configures the CUDA grid and block dimensions for parallel execution. Finally, it calls the <code>Compress</code> kernel function to perform the compression operation on the gradients, which is the reverse operation of the forward expansion.</p>
<p>Memory management strategy: The function does not allocate or free any memory directly. It relies on the memory allocated for the input and output gradient tensors. Exception handling mechanism: There is no explicit exception handling in this function. However, the <code>Compress</code> kernel call may encounter errors related to CUDA operations such as invalid grid/block dimensions or device issues.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">None</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>Ensure that the CUDA device is properly initialized before calling this function.</li>
<li>The <code>Compress</code> kernel function should be implemented correctly to handle the gradient compression operation.</li>
<li>The time complexity of the compression operation depends on the implementation of the <code>Compress</code> kernel, but in general, it has a linear time complexity O(n), where n is the total number of elements in the output tensor.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1nodes_1_1calc_1_1_expand_node.html">ExpandNode</a> expandNode; <span class="comment">// Assume expandNode is properly initialized</span></div>
<div class="line">expandNode.<a class="code hl_function" href="#aac692ee5bf79df2148b9595030b46585">backward</a>();</div>
<div class="line">```</div>
<div class="ttc" id="aclassnz_1_1nodes_1_1calc_1_1_expand_node_html_aac692ee5bf79df2148b9595030b46585"><div class="ttname"><a href="#aac692ee5bf79df2148b9595030b46585">nz::nodes::calc::ExpandNode::backward</a></div><div class="ttdeci">void backward() override</div><div class="ttdoc">Performs the backward propagation for the ExpandNode.</div><div class="ttdef"><b>Definition</b> <a href="_nodes_8cu_source.html#l00594">Nodes.cu:594</a></div></div>
</div><!-- fragment --><dl class="section author"><dt>Author</dt><dd>Mgepahmge(<a href="https://github.com/Mgepahmge">https://github.com/Mgepahmge</a>)</dd></dl>
<dl class="section date"><dt>Date</dt><dd>2024/07/15 </dd></dl>

<p>Implements <a class="el" href="classnz_1_1nodes_1_1_node.html#a0a9ecbaa3d790ba38e8218aca7837fd0">nz::nodes::Node</a>.</p>

<p class="definition">Definition at line <a class="el" href="_nodes_8cu_source.html#l00594">594</a> of file <a class="el" href="_nodes_8cu_source.html">Nodes.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1nodes_1_1calc_1_1_expand_node_aac692ee5bf79df2148b9595030b46585_cgraph.png" border="0" usemap="#aclassnz_1_1nodes_1_1calc_1_1_expand_node_aac692ee5bf79df2148b9595030b46585_cgraph" alt=""/></div>
<map name="aclassnz_1_1nodes_1_1calc_1_1_expand_node_aac692ee5bf79df2148b9595030b46585_cgraph" id="aclassnz_1_1nodes_1_1calc_1_1_expand_node_aac692ee5bf79df2148b9595030b46585_cgraph">
<area shape="rect" title="Performs the backward propagation for the ExpandNode." alt="" coords="5,39,199,81"/>
<area shape="rect" href="namespacenz_1_1krnl.html#a454a28ef0e22014efca1ede4e954db65" title="Compresses the input array into the output array with a specified total size." alt="" coords="247,47,379,73"/>
<area shape="poly" title=" " alt="" coords="199,57,231,57,231,63,199,63"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="427,5,612,48"/>
<area shape="poly" title=" " alt="" coords="379,47,411,41,412,47,380,52"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a46ce59b45de432842454aadf00b93791" title="Asynchronously submits a CUDA kernel with stream&#45;ordered dependency management." alt="" coords="427,72,612,115"/>
<area shape="poly" title=" " alt="" coords="380,68,412,73,411,79,379,73"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a1de1cf3aadea137faf90a2f9b4b7abe2" title="Acquires CUDA stream from pool using round&#45;robin scheduling." alt="" coords="660,39,846,81"/>
<area shape="poly" title=" " alt="" coords="612,77,644,73,645,78,613,83"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#adb1078a67c6e38932d7d58c2adb05ec0" title="Synchronizes CUDA stream execution until data writes complete." alt="" coords="660,105,846,148"/>
<area shape="poly" title=" " alt="" coords="613,104,645,109,644,114,612,109"/>
</map>
</div>

</div>
</div>
<a id="a883419ee48eca406c2deb6939aa1a546" name="a883419ee48eca406c2deb6939aa1a546"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a883419ee48eca406c2deb6939aa1a546">&#9670;&#160;</a></span>forward()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void nz::nodes::calc::ExpandNode::forward </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs the forward propagation for the <a class="el" href="classnz_1_1nodes_1_1calc_1_1_expand_node.html" title="Expands tensors with batch size 1 to arbitrary batch dimensions through data replication.">ExpandNode</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">None</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None</dd></dl>
<p>This function conducts the forward propagation of the <a class="el" href="classnz_1_1nodes_1_1calc_1_1_expand_node.html" title="Expands tensors with batch size 1 to arbitrary batch dimensions through data replication.">ExpandNode</a>. It first calculates the size of a single element in the input tensor (excluding the batch dimension) and the total number of elements in the output tensor. Then, it configures the CUDA grid and block dimensions for parallel execution. Finally, it calls the <code>Expand</code> kernel function to perform the actual expansion operation on the device.</p>
<p>Memory management strategy: The function does not allocate or free any memory directly. It relies on the memory allocated for the input and output tensors in the constructor. Exception handling mechanism: There is no explicit exception handling in this function. However, the <code>Expand</code> kernel call may encounter errors related to CUDA operations such as invalid grid/block dimensions or device issues.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">None</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>Ensure that the CUDA device is properly initialized before calling this function.</li>
<li>The <code>Expand</code> kernel function should be implemented correctly to handle the expansion operation.</li>
<li>The time complexity of the expansion operation depends on the implementation of the <code>Expand</code> kernel, but in general, it has a linear time complexity O(n), where n is the total number of elements in the output tensor.</li>
</ul>
</dd></dl>
<div class="fragment"><div class="line">```cpp</div>
<div class="line"><a class="code hl_class" href="classnz_1_1nodes_1_1calc_1_1_expand_node.html">ExpandNode</a> expandNode; <span class="comment">// Assume expandNode is properly initialized</span></div>
<div class="line">expandNode.<a class="code hl_function" href="#a883419ee48eca406c2deb6939aa1a546">forward</a>();</div>
<div class="line">```</div>
<div class="ttc" id="aclassnz_1_1nodes_1_1calc_1_1_expand_node_html_a883419ee48eca406c2deb6939aa1a546"><div class="ttname"><a href="#a883419ee48eca406c2deb6939aa1a546">nz::nodes::calc::ExpandNode::forward</a></div><div class="ttdeci">void forward() override</div><div class="ttdoc">Performs the forward propagation for the ExpandNode.</div><div class="ttdef"><b>Definition</b> <a href="_nodes_8cu_source.html#l00585">Nodes.cu:585</a></div></div>
</div><!-- fragment --><dl class="section author"><dt>Author</dt><dd>Mgepahmge(<a href="https://github.com/Mgepahmge">https://github.com/Mgepahmge</a>)</dd></dl>
<dl class="section date"><dt>Date</dt><dd>2024/07/15 </dd></dl>

<p>Implements <a class="el" href="classnz_1_1nodes_1_1_node.html#a8a828c2e91a4aa2a9ab7b94554e4685b">nz::nodes::Node</a>.</p>

<p class="definition">Definition at line <a class="el" href="_nodes_8cu_source.html#l00585">585</a> of file <a class="el" href="_nodes_8cu_source.html">Nodes.cu</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1nodes_1_1calc_1_1_expand_node_a883419ee48eca406c2deb6939aa1a546_cgraph.png" border="0" usemap="#aclassnz_1_1nodes_1_1calc_1_1_expand_node_a883419ee48eca406c2deb6939aa1a546_cgraph" alt=""/></div>
<map name="aclassnz_1_1nodes_1_1calc_1_1_expand_node_a883419ee48eca406c2deb6939aa1a546_cgraph" id="aclassnz_1_1nodes_1_1calc_1_1_expand_node_a883419ee48eca406c2deb6939aa1a546_cgraph">
<area shape="rect" title="Performs the forward propagation for the ExpandNode." alt="" coords="5,39,199,81"/>
<area shape="rect" href="namespacenz_1_1krnl.html#ae45dbebceb76ddf82fa5e6b9df882e62" title="Expands the input array into the output array with a specified total size." alt="" coords="247,47,363,73"/>
<area shape="poly" title=" " alt="" coords="199,57,231,57,231,63,199,63"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#ab4b2eb422e0e1ee44bdfdc0eb94457ce" title="Returns a reference to the singleton instance of the StreamManager." alt="" coords="411,5,596,48"/>
<area shape="poly" title=" " alt="" coords="363,48,395,42,396,47,364,53"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a46ce59b45de432842454aadf00b93791" title="Asynchronously submits a CUDA kernel with stream&#45;ordered dependency management." alt="" coords="411,72,596,115"/>
<area shape="poly" title=" " alt="" coords="364,67,396,73,395,78,363,72"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#a1de1cf3aadea137faf90a2f9b4b7abe2" title="Acquires CUDA stream from pool using round&#45;robin scheduling." alt="" coords="644,39,830,81"/>
<area shape="poly" title=" " alt="" coords="596,77,628,73,629,78,597,83"/>
<area shape="rect" href="classnz_1_1cu_strm_1_1_stream_manager.html#adb1078a67c6e38932d7d58c2adb05ec0" title="Synchronizes CUDA stream execution until data writes complete." alt="" coords="644,105,830,148"/>
<area shape="poly" title=" " alt="" coords="597,104,629,109,628,114,596,109"/>
</map>
</div>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>D:/Users/Mgepahmge/Documents/C Program/NeuZephyr/include/NeuZephyr/<a class="el" href="_nodes_8cuh_source.html">Nodes.cuh</a></li>
<li>D:/Users/Mgepahmge/Documents/C Program/NeuZephyr/src/<a class="el" href="_nodes_8cu_source.html">Nodes.cu</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.12.0
</small></address>
</div><!-- doc-content -->
</body>
</html>
