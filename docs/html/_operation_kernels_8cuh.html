<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.12.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NeuZephyr: D:/Users/Mgepahmge/Documents/C Program/NeuZephyr/include/NeuZephyr/OperationKernels.cuh File Reference</title>
<link rel="icon" href="NZ_logo2.png" type="image/x-icon" />
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="NZ_logo2.png"/></td>
  <td id="projectalign">
   <div id="projectname">NeuZephyr
   </div>
   <div id="projectbrief">Simple DL Framework</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.12.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
    </ul>
  </div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){ initResizable(false); });
/* @license-end */
</script>
<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_d522931ffa1371640980b621734a4381.html">Users</a></li><li class="navelem"><a class="el" href="dir_a7e6ee1ae3f772c9504a0b543f2027e2.html">Mgepahmge</a></li><li class="navelem"><a class="el" href="dir_e03f57e346cc4845a4c354a35630b169.html">Documents</a></li><li class="navelem"><a class="el" href="dir_231a0482af2b83c895f27ba7fe745141.html">C Program</a></li><li class="navelem"><a class="el" href="dir_0fa7fc3a0dfd304dbfc9dce9f6facfa2.html">NeuZephyr</a></li><li class="navelem"><a class="el" href="dir_e7295b03dab2e9cdf32139bd8ec2e607.html">include</a></li><li class="navelem"><a class="el" href="dir_657344ecc65cfc28732701509f8d8421.html">NeuZephyr</a></li>  </ul>
</div>
</div><!-- top -->
<div id="doc-content">
<div class="header">
  <div class="summary">
<a href="#namespaces">Namespaces</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">OperationKernels.cuh File Reference</div></div>
</div><!--header-->
<div class="contents">

<p>CUDA Kernel Definitions for High-Performance Tensor Operations.  
<a href="#details">More...</a></p>
<div class="textblock"><div class="dynheader">
This graph shows which files directly or indirectly include this file:</div>
<div class="dyncontent">
<div class="center"><img src="_operation_kernels_8cuh__dep__incl.png" border="0" usemap="#a_d_1_2_users_2_mgepahmge_2_documents_2_c_01_program_2_neu_zephyr_2include_2_neu_zephyr_2_operation_kernels_8cuhdep" alt=""/></div>
<map name="a_d_1_2_users_2_mgepahmge_2_documents_2_c_01_program_2_neu_zephyr_2include_2_neu_zephyr_2_operation_kernels_8cuhdep" id="a_d_1_2_users_2_mgepahmge_2_documents_2_c_01_program_2_neu_zephyr_2include_2_neu_zephyr_2_operation_kernels_8cuhdep">
<area shape="rect" title="CUDA Kernel Definitions for High&#45;Performance Tensor Operations." alt="" coords="695,5,897,80"/>
<area shape="rect" href="_compute_graph_8cuh.html" title="Defines the ComputeGraph class for constructing and managing computational graphs in neural network m..." alt="" coords="15,128,217,203"/>
<area shape="poly" title=" " alt="" coords="679,58,469,86,349,106,230,131,218,133,217,128,229,125,348,101,468,81,679,53"/>
<area shape="rect" href="_mapped_tensor_8cu_source.html" title=" " alt="" coords="242,136,460,195"/>
<area shape="poly" title=" " alt="" coords="680,76,473,131,447,138,445,133,471,125,679,71"/>
<area shape="rect" href="_nodes_8cu_source.html" title=" " alt="" coords="484,136,655,195"/>
<area shape="poly" title=" " alt="" coords="714,90,625,138,622,133,712,85"/>
<area shape="rect" href="_operation_kernels_8cu_source.html" title=" " alt="" coords="679,136,913,195"/>
<area shape="poly" title=" " alt="" coords="799,96,799,136,793,136,793,96"/>
<area shape="rect" href="_optimizer_8cu_source.html" title=" " alt="" coords="937,136,1127,195"/>
<area shape="poly" title=" " alt="" coords="883,85,977,133,974,138,881,90"/>
<area shape="rect" href="_tensor_8cu_source.html" title=" " alt="" coords="1151,136,1324,195"/>
<area shape="poly" title=" " alt="" coords="913,67,1023,93,1139,125,1162,133,1161,138,1138,131,1022,98,912,72"/>
<area shape="rect" href="_tensor_operations_8cu_source.html" title=" " alt="" coords="1348,136,1583,195"/>
<area shape="poly" title=" " alt="" coords="913,56,1112,84,1337,125,1368,133,1367,138,1335,131,1111,89,912,61"/>
<area shape="rect" href="_compute_graph_8cu_source.html" title=" " alt="" coords="5,251,227,309"/>
<area shape="poly" title=" " alt="" coords="119,218,119,250,113,250,113,218"/>
</map>
</div>
</div>
<p><a href="_operation_kernels_8cuh_source.html">Go to the source code of this file.</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="namespaces" name="namespaces"></a>
Namespaces</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">namespace &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html">nz::krnl</a></td></tr>
<tr class="memdesc:namespacenz_1_1krnl"><td class="mdescLeft">&#160;</td><td class="mdescRight">High-Performance CUDA Kernel Implementations for Tensor Computations. <br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ac24c370f0323c789136d1c2e1fd00137" id="r_ac24c370f0323c789136d1c2e1fd00137"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#ac24c370f0323c789136d1c2e1fd00137">nz::krnl::MatrixAdd</a> (dim3 gridDim, dim3 blockDim, const float *a, const float *b, float *c, unsigned long long n)</td></tr>
<tr class="memdesc:ac24c370f0323c789136d1c2e1fd00137"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to perform matrix addition on GPU.  <br /></td></tr>
<tr class="separator:ac24c370f0323c789136d1c2e1fd00137"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02ad4d4f320e2561be553557ef5805af" id="r_a02ad4d4f320e2561be553557ef5805af"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a02ad4d4f320e2561be553557ef5805af">nz::krnl::MatrixSub</a> (dim3 gridDim, dim3 blockDim, const float *a, const float *b, float *c, unsigned long long n)</td></tr>
<tr class="memdesc:a02ad4d4f320e2561be553557ef5805af"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to perform matrix subtraction on GPU.  <br /></td></tr>
<tr class="separator:a02ad4d4f320e2561be553557ef5805af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a33d3b5cd440afb3c6557515247b5b680" id="r_a33d3b5cd440afb3c6557515247b5b680"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a33d3b5cd440afb3c6557515247b5b680">nz::krnl::GeneralMatrixMul</a> (dim3 gridDim, dim3 blockDim, const float *A, const float *B, float *C, unsigned long long M, unsigned long long N, unsigned long long K)</td></tr>
<tr class="memdesc:a33d3b5cd440afb3c6557515247b5b680"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to perform single-precision matrix multiplication on GPU using CUDA cores.  <br /></td></tr>
<tr class="separator:a33d3b5cd440afb3c6557515247b5b680"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac35465fb782e707b54abe85d98d417f6" id="r_ac35465fb782e707b54abe85d98d417f6"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#ac35465fb782e707b54abe85d98d417f6">nz::krnl::Transpose</a> (const dim3 gridDim, const dim3 blockDim, const float *d_A, float *d_B, const unsigned int rows, const unsigned int cols)</td></tr>
<tr class="memdesc:ac35465fb782e707b54abe85d98d417f6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to transpose a matrix on the GPU.  <br /></td></tr>
<tr class="separator:ac35465fb782e707b54abe85d98d417f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3ff4ec6909c3296e1b0d5631c29a44bb" id="r_a3ff4ec6909c3296e1b0d5631c29a44bb"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a3ff4ec6909c3296e1b0d5631c29a44bb">nz::krnl::ScalarMul</a> (const dim3 gridDim, const dim3 blockDim, float *out, const float *in, const float num, const unsigned long long n)</td></tr>
<tr class="memdesc:a3ff4ec6909c3296e1b0d5631c29a44bb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to perform scalar multiplication on the GPU.  <br /></td></tr>
<tr class="separator:a3ff4ec6909c3296e1b0d5631c29a44bb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5836f2ff0444a53b8ae60e8fee4b01ac" id="r_a5836f2ff0444a53b8ae60e8fee4b01ac"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a5836f2ff0444a53b8ae60e8fee4b01ac">nz::krnl::ScalarDiv</a> (const dim3 gridDim, const dim3 blockDim, float *out, const float *in, const float num, const unsigned long long n)</td></tr>
<tr class="memdesc:a5836f2ff0444a53b8ae60e8fee4b01ac"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to perform scalar division on the GPU.  <br /></td></tr>
<tr class="separator:a5836f2ff0444a53b8ae60e8fee4b01ac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adcbfa84211bb6cac845f1dc94e59ec19" id="r_adcbfa84211bb6cac845f1dc94e59ec19"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#adcbfa84211bb6cac845f1dc94e59ec19">nz::krnl::ScalarAdd</a> (const dim3 gridDim, const dim3 blockDim, float *out, const float *in, const float num, const unsigned long long n)</td></tr>
<tr class="memdesc:adcbfa84211bb6cac845f1dc94e59ec19"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to add a scalar to each element of a matrix on the GPU.  <br /></td></tr>
<tr class="separator:adcbfa84211bb6cac845f1dc94e59ec19"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac4e4b8e2415062632b49dd77694b0974" id="r_ac4e4b8e2415062632b49dd77694b0974"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#ac4e4b8e2415062632b49dd77694b0974">nz::krnl::Negation</a> (const dim3 gridDim, const dim3 blockDim, float *out, const float *in, const unsigned long long n)</td></tr>
<tr class="memdesc:ac4e4b8e2415062632b49dd77694b0974"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to negate each element of a matrix on the GPU.  <br /></td></tr>
<tr class="separator:ac4e4b8e2415062632b49dd77694b0974"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9d66573a9e8bb1816eaae83dbdb0bcf6" id="r_a9d66573a9e8bb1816eaae83dbdb0bcf6"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a9d66573a9e8bb1816eaae83dbdb0bcf6">nz::krnl::Recip</a> (const dim3 gridDim, const dim3 blockDim, float *out, const float *in, const unsigned long long n)</td></tr>
<tr class="memdesc:a9d66573a9e8bb1816eaae83dbdb0bcf6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to compute the reciprocal of each element of a matrix on the GPU.  <br /></td></tr>
<tr class="separator:a9d66573a9e8bb1816eaae83dbdb0bcf6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af7a6c276ed33c218e97f4e41c50f5ede" id="r_af7a6c276ed33c218e97f4e41c50f5ede"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#af7a6c276ed33c218e97f4e41c50f5ede">nz::krnl::RectifiedLinearUnit</a> (const dim3 gridDim, const dim3 blockDim, float *out, const float *in, const unsigned long long n)</td></tr>
<tr class="memdesc:af7a6c276ed33c218e97f4e41c50f5ede"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to apply the Rectified Linear Unit (ReLU) activation on the GPU.  <br /></td></tr>
<tr class="separator:af7a6c276ed33c218e97f4e41c50f5ede"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae0a11355c95bb213319f035c77f405f0" id="r_ae0a11355c95bb213319f035c77f405f0"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#ae0a11355c95bb213319f035c77f405f0">nz::krnl::ReLUBackward</a> (const dim3 gridDim, const dim3 blockDim, float *A_grad, const float *A, const float *B_grad, const unsigned long long n)</td></tr>
<tr class="memdesc:ae0a11355c95bb213319f035c77f405f0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to compute the gradient of the ReLU activation during backpropagation.  <br /></td></tr>
<tr class="separator:ae0a11355c95bb213319f035c77f405f0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aabac4b35d1aa83e380e0ef33af0a9e57" id="r_aabac4b35d1aa83e380e0ef33af0a9e57"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#aabac4b35d1aa83e380e0ef33af0a9e57">nz::krnl::Sigmoid</a> (const dim3 gridDim, const dim3 blockDim, float *out, const float *in, const unsigned long long n)</td></tr>
<tr class="memdesc:aabac4b35d1aa83e380e0ef33af0a9e57"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to apply the Sigmoid activation function on the GPU.  <br /></td></tr>
<tr class="separator:aabac4b35d1aa83e380e0ef33af0a9e57"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a65ca09a71042bdbf1434f2f37e95797b" id="r_a65ca09a71042bdbf1434f2f37e95797b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a65ca09a71042bdbf1434f2f37e95797b">nz::krnl::SigmoidBackward</a> (const dim3 gridDim, const dim3 blockDim, float *A_grad, const float *B, const float *B_grad, const unsigned long long n)</td></tr>
<tr class="memdesc:a65ca09a71042bdbf1434f2f37e95797b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to compute the gradient of the Sigmoid activation during backpropagation.  <br /></td></tr>
<tr class="separator:a65ca09a71042bdbf1434f2f37e95797b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9abd2a1f99af9e1799edb336355d1ba0" id="r_a9abd2a1f99af9e1799edb336355d1ba0"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a9abd2a1f99af9e1799edb336355d1ba0">nz::krnl::Tanh</a> (const dim3 gridDim, const dim3 blockDim, float *out, const float *in, const unsigned long long n)</td></tr>
<tr class="memdesc:a9abd2a1f99af9e1799edb336355d1ba0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to apply the Tanh activation function on the GPU.  <br /></td></tr>
<tr class="separator:a9abd2a1f99af9e1799edb336355d1ba0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae292654b15c72e5de76584d3f3a11817" id="r_ae292654b15c72e5de76584d3f3a11817"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#ae292654b15c72e5de76584d3f3a11817">nz::krnl::TanhBackward</a> (const dim3 gridDim, const dim3 blockDim, float *A_grad, const float *B, const float *B_grad, const unsigned long long n)</td></tr>
<tr class="memdesc:ae292654b15c72e5de76584d3f3a11817"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to compute the gradient of the Tanh activation during backpropagation.  <br /></td></tr>
<tr class="separator:ae292654b15c72e5de76584d3f3a11817"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46f2fac9d4d89c221194e3d44174bda0" id="r_a46f2fac9d4d89c221194e3d44174bda0"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a46f2fac9d4d89c221194e3d44174bda0">nz::krnl::LeakyReLU</a> (const dim3 gridDim, const dim3 blockDim, float *out, const float *in, const unsigned long long n, const float alpha=0.01f)</td></tr>
<tr class="memdesc:a46f2fac9d4d89c221194e3d44174bda0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to apply the Leaky ReLU activation function on the GPU.  <br /></td></tr>
<tr class="separator:a46f2fac9d4d89c221194e3d44174bda0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a932eaf573ea612466b51a74260c4dc4c" id="r_a932eaf573ea612466b51a74260c4dc4c"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a932eaf573ea612466b51a74260c4dc4c">nz::krnl::LeakyReLUBackward</a> (const dim3 gridDim, const dim3 blockDim, float *A_grad, const float *A, const float *B_grad, unsigned long long n, float alpha=0.01f)</td></tr>
<tr class="memdesc:a932eaf573ea612466b51a74260c4dc4c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to compute the gradient of the Leaky ReLU activation during backpropagation.  <br /></td></tr>
<tr class="separator:a932eaf573ea612466b51a74260c4dc4c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5d16dbfa0fdad676c5eecd502aa312a3" id="r_a5d16dbfa0fdad676c5eecd502aa312a3"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a5d16dbfa0fdad676c5eecd502aa312a3">nz::krnl::Swish</a> (const dim3 gridDim, const dim3 blockDim, float *out, const float *in, const unsigned long long n)</td></tr>
<tr class="memdesc:a5d16dbfa0fdad676c5eecd502aa312a3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to apply the Swish activation function on the GPU.  <br /></td></tr>
<tr class="separator:a5d16dbfa0fdad676c5eecd502aa312a3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c31fba26003ca607eb484f3ff66701c" id="r_a1c31fba26003ca607eb484f3ff66701c"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a1c31fba26003ca607eb484f3ff66701c">nz::krnl::SwishBackward</a> (const dim3 gridDim, const dim3 blockDim, float *A_grad, const float *A, const float *B, const float *B_grad, const unsigned long long n)</td></tr>
<tr class="memdesc:a1c31fba26003ca607eb484f3ff66701c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to compute the gradient of the Swish activation during backpropagation.  <br /></td></tr>
<tr class="separator:a1c31fba26003ca607eb484f3ff66701c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a76bae8401d19501237cb390fb6f6e11a" id="r_a76bae8401d19501237cb390fb6f6e11a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a76bae8401d19501237cb390fb6f6e11a">nz::krnl::ExponentialLinearUnit</a> (const dim3 gridDim, const dim3 blockDim, float *out, const float *in, unsigned long long n, float alpha=1.0f)</td></tr>
<tr class="memdesc:a76bae8401d19501237cb390fb6f6e11a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to apply the Exponential Linear Unit (ELU) activation function on the GPU.  <br /></td></tr>
<tr class="separator:a76bae8401d19501237cb390fb6f6e11a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a60576f05d988d55c4ed32faf22b71605" id="r_a60576f05d988d55c4ed32faf22b71605"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a60576f05d988d55c4ed32faf22b71605">nz::krnl::ELUBackward</a> (const dim3 gridDim, const dim3 blockDim, float *A_grad, const float *A, const float *B_grad, unsigned long long n, float alpha=1.0f)</td></tr>
<tr class="memdesc:a60576f05d988d55c4ed32faf22b71605"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to compute the gradient of the ELU activation during backpropagation.  <br /></td></tr>
<tr class="separator:a60576f05d988d55c4ed32faf22b71605"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec68f7e90b1451e551de0804ef11df1c" id="r_aec68f7e90b1451e551de0804ef11df1c"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#aec68f7e90b1451e551de0804ef11df1c">nz::krnl::HardSigmoid</a> (const dim3 gridDim, const dim3 blockDim, float *out, const float *in, const unsigned long long n, const float alpha=0.2f, const float beta=0.5f)</td></tr>
<tr class="memdesc:aec68f7e90b1451e551de0804ef11df1c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to apply the Hard Sigmoid activation function on the GPU.  <br /></td></tr>
<tr class="separator:aec68f7e90b1451e551de0804ef11df1c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1a168ca2b5e433574004ae73b5f7deec" id="r_a1a168ca2b5e433574004ae73b5f7deec"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a1a168ca2b5e433574004ae73b5f7deec">nz::krnl::HardSigmoidBackward</a> (const dim3 gridDim, const dim3 blockDim, float *A_grad, const float *A, const float *B_grad, unsigned long long n, float alpha=0.2f, float beta=0.5f)</td></tr>
<tr class="memdesc:a1a168ca2b5e433574004ae73b5f7deec"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to compute the gradient of the Hard Sigmoid activation during backpropagation.  <br /></td></tr>
<tr class="separator:a1a168ca2b5e433574004ae73b5f7deec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c18d8a2b6ddeeeb83cea014829864ad" id="r_a6c18d8a2b6ddeeeb83cea014829864ad"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a6c18d8a2b6ddeeeb83cea014829864ad">nz::krnl::HardSwish</a> (const dim3 gridDim, const dim3 blockDim, float *out, const float *in, unsigned long long n, float alpha=0.2f, float beta=0.5f)</td></tr>
<tr class="memdesc:a6c18d8a2b6ddeeeb83cea014829864ad"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to apply the Hard Swish activation function on the GPU.  <br /></td></tr>
<tr class="separator:a6c18d8a2b6ddeeeb83cea014829864ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a293918c6c59bd44f5f0c94b5791202f7" id="r_a293918c6c59bd44f5f0c94b5791202f7"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a293918c6c59bd44f5f0c94b5791202f7">nz::krnl::HardSwishBackward</a> (const dim3 gridDim, const dim3 blockDim, float *A_grad, const float *A, const float *B_grad, unsigned long long n, float alpha=0.2f, float beta=0.5f)</td></tr>
<tr class="memdesc:a293918c6c59bd44f5f0c94b5791202f7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to compute the gradient of the Hard Swish activation during backpropagation.  <br /></td></tr>
<tr class="separator:a293918c6c59bd44f5f0c94b5791202f7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8ab711742ea831cdf1fb86824d17e25f" id="r_a8ab711742ea831cdf1fb86824d17e25f"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a8ab711742ea831cdf1fb86824d17e25f">nz::krnl::SummationExp</a> (const dim3 gridDim, const dim3 blockDim, const size_t sharedMemSize, float *out, const float *g_data, const unsigned long long n)</td></tr>
<tr class="memdesc:a8ab711742ea831cdf1fb86824d17e25f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to compute the summation of exponentials of each element in the input array.  <br /></td></tr>
<tr class="separator:a8ab711742ea831cdf1fb86824d17e25f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af2da66c855055532571077c3f0db0425" id="r_af2da66c855055532571077c3f0db0425"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#af2da66c855055532571077c3f0db0425">nz::krnl::Softmax</a> (const dim3 gridDim, const dim3 blockDim, float *out, const float *in, const float exp_sum_of_input, const unsigned long long n)</td></tr>
<tr class="memdesc:af2da66c855055532571077c3f0db0425"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to apply the Softmax function on the GPU.  <br /></td></tr>
<tr class="separator:af2da66c855055532571077c3f0db0425"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7aa8960ce34fdfd2f7ebbb5762bec2e4" id="r_a7aa8960ce34fdfd2f7ebbb5762bec2e4"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a7aa8960ce34fdfd2f7ebbb5762bec2e4">nz::krnl::SoftmaxJacobian</a> (const dim3 gridDim, const dim3 blockDim, float *out, const float *in, const unsigned long long n)</td></tr>
<tr class="memdesc:a7aa8960ce34fdfd2f7ebbb5762bec2e4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to compute the Jacobian of the Softmax function.  <br /></td></tr>
<tr class="separator:a7aa8960ce34fdfd2f7ebbb5762bec2e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6ac88757669475405e9b11280a54e947" id="r_a6ac88757669475405e9b11280a54e947"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a6ac88757669475405e9b11280a54e947">nz::krnl::MeanSquaredError</a> (const dim3 gridDim, const dim3 blockDim, const size_t sharedMemSize, float *out, const float *predict, const float *real, const unsigned long long n)</td></tr>
<tr class="memdesc:a6ac88757669475405e9b11280a54e947"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to compute the Mean Squared Error (MSE) loss between predicted and real values.  <br /></td></tr>
<tr class="separator:a6ac88757669475405e9b11280a54e947"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac8b897372ef72573098d23f19c887f86" id="r_ac8b897372ef72573098d23f19c887f86"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#ac8b897372ef72573098d23f19c887f86">nz::krnl::MSEBackward</a> (const dim3 gridDim, const dim3 blockDim, float *out, const float *predict, const float *real, const unsigned long long n)</td></tr>
<tr class="memdesc:ac8b897372ef72573098d23f19c887f86"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to compute the gradient of the Mean Squared Error (MSE) loss for backpropagation.  <br /></td></tr>
<tr class="separator:ac8b897372ef72573098d23f19c887f86"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a519338ba13d0b3a381fa187a0141d196" id="r_a519338ba13d0b3a381fa187a0141d196"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a519338ba13d0b3a381fa187a0141d196">nz::krnl::StochasticGradientDescent</a> (const dim3 gridDim, const dim3 blockDim, float *data, const float *grad, const float lr, const unsigned long long n)</td></tr>
<tr class="memdesc:a519338ba13d0b3a381fa187a0141d196"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to perform Stochastic Gradient Descent (SGD) optimization.  <br /></td></tr>
<tr class="separator:a519338ba13d0b3a381fa187a0141d196"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa8ac93615d2263e015c2677953a77a3d" id="r_aa8ac93615d2263e015c2677953a77a3d"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#aa8ac93615d2263e015c2677953a77a3d">nz::krnl::BinaryCrossEntropy</a> (const dim3 gridDim, const dim3 blockDim, const size_t sharedMemSize, float *out, const float *predict, const float *real, const unsigned long long n)</td></tr>
<tr class="memdesc:aa8ac93615d2263e015c2677953a77a3d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to compute the Binary Cross Entropy (BCE) loss between predicted and real values.  <br /></td></tr>
<tr class="separator:aa8ac93615d2263e015c2677953a77a3d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8d32b374b22c0bd3f507d5c5ed8aeca6" id="r_a8d32b374b22c0bd3f507d5c5ed8aeca6"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a8d32b374b22c0bd3f507d5c5ed8aeca6">nz::krnl::BCEBackward</a> (const dim3 gridDim, const dim3 blockDim, float *out, const float *predict, const float *real, const unsigned long long n)</td></tr>
<tr class="memdesc:a8d32b374b22c0bd3f507d5c5ed8aeca6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to compute the gradient of Binary Cross Entropy (BCE) loss for backpropagation.  <br /></td></tr>
<tr class="separator:a8d32b374b22c0bd3f507d5c5ed8aeca6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a657c98688dfb7749e382bba46ccbfd5b" id="r_a657c98688dfb7749e382bba46ccbfd5b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a657c98688dfb7749e382bba46ccbfd5b">nz::krnl::Momentum</a> (dim3 gridDim, dim3 blockDim, float *output, const float *grad, const float *velocity, float beta, unsigned long long n)</td></tr>
<tr class="memdesc:a657c98688dfb7749e382bba46ccbfd5b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to apply Momentum optimization.  <br /></td></tr>
<tr class="separator:a657c98688dfb7749e382bba46ccbfd5b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9860327858b8f09981e31d78b7bf39d2" id="r_a9860327858b8f09981e31d78b7bf39d2"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a9860327858b8f09981e31d78b7bf39d2">nz::krnl::AdaGrad</a> (const dim3 gridDim, const dim3 blockDim, float *data, float *G, const float *grad, const float lr, const float eps, const unsigned long long n)</td></tr>
<tr class="memdesc:a9860327858b8f09981e31d78b7bf39d2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to apply AdaGrad optimization.  <br /></td></tr>
<tr class="separator:a9860327858b8f09981e31d78b7bf39d2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02ea9559eff9305923d9f4cd2c562e1e" id="r_a02ea9559eff9305923d9f4cd2c562e1e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a02ea9559eff9305923d9f4cd2c562e1e">nz::krnl::RMSprop</a> (const dim3 gridDim, const dim3 blockDim, float *data, float *v, const float *grad, const float lr, const float beta, const float eps, const unsigned long long n)</td></tr>
<tr class="memdesc:a02ea9559eff9305923d9f4cd2c562e1e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to apply RMSprop optimization.  <br /></td></tr>
<tr class="separator:a02ea9559eff9305923d9f4cd2c562e1e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af867be3ad4ff2028ae16857a368054f2" id="r_af867be3ad4ff2028ae16857a368054f2"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#af867be3ad4ff2028ae16857a368054f2">nz::krnl::Adam</a> (const dim3 gridDim, const dim3 blockDim, float *data, float *m, float *v, const float *grad, const float lr, const float beta1, const float beta2, const float eps, const int t, const unsigned long long n)</td></tr>
<tr class="memdesc:af867be3ad4ff2028ae16857a368054f2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to apply Adam optimization.  <br /></td></tr>
<tr class="separator:af867be3ad4ff2028ae16857a368054f2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a04cc89e77f54501bd5434503a1a63493" id="r_a04cc89e77f54501bd5434503a1a63493"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a04cc89e77f54501bd5434503a1a63493">nz::krnl::NAdam</a> (const dim3 gridDim, const dim3 blockDim, float *data, float *m, float *m_modified, float *v, const float *grad, const float lr, const float beta1, const float beta2, const float eps, const int t, const unsigned long long n)</td></tr>
<tr class="memdesc:a04cc89e77f54501bd5434503a1a63493"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to apply NAdam optimization.  <br /></td></tr>
<tr class="separator:a04cc89e77f54501bd5434503a1a63493"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8d18897fad679e1ceb29c2f9ebfffb0b" id="r_a8d18897fad679e1ceb29c2f9ebfffb0b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a8d18897fad679e1ceb29c2f9ebfffb0b">nz::krnl::AdaDelta</a> (const dim3 gridDim, const dim3 blockDim, float *data, float *acc_delta, float *acc_grad, const float *grad, const float rho, const float eps, const unsigned long long n)</td></tr>
<tr class="memdesc:a8d18897fad679e1ceb29c2f9ebfffb0b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to apply AdaDelta optimization.  <br /></td></tr>
<tr class="separator:a8d18897fad679e1ceb29c2f9ebfffb0b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afaaec3e0398823e64710a8474ff1dcd5" id="r_afaaec3e0398823e64710a8474ff1dcd5"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#afaaec3e0398823e64710a8474ff1dcd5">nz::krnl::TensorCoreGEMM</a> (const float *A, const float *B, float *C, unsigned long long M, unsigned long long N, unsigned long long K)</td></tr>
<tr class="memdesc:afaaec3e0398823e64710a8474ff1dcd5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to perform fast matrix multiplication using Tensor Cores with half-precision (FP16) support.  <br /></td></tr>
<tr class="separator:afaaec3e0398823e64710a8474ff1dcd5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7c8d5892bd795b00c76203e1155b0780" id="r_a7c8d5892bd795b00c76203e1155b0780"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a7c8d5892bd795b00c76203e1155b0780">nz::krnl::Fill</a> (dim3 gridDim, dim3 blockDim, float *data, float value, unsigned long long n)</td></tr>
<tr class="memdesc:a7c8d5892bd795b00c76203e1155b0780"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to fill a data array with a given value.  <br /></td></tr>
<tr class="separator:a7c8d5892bd795b00c76203e1155b0780"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1e77cfb3eca024d16efdfb0b50d3b4c" id="r_ab1e77cfb3eca024d16efdfb0b50d3b4c"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#ab1e77cfb3eca024d16efdfb0b50d3b4c">nz::krnl::HadamardProduct</a> (dim3 gridDim, dim3 blockDim, float *out, const float *in1, const float *in2, unsigned long long n)</td></tr>
<tr class="memdesc:ab1e77cfb3eca024d16efdfb0b50d3b4c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to perform element-wise Hadamard product of two arrays.  <br /></td></tr>
<tr class="separator:ab1e77cfb3eca024d16efdfb0b50d3b4c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adeba04211c5d61e2451ee0df15bd23eb" id="r_adeba04211c5d61e2451ee0df15bd23eb"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#adeba04211c5d61e2451ee0df15bd23eb">nz::krnl::ElementwiseDivide</a> (dim3 gridDim, dim3 blockDim, float *out, const float *in1, const float *in2, unsigned long long n)</td></tr>
<tr class="memdesc:adeba04211c5d61e2451ee0df15bd23eb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to perform element-wise division of two arrays.  <br /></td></tr>
<tr class="separator:adeba04211c5d61e2451ee0df15bd23eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a48fdfa2ba1f5215f55f1f2490956f5ef" id="r_a48fdfa2ba1f5215f55f1f2490956f5ef"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenz_1_1krnl.html#a48fdfa2ba1f5215f55f1f2490956f5ef">nz::krnl::Summation</a> (dim3 gridDim, dim3 blockDim, unsigned long long sharedMemSize, float *out, const float *in, unsigned long long n)</td></tr>
<tr class="memdesc:a48fdfa2ba1f5215f55f1f2490956f5ef"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel function to perform element-wise summation of two arrays.  <br /></td></tr>
<tr class="separator:a48fdfa2ba1f5215f55f1f2490956f5ef"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>CUDA Kernel Definitions for High-Performance Tensor Operations. </p>
<p>This header file provides a comprehensive collection of CUDA kernel functions for accelerated tensor computations, designed to support various mathematical operations, neural network layers, activation functions, and optimization algorithms.</p>
<p>The kernel functions in this file are organized within the <code><a class="el" href="namespacenz_1_1krnl.html" title="High-Performance CUDA Kernel Implementations for Tensor Computations.">nz::krnl</a></code> namespace and cover a wide range of computational tasks:</p>
<ul>
<li><b>Matrix Operations</b>: Basic matrix arithmetic like addition, subtraction, multiplication, and transposition.</li>
<li><b>Element-wise Operations</b>: Scalar operations, negation, reciprocal calculations.</li>
<li><b>Activation Functions</b>:<ul>
<li>Linear: ReLU, Leaky ReLU</li>
<li>Sigmoid Variants: Standard Sigmoid, Hard Sigmoid</li>
<li>Non-linear: Tanh, Swish, ELU</li>
</ul>
</li>
<li><b>Backward Propagation Kernels</b>: Gradient computations for each activation function.</li>
<li><b>Loss Functions</b>: Mean Squared Error, Binary Cross-Entropy</li>
<li><b>Optimization Algorithms</b>: Stochastic Gradient Descent, Momentum, AdaGrad, RMSprop, Adam, NAdam, AdaDelta</li>
</ul>
<p>Kernels are designed for parallel execution on CUDA-enabled GPUs, leveraging high-performance computing capabilities for efficient deep learning computations.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>All kernels utilize <code>unsigned long long</code> for size parameters to support large tensor dimensions.</li>
<li>Most kernels operate on raw float pointers for maximum flexibility and performance.</li>
<li>Kernel launch configurations (grid and block sizes) should be carefully managed to ensure optimal GPU utilization.</li>
</ul>
</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>These low-level CUDA kernel functions are intended for internal library implementation and framework extension. End-users building neural network models SHOULD NOT directly call these kernels. They are meant to be used exclusively by library developers contributing to the internal functionality of the nz framework.</dd></dl>
<dl class="section author"><dt>Author</dt><dd>Mgepahmge (<a href="https://github.com/Mgepahmge">https://github.com/Mgepahmge</a>)</dd></dl>
<dl class="section date"><dt>Date</dt><dd>2024/12/07 </dd></dl>

<p class="definition">Definition in file <a class="el" href="_operation_kernels_8cuh_source.html">OperationKernels.cuh</a>.</p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.12.0
</small></address>
</div><!-- doc-content -->
</body>
</html>
