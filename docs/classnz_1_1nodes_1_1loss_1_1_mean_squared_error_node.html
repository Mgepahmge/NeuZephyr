<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.12.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NeuZephyr: nz::nodes::loss::MeanSquaredErrorNode Class Reference</title>
<link rel="icon" href="NZ_logo2.png" type="image/x-icon" />
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="NZ_logo2.png"/></td>
  <td id="projectalign">
   <div id="projectname">NeuZephyr
   </div>
   <div id="projectbrief">Simple DL Framework</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.12.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>Class&#160;List</span></a></li>
      <li><a href="classes.html"><span>Class&#160;Index</span></a></li>
      <li><a href="inherits.html"><span>Class&#160;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&#160;Members</span></a></li>
    </ul>
  </div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){ initResizable(false); });
/* @license-end */
</script>
<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>nz</b></li><li class="navelem"><a class="el" href="namespacenz_1_1nodes.html">nodes</a></li><li class="navelem"><a class="el" href="namespacenz_1_1nodes_1_1loss.html">loss</a></li><li class="navelem"><a class="el" href="classnz_1_1nodes_1_1loss_1_1_mean_squared_error_node.html">MeanSquaredErrorNode</a></li>  </ul>
</div>
</div><!-- top -->
<div id="doc-content">
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classnz_1_1nodes_1_1loss_1_1_mean_squared_error_node-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">nz::nodes::loss::MeanSquaredErrorNode Class Reference</div></div>
</div><!--header-->
<div class="contents">

<p>Represents the Mean Squared Error (MSE) loss function node in a computational graph.  
 <a href="#details">More...</a></p>
<div class="dynheader">
Inheritance diagram for nz::nodes::loss::MeanSquaredErrorNode:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1nodes_1_1loss_1_1_mean_squared_error_node__inherit__graph.png" border="0" usemap="#anz_1_1nodes_1_1loss_1_1_mean_squared_error_node_inherit__map" alt="Inheritance graph"/></div>
<map name="anz_1_1nodes_1_1loss_1_1_mean_squared_error_node_inherit__map" id="anz_1_1nodes_1_1loss_1_1_mean_squared_error_node_inherit__map">
<area shape="rect" title="Represents the Mean Squared Error (MSE) loss function node in a computational graph." alt="" coords="5,155,204,197"/>
<area shape="rect" href="classnz_1_1nodes_1_1io_1_1_output_node.html" title="Base class for loss function nodes in a computational graph." alt="" coords="17,80,192,107"/>
<area shape="poly" title=" " alt="" coords="107,122,107,154,102,154,102,122"/>
<area shape="rect" href="classnz_1_1nodes_1_1_node.html" title="Base class for nodes in a neural network or computational graph." alt="" coords="46,5,163,32"/>
<area shape="poly" title=" " alt="" coords="107,48,107,80,102,80,102,48"/>
</map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for nz::nodes::loss::MeanSquaredErrorNode:</div>
<div class="dyncontent">
<div class="center"><img src="classnz_1_1nodes_1_1loss_1_1_mean_squared_error_node__coll__graph.png" border="0" usemap="#anz_1_1nodes_1_1loss_1_1_mean_squared_error_node_coll__map" alt="Collaboration graph"/></div>
<map name="anz_1_1nodes_1_1loss_1_1_mean_squared_error_node_coll__map" id="anz_1_1nodes_1_1loss_1_1_mean_squared_error_node_coll__map">
<area shape="rect" title="Represents the Mean Squared Error (MSE) loss function node in a computational graph." alt="" coords="5,155,204,197"/>
<area shape="rect" href="classnz_1_1nodes_1_1io_1_1_output_node.html" title="Base class for loss function nodes in a computational graph." alt="" coords="17,80,192,107"/>
<area shape="poly" title=" " alt="" coords="107,122,107,154,102,154,102,122"/>
<area shape="rect" href="classnz_1_1nodes_1_1_node.html" title="Base class for nodes in a neural network or computational graph." alt="" coords="46,5,163,32"/>
<area shape="poly" title=" " alt="" coords="107,48,107,80,102,80,102,48"/>
</map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ac9e098d63556329314c7389b779169b6" id="r_ac9e098d63556329314c7389b779169b6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ac9e098d63556329314c7389b779169b6">MeanSquaredErrorNode</a> (<a class="el" href="classnz_1_1nodes_1_1_node.html">Node</a> *input1, <a class="el" href="classnz_1_1nodes_1_1_node.html">Node</a> *input2)</td></tr>
<tr class="memdesc:ac9e098d63556329314c7389b779169b6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor to initialize a <code><a class="el" href="classnz_1_1nodes_1_1loss_1_1_mean_squared_error_node.html" title="Represents the Mean Squared Error (MSE) loss function node in a computational graph.">MeanSquaredErrorNode</a></code> for computing the Mean Squared Error (MSE) loss.  <br /></td></tr>
<tr class="separator:ac9e098d63556329314c7389b779169b6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae81d6afb059f76617ea034032c12ec13" id="r_ae81d6afb059f76617ea034032c12ec13"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ae81d6afb059f76617ea034032c12ec13">forward</a> () override</td></tr>
<tr class="memdesc:ae81d6afb059f76617ea034032c12ec13"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the forward pass of the Mean Squared Error (MSE) loss function.  <br /></td></tr>
<tr class="separator:ae81d6afb059f76617ea034032c12ec13"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8ccbbad9b8bb2111d24af789020337ce" id="r_a8ccbbad9b8bb2111d24af789020337ce"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a8ccbbad9b8bb2111d24af789020337ce">backward</a> () override</td></tr>
<tr class="memdesc:a8ccbbad9b8bb2111d24af789020337ce"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the backward pass of the Mean Squared Error (MSE) loss function.  <br /></td></tr>
<tr class="separator:a8ccbbad9b8bb2111d24af789020337ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classnz_1_1nodes_1_1io_1_1_output_node"><td colspan="2" onclick="javascript:dynsection.toggleInherit('pub_methods_classnz_1_1nodes_1_1io_1_1_output_node')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classnz_1_1nodes_1_1io_1_1_output_node.html">nz::nodes::io::OutputNode</a></td></tr>
<tr class="memitem:a98af165dc12d16d812708c3cdc9097b2 inherit pub_methods_classnz_1_1nodes_1_1io_1_1_output_node" id="r_a98af165dc12d16d812708c3cdc9097b2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnz_1_1nodes_1_1io_1_1_output_node.html#a98af165dc12d16d812708c3cdc9097b2">OutputNode</a> (<a class="el" href="classnz_1_1nodes_1_1_node.html">Node</a> *input)</td></tr>
<tr class="memdesc:a98af165dc12d16d812708c3cdc9097b2 inherit pub_methods_classnz_1_1nodes_1_1io_1_1_output_node"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor to initialize an <code><a class="el" href="classnz_1_1nodes_1_1io_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code> with a given input node.  <br /></td></tr>
<tr class="separator:a98af165dc12d16d812708c3cdc9097b2 inherit pub_methods_classnz_1_1nodes_1_1io_1_1_output_node"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c05ec6cdbddef105a20c400d0515471 inherit pub_methods_classnz_1_1nodes_1_1io_1_1_output_node" id="r_a1c05ec6cdbddef105a20c400d0515471"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnz_1_1nodes_1_1io_1_1_output_node.html#a1c05ec6cdbddef105a20c400d0515471">forward</a> () override</td></tr>
<tr class="memdesc:a1c05ec6cdbddef105a20c400d0515471 inherit pub_methods_classnz_1_1nodes_1_1io_1_1_output_node"><td class="mdescLeft">&#160;</td><td class="mdescRight">Forward pass for the <code><a class="el" href="classnz_1_1nodes_1_1io_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code>.  <br /></td></tr>
<tr class="separator:a1c05ec6cdbddef105a20c400d0515471 inherit pub_methods_classnz_1_1nodes_1_1io_1_1_output_node"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2f76355b646a9c9f1a0972ad87f6a260 inherit pub_methods_classnz_1_1nodes_1_1io_1_1_output_node" id="r_a2f76355b646a9c9f1a0972ad87f6a260"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnz_1_1nodes_1_1io_1_1_output_node.html#a2f76355b646a9c9f1a0972ad87f6a260">backward</a> () override</td></tr>
<tr class="memdesc:a2f76355b646a9c9f1a0972ad87f6a260 inherit pub_methods_classnz_1_1nodes_1_1io_1_1_output_node"><td class="mdescLeft">&#160;</td><td class="mdescRight">Backward pass for the <code><a class="el" href="classnz_1_1nodes_1_1io_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code>.  <br /></td></tr>
<tr class="separator:a2f76355b646a9c9f1a0972ad87f6a260 inherit pub_methods_classnz_1_1nodes_1_1io_1_1_output_node"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7ac1292b280afcd86b31853b1275c1c4 inherit pub_methods_classnz_1_1nodes_1_1io_1_1_output_node" id="r_a7ac1292b280afcd86b31853b1275c1c4"><td class="memItemLeft" align="right" valign="top">Tensor::value_type&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnz_1_1nodes_1_1io_1_1_output_node.html#a7ac1292b280afcd86b31853b1275c1c4">getLoss</a> () const</td></tr>
<tr class="memdesc:a7ac1292b280afcd86b31853b1275c1c4 inherit pub_methods_classnz_1_1nodes_1_1io_1_1_output_node"><td class="mdescLeft">&#160;</td><td class="mdescRight">Retrieves the loss value stored in the <code><a class="el" href="classnz_1_1nodes_1_1io_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code>.  <br /></td></tr>
<tr class="separator:a7ac1292b280afcd86b31853b1275c1c4 inherit pub_methods_classnz_1_1nodes_1_1io_1_1_output_node"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac340bd5a932808333e08e8bf24d53039 inherit pub_methods_classnz_1_1nodes_1_1io_1_1_output_node" id="r_ac340bd5a932808333e08e8bf24d53039"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnz_1_1nodes_1_1io_1_1_output_node.html#ac340bd5a932808333e08e8bf24d53039">print</a> (std::ostream &amp;os) const override</td></tr>
<tr class="memdesc:ac340bd5a932808333e08e8bf24d53039 inherit pub_methods_classnz_1_1nodes_1_1io_1_1_output_node"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prints the type, data, gradient, and loss of the node.  <br /></td></tr>
<tr class="separator:ac340bd5a932808333e08e8bf24d53039 inherit pub_methods_classnz_1_1nodes_1_1io_1_1_output_node"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classnz_1_1nodes_1_1_node"><td colspan="2" onclick="javascript:dynsection.toggleInherit('pub_methods_classnz_1_1nodes_1_1_node')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classnz_1_1nodes_1_1_node.html">nz::nodes::Node</a></td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Represents the Mean Squared Error (MSE) loss function node in a computational graph. </p>
<p>The <code><a class="el" href="classnz_1_1nodes_1_1loss_1_1_mean_squared_error_node.html" title="Represents the Mean Squared Error (MSE) loss function node in a computational graph.">MeanSquaredErrorNode</a></code> class computes the Mean Squared Error loss between two input tensors. The loss is calculated as the average of the squared differences between the corresponding elements of the two tensors: </p><div class="fragment"><div class="line">MSE(x, y) = 1/n * Î£ (x_i - y_i)^2</div>
</div><!-- fragment --><p> where <code>x</code> and <code>y</code> are the two input tensors, and <code>n</code> is the number of elements in the tensors. This class is typically used for training models, especially in regression tasks.</p>
<p>Key features:</p><ul>
<li><b>Forward Pass</b>: Calculates the Mean Squared Error loss between the two input tensors, storing the result in the output tensor. The MSE loss is computed on a per-element basis and aggregated across the entire tensor.</li>
<li><b>Backward Pass</b>: Computes the gradients of the MSE loss with respect to the input tensors for use in backpropagation. The gradients are propagated only if the output tensor requires gradients.</li>
<li><b>Shape Compatibility</b>: Ensures that both input tensors have the same shape. An exception is thrown if the shapes do not match.</li>
<li><b>Efficient Computation</b>: The forward and backward passes are optimized for parallel execution using CUDA.</li>
</ul>
<p>This class is part of the <code><a class="el" href="namespacenz_1_1nodes.html" title="Contains classes and functionality for nodes in a neural network or computational graph.">nz::nodes</a></code> namespace and is useful in models where Mean Squared Error is the loss function.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The <code><a class="el" href="classnz_1_1nodes_1_1loss_1_1_mean_squared_error_node.html" title="Represents the Mean Squared Error (MSE) loss function node in a computational graph.">MeanSquaredErrorNode</a></code> requires two input nodes, both of which must have tensors of the same shape.</li>
<li>The forward pass performs the MSE calculation on the GPU, while the backward pass computes the gradient of the MSE loss.</li>
<li>The loss is stored in the <code>loss</code> attribute, which is updated during the forward pass.</li>
<li>The gradients are stored in the <code>grad</code> attribute of the input tensors during the backward pass.</li>
</ul>
</dd></dl>
<h3><a class="anchor" id="autotoc_md55"></a>
Usage Example:</h3>
<div class="fragment"><div class="line"><span class="comment">// Example: Using MeanSquaredErrorNode in a computational graph</span></div>
<div class="line">InputNode input1({3, 3}, <span class="keyword">true</span>);  <span class="comment">// Create the first input node with shape {3, 3}</span></div>
<div class="line">InputNode input2({3, 3}, <span class="keyword">true</span>);  <span class="comment">// Create the second input node with shape {3, 3}</span></div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">float</span> data1[] = {1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f, 7.0f, 8.0f, 9.0f};  <span class="comment">// Sample input1 values</span></div>
<div class="line"><span class="keywordtype">float</span> data2[] = {1.5f, 2.5f, 3.5f, 4.5f, 5.5f, 6.5f, 7.5f, 8.5f, 9.5f};  <span class="comment">// Sample input2 values</span></div>
<div class="line">input1.output-&gt;copyData(data1);  <span class="comment">// Copy data to the first input tensor</span></div>
<div class="line">input2.output-&gt;copyData(data2);  <span class="comment">// Copy data to the second input tensor</span></div>
<div class="line"> </div>
<div class="line"><a class="code hl_function" href="#ac9e098d63556329314c7389b779169b6">MeanSquaredErrorNode</a> mse_node(&amp;input1, &amp;input2);  <span class="comment">// Create the Mean Squared Error node</span></div>
<div class="line">mse_node.forward();  <span class="comment">// Perform the forward pass and compute the MSE loss</span></div>
<div class="line">mse_node.backward();  <span class="comment">// Perform the backward pass and compute gradients</span></div>
<div class="line"> </div>
<div class="line">std::cout &lt;&lt; <span class="stringliteral">&quot;MSE Loss: &quot;</span> &lt;&lt; mse_node.getLoss() &lt;&lt; std::endl;  <span class="comment">// Print the computed MSE loss</span></div>
<div class="ttc" id="aclassnz_1_1nodes_1_1loss_1_1_mean_squared_error_node_html_ac9e098d63556329314c7389b779169b6"><div class="ttname"><a href="#ac9e098d63556329314c7389b779169b6">nz::nodes::loss::MeanSquaredErrorNode::MeanSquaredErrorNode</a></div><div class="ttdeci">MeanSquaredErrorNode(Node *input1, Node *input2)</div><div class="ttdoc">Constructor to initialize a MeanSquaredErrorNode for computing the Mean Squared Error (MSE) loss.</div><div class="ttdef"><b>Definition</b> <a href="_nodes_8cu_source.html#l00499">Nodes.cu:499</a></div></div>
</div><!-- fragment --><dl class="section see"><dt>See also</dt><dd><a class="el" href="#ae81d6afb059f76617ea034032c12ec13" title="Computes the forward pass of the Mean Squared Error (MSE) loss function.">forward()</a> for the Mean Squared Error computation in the <a class="el" href="#ae81d6afb059f76617ea034032c12ec13" title="Computes the forward pass of the Mean Squared Error (MSE) loss function.">forward</a> pass. </dd>
<dd>
<a class="el" href="#a8ccbbad9b8bb2111d24af789020337ce" title="Computes the backward pass of the Mean Squared Error (MSE) loss function.">backward()</a> for gradient computation in the <a class="el" href="#a8ccbbad9b8bb2111d24af789020337ce" title="Computes the backward pass of the Mean Squared Error (MSE) loss function.">backward</a> pass.</dd></dl>
<dl class="section author"><dt>Author</dt><dd>Mgepahmge (<a href="https://github.com/Mgepahmge">https://github.com/Mgepahmge</a>)</dd></dl>
<dl class="section date"><dt>Date</dt><dd>2024/12/07 </dd></dl>

<p class="definition">Definition at line <a class="el" href="_nodes_8cuh_source.html#l03201">3201</a> of file <a class="el" href="_nodes_8cuh_source.html">Nodes.cuh</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="ac9e098d63556329314c7389b779169b6" name="ac9e098d63556329314c7389b779169b6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac9e098d63556329314c7389b779169b6">&#9670;&#160;</a></span>MeanSquaredErrorNode()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">nz::nodes::loss::MeanSquaredErrorNode::MeanSquaredErrorNode </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnz_1_1nodes_1_1_node.html">Node</a> *</td>          <td class="paramname"><span class="paramname"><em>input1</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnz_1_1nodes_1_1_node.html">Node</a> *</td>          <td class="paramname"><span class="paramname"><em>input2</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">explicit</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Constructor to initialize a <code><a class="el" href="classnz_1_1nodes_1_1loss_1_1_mean_squared_error_node.html" title="Represents the Mean Squared Error (MSE) loss function node in a computational graph.">MeanSquaredErrorNode</a></code> for computing the Mean Squared Error (MSE) loss. </p>
<p>The constructor initializes a <code><a class="el" href="classnz_1_1nodes_1_1loss_1_1_mean_squared_error_node.html" title="Represents the Mean Squared Error (MSE) loss function node in a computational graph.">MeanSquaredErrorNode</a></code>, which computes the MSE loss between two input nodes. It checks that both input nodes have the same shape and sets up the necessary internal structures for the loss calculation.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input1</td><td>A pointer to the first input node. The <code>output</code> tensor of this node will be used as the predicted values. </td></tr>
    <tr><td class="paramname">input2</td><td>A pointer to the second input node. The <code>output</code> tensor of this node will be used as the ground truth values.</td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>if <code>input1</code> and <code>input2</code> do not have the same shape.</td></tr>
  </table>
  </dd>
</dl>
<ul>
<li>The constructor verifies that the shapes of the two input tensors are the same. If they are not, an exception is thrown.</li>
<li>The second input node (<code>input2</code>) is added to the <code>inputs</code> vector, while the first input node is inherited from the <code>OutputNode</code> base class.</li>
<li>The <code>type</code> attribute is set to <code>"MeanSquaredError"</code>, indicating the type of operation this node represents.</li>
</ul>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The MSE loss is only calculated if the input nodes have matching shapes. If the shapes do not match, an exception will be thrown to ensure consistency.</li>
<li>The constructor initializes the internal state and prepares the node for the forward and backward passes.</li>
</ul>
</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="#ae81d6afb059f76617ea034032c12ec13" title="Computes the forward pass of the Mean Squared Error (MSE) loss function.">forward()</a> for computing the MSE <a class="el" href="namespacenz_1_1nodes_1_1loss.html" title="Contains loss function nodes for computing various loss metrics in a machine learning model.">loss</a> in the <a class="el" href="#ae81d6afb059f76617ea034032c12ec13" title="Computes the forward pass of the Mean Squared Error (MSE) loss function.">forward</a> pass. </dd>
<dd>
<a class="el" href="#a8ccbbad9b8bb2111d24af789020337ce" title="Computes the backward pass of the Mean Squared Error (MSE) loss function.">backward()</a> for computing the gradients in the <a class="el" href="#a8ccbbad9b8bb2111d24af789020337ce" title="Computes the backward pass of the Mean Squared Error (MSE) loss function.">backward</a> pass.</dd></dl>
<dl class="section author"><dt>Author</dt><dd>Mgepahmge (<a href="https://github.com/Mgepahmge">https://github.com/Mgepahmge</a>)</dd></dl>
<dl class="section date"><dt>Date</dt><dd>2024/12/07 </dd></dl>

<p class="definition">Definition at line <a class="el" href="_nodes_8cu_source.html#l00499">499</a> of file <a class="el" href="_nodes_8cu_source.html">Nodes.cu</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a8ccbbad9b8bb2111d24af789020337ce" name="a8ccbbad9b8bb2111d24af789020337ce"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8ccbbad9b8bb2111d24af789020337ce">&#9670;&#160;</a></span>backward()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void nz::nodes::loss::MeanSquaredErrorNode::backward </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes the backward pass of the Mean Squared Error (MSE) loss function. </p>
<p>This method computes the gradients of the MSE loss with respect to the input tensors (<code>inputs[0]</code> and <code>inputs[1]</code>). The gradients are calculated only if the output tensor requires gradients, and they are used for backpropagation in training deep learning models.</p>
<p>The backward pass is performed using a CUDA kernel to efficiently compute the gradients in parallel on the GPU.</p>
<ul>
<li>The method first checks if the output tensor requires gradients by calling <code>requiresGrad()</code> on the output.</li>
<li>If gradients are required, a CUDA kernel (<code>MSEBackward</code>) is launched to compute the gradients of the loss with respect to both input tensors.</li>
<li>The gradients are computed by comparing the predicted values (<code>inputs[0]</code>) and the ground truth values (<code>inputs[1]</code>) in a parallel manner across all elements of the tensors.</li>
<li>The result is stored in the <code>grad</code> attribute of the output tensor.</li>
</ul>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The method assumes that both input tensors have the same shape, as validated during the initialization phase.</li>
<li>The <code>requiresGrad()</code> check ensures that gradients are only computed if necessary, avoiding unnecessary computations.</li>
<li>This method is essential for updating the model's parameters during the training process through backpropagation.</li>
</ul>
</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="#ae81d6afb059f76617ea034032c12ec13" title="Computes the forward pass of the Mean Squared Error (MSE) loss function.">forward()</a> for the <a class="el" href="#ae81d6afb059f76617ea034032c12ec13" title="Computes the forward pass of the Mean Squared Error (MSE) loss function.">forward</a> pass, which computes the MSE <a class="el" href="namespacenz_1_1nodes_1_1loss.html" title="Contains loss function nodes for computing various loss metrics in a machine learning model.">loss</a>.</dd></dl>
<dl class="section author"><dt>Author</dt><dd>Mgepahmge (<a href="https://github.com/Mgepahmge">https://github.com/Mgepahmge</a>)</dd></dl>
<dl class="section date"><dt>Date</dt><dd>2024/12/07 </dd></dl>

<p>Implements <a class="el" href="classnz_1_1nodes_1_1_node.html#a0a9ecbaa3d790ba38e8218aca7837fd0">nz::nodes::Node</a>.</p>

<p class="definition">Definition at line <a class="el" href="_nodes_8cu_source.html#l00526">526</a> of file <a class="el" href="_nodes_8cu_source.html">Nodes.cu</a>.</p>

</div>
</div>
<a id="ae81d6afb059f76617ea034032c12ec13" name="ae81d6afb059f76617ea034032c12ec13"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae81d6afb059f76617ea034032c12ec13">&#9670;&#160;</a></span>forward()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void nz::nodes::loss::MeanSquaredErrorNode::forward </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes the forward pass of the Mean Squared Error (MSE) loss function. </p>
<p>This method calculates the Mean Squared Error (MSE) loss between two input tensors. The loss is computed by comparing the predicted values (<code>inputs[0]</code>) to the ground truth values (<code>inputs[1]</code>) element-wise. The result is accumulated in the <code>loss</code> attribute of the node.</p>
<p>The computation is performed in parallel on the GPU using CUDA kernels for efficiency.</p>
<ul>
<li>The method first calls the <code><a class="el" href="#ae81d6afb059f76617ea034032c12ec13" title="Computes the forward pass of the Mean Squared Error (MSE) loss function.">forward()</a></code> method of the <code>OutputNode</code> base class to handle any initialization and setup required by the base class.</li>
<li>CUDA is used to compute the MSE loss across the entire tensor. A kernel is launched to calculate the squared differences between the elements of the two input tensors.</li>
<li>The results from the GPU computation are copied to the host memory, and the total MSE loss is accumulated.</li>
<li>The final computed loss is stored in the <code>loss</code> attribute.</li>
</ul>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The <code>inputs</code> vector must contain exactly two nodes: the predicted values and the ground truth values. Both tensors must have the same shape, and this is validated during the initialization.</li>
<li>The loss is stored in the <code>loss</code> attribute, which is updated after each forward pass.</li>
</ul>
</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="#a8ccbbad9b8bb2111d24af789020337ce" title="Computes the backward pass of the Mean Squared Error (MSE) loss function.">backward()</a> for the <a class="el" href="#a8ccbbad9b8bb2111d24af789020337ce" title="Computes the backward pass of the Mean Squared Error (MSE) loss function.">backward</a> pass, which computes the gradients of the MSE <a class="el" href="namespacenz_1_1nodes_1_1loss.html" title="Contains loss function nodes for computing various loss metrics in a machine learning model.">loss</a>.</dd></dl>
<dl class="section author"><dt>Author</dt><dd>Mgepahmge (<a href="https://github.com/Mgepahmge">https://github.com/Mgepahmge</a>)</dd></dl>
<dl class="section date"><dt>Date</dt><dd>2024/12/07 </dd></dl>

<p>Implements <a class="el" href="classnz_1_1nodes_1_1_node.html#a8a828c2e91a4aa2a9ab7b94554e4685b">nz::nodes::Node</a>.</p>

<p class="definition">Definition at line <a class="el" href="_nodes_8cu_source.html#l00508">508</a> of file <a class="el" href="_nodes_8cu_source.html">Nodes.cu</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>D:/C Program/Simple-CPP-DL-Framework/include/NeuZephyr/<a class="el" href="_nodes_8cuh_source.html">Nodes.cuh</a></li>
<li>D:/C Program/Simple-CPP-DL-Framework/src/<a class="el" href="_nodes_8cu_source.html">Nodes.cu</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.12.0
</small></address>
</div><!-- doc-content -->
</body>
</html>
