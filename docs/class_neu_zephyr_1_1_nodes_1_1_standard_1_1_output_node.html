<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.12.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NeuZephyr: NeuZephyr::Nodes::Standard::OutputNode Class Reference</title>
<link rel="icon" href="NZ_logo2.png" type="image/x-icon" />
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="NZ_logo2.png"/></td>
  <td id="projectalign">
   <div id="projectname">NeuZephyr
   </div>
   <div id="projectbrief">Simple DL Framework</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.12.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>Class&#160;List</span></a></li>
      <li><a href="classes.html"><span>Class&#160;Index</span></a></li>
      <li><a href="inherits.html"><span>Class&#160;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&#160;Members</span></a></li>
    </ul>
  </div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){ initResizable(false); });
/* @license-end */
</script>
<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>NeuZephyr</b></li><li class="navelem"><a class="el" href="namespace_neu_zephyr_1_1_nodes.html">Nodes</a></li><li class="navelem"><a class="el" href="namespace_neu_zephyr_1_1_nodes_1_1_standard.html">Standard</a></li><li class="navelem"><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html">OutputNode</a></li>  </ul>
</div>
</div><!-- top -->
<div id="doc-content">
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">NeuZephyr::Nodes::Standard::OutputNode Class Reference</div></div>
</div><!--header-->
<div class="contents">

<p>Base class for loss function nodes in a computational graph.  
 <a href="#details">More...</a></p>
<div class="dynheader">
Inheritance diagram for NeuZephyr::Nodes::Standard::OutputNode:</div>
<div class="dyncontent">
<div class="center"><img src="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node__inherit__graph.png" border="0" usemap="#a_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node_inherit__map" alt="Inheritance graph"/></div>
<map name="a_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node_inherit__map" id="a_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node_inherit__map">
<area shape="rect" title="Base class for loss function nodes in a computational graph." alt="" coords="224,39,415,81"/>
<area shape="rect" href="class_neu_zephyr_1_1_nodes_1_1_loss_1_1_binary_cross_entropy_node.html" title="Represents the Binary Cross&#45;Entropy (BCE) loss function node in a computational graph." alt="" coords="463,5,640,48"/>
<area shape="poly" title=" " alt="" coords="430,41,462,37,463,42,431,47"/>
<area shape="rect" href="class_neu_zephyr_1_1_nodes_1_1_loss_1_1_mean_squared_error_node.html" title="Represents the Mean Squared Error (MSE) loss function node in a computational graph." alt="" coords="468,72,636,115"/>
<area shape="poly" title=" " alt="" coords="431,73,468,79,467,84,430,79"/>
<area shape="rect" href="class_neu_zephyr_1_1_nodes_1_1_node.html" title="Base class for nodes in a neural network or computational graph." alt="" coords="5,47,176,73"/>
<area shape="poly" title=" " alt="" coords="191,57,223,57,223,63,191,63"/>
</map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for NeuZephyr::Nodes::Standard::OutputNode:</div>
<div class="dyncontent">
<div class="center"><img src="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node__coll__graph.png" border="0" usemap="#a_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node_coll__map" alt="Collaboration graph"/></div>
<map name="a_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node_coll__map" id="a_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node_coll__map">
<area shape="rect" title="Base class for loss function nodes in a computational graph." alt="" coords="5,80,197,123"/>
<area shape="rect" href="class_neu_zephyr_1_1_nodes_1_1_node.html" title="Base class for nodes in a neural network or computational graph." alt="" coords="16,5,186,32"/>
<area shape="poly" title=" " alt="" coords="104,48,104,80,98,80,98,48"/>
</map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a25cd49675b51fcc993611dd9aec03b4d" id="r_a25cd49675b51fcc993611dd9aec03b4d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a25cd49675b51fcc993611dd9aec03b4d">OutputNode</a> (<a class="el" href="class_neu_zephyr_1_1_nodes_1_1_node.html">Node</a> *input)</td></tr>
<tr class="memdesc:a25cd49675b51fcc993611dd9aec03b4d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor to initialize an <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code> with a given input node.  <br /></td></tr>
<tr class="separator:a25cd49675b51fcc993611dd9aec03b4d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a953ccc48d72a5e23501a6bc265415bad" id="r_a953ccc48d72a5e23501a6bc265415bad"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a953ccc48d72a5e23501a6bc265415bad">forward</a> () override</td></tr>
<tr class="memdesc:a953ccc48d72a5e23501a6bc265415bad"><td class="mdescLeft">&#160;</td><td class="mdescRight">Forward pass for the <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code>.  <br /></td></tr>
<tr class="separator:a953ccc48d72a5e23501a6bc265415bad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2a9f8963286cd2e59fedc2c3e731835a" id="r_a2a9f8963286cd2e59fedc2c3e731835a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a2a9f8963286cd2e59fedc2c3e731835a">backward</a> () override</td></tr>
<tr class="memdesc:a2a9f8963286cd2e59fedc2c3e731835a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Backward pass for the <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code>.  <br /></td></tr>
<tr class="separator:a2a9f8963286cd2e59fedc2c3e731835a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab6ef4ccdda9297210927b2055b5fddfc" id="r_ab6ef4ccdda9297210927b2055b5fddfc"><td class="memItemLeft" align="right" valign="top">Tensor::value_type&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ab6ef4ccdda9297210927b2055b5fddfc">getLoss</a> () const</td></tr>
<tr class="memdesc:ab6ef4ccdda9297210927b2055b5fddfc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Retrieves the loss value stored in the <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code>.  <br /></td></tr>
<tr class="separator:ab6ef4ccdda9297210927b2055b5fddfc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_class_neu_zephyr_1_1_nodes_1_1_node"><td colspan="2" onclick="javascript:dynsection.toggleInherit('pub_methods_class_neu_zephyr_1_1_nodes_1_1_node')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="class_neu_zephyr_1_1_nodes_1_1_node.html">NeuZephyr::Nodes::Node</a></td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Base class for loss function nodes in a computational graph. </p>
<p>The <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code> class serves as the base class for all nodes representing loss functions in a neural network. It connects to the output of a node that produces the final result, and it computes the loss based on that result. During the forward pass, it simply copies the output of the input node, and during the backward pass, it sets the gradient of the output tensor to 1, effectively marking the end of the gradient flow.</p>
<p>The <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code> class is used as a parent class for more specific loss function nodes (such as Mean Squared Error or Cross-Entropy loss), which can further extend its functionality to compute the actual loss and update the <code>loss</code> member.</p>
<p>Key features:</p><ul>
<li><b><a class="el" href="namespace_neu_zephyr_1_1_nodes_1_1_loss.html" title="Contains loss function nodes for computing various loss metrics in a machine learning model.">Loss</a> Calculation</b>: The <code>loss</code> member variable holds the value of the computed loss. Specific loss functions can update this value by extending the <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code> class.</li>
<li><b>Forward Pass</b>: The <code><a class="el" href="#a953ccc48d72a5e23501a6bc265415bad" title="Forward pass for the OutputNode.">forward()</a></code> method simply sets the <code>output</code> member to the output of the input node.</li>
<li><b>Backward Pass</b>: The <code><a class="el" href="#a2a9f8963286cd2e59fedc2c3e731835a" title="Backward pass for the OutputNode.">backward()</a></code> method sets the gradient of the output tensor to 1, which marks the start of gradient propagation for the backward pass.</li>
<li><b><a class="el" href="namespace_neu_zephyr_1_1_nodes_1_1_loss.html" title="Contains loss function nodes for computing various loss metrics in a machine learning model.">Loss</a> Access</b>: The <code><a class="el" href="#ab6ef4ccdda9297210927b2055b5fddfc" title="Retrieves the loss value stored in the OutputNode.">getLoss()</a></code> method provides access to the loss value stored in the <code>loss</code> member.</li>
</ul>
<p>This class is part of the <code><a class="el" href="namespace_neu_zephyr_1_1_nodes.html" title="Contains classes and functionality for nodes in a neural network or computational graph.">NeuZephyr::Nodes</a></code> namespace, and it is designed to be extended for implementing various loss functions.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code> class does not perform any specific loss computation. It is intended to be a base class for more specific loss function nodes that compute and track the actual loss.</li>
<li>The backward pass simply sets the gradient to 1, which is appropriate for the output layer of a neural network where the loss gradient is propagated back.</li>
</ul>
</dd></dl>
<h3><a class="anchor" id="autotoc_md38"></a>
Usage Example:</h3>
<div class="fragment"><div class="line"><a class="code hl_class" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_input_node.html">InputNode</a> input({3, 3}, <span class="keyword">true</span>);  <span class="comment">// Create an input node with shape {3, 3} and requires gradients</span></div>
<div class="line">input.output-&gt;fill(1.0f);  <span class="comment">// Fill the input tensor with 1.0</span></div>
<div class="line"> </div>
<div class="line"><a class="code hl_class" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html">OutputNode</a> output(&amp;input);  <span class="comment">// Create an OutputNode and pass the input node as the source</span></div>
<div class="line">output.forward();  <span class="comment">// Forward pass: output now points to the input node&#39;s output</span></div>
<div class="line">output.backward();  <span class="comment">// Backward pass: set the gradient of the input node&#39;s output to 1</span></div>
<div class="line"> </div>
<div class="line">std::cout &lt;&lt; <span class="stringliteral">&quot;Loss: &quot;</span> &lt;&lt; output.getLoss() &lt;&lt; std::endl;  <span class="comment">// Access the loss value (which is 0 initially)</span></div>
<div class="ttc" id="aclass_neu_zephyr_1_1_nodes_1_1_standard_1_1_input_node_html"><div class="ttname"><a href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_input_node.html">NeuZephyr::Nodes::Standard::InputNode</a></div><div class="ttdoc">Represents an input node in a computational graph.</div><div class="ttdef"><b>Definition</b> <a href="_nodes_8cuh_source.html#l00260">Nodes.cuh:260</a></div></div>
<div class="ttc" id="aclass_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node_html"><div class="ttname"><a href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html">NeuZephyr::Nodes::Standard::OutputNode</a></div><div class="ttdoc">Base class for loss function nodes in a computational graph.</div><div class="ttdef"><b>Definition</b> <a href="_nodes_8cuh_source.html#l00447">Nodes.cuh:447</a></div></div>
</div><!-- fragment --><dl class="section see"><dt>See also</dt><dd><a class="el" href="#a953ccc48d72a5e23501a6bc265415bad" title="Forward pass for the OutputNode.">forward()</a> for the <a class="el" href="#a953ccc48d72a5e23501a6bc265415bad" title="Forward pass for the OutputNode.">forward</a> pass computation method. </dd>
<dd>
<a class="el" href="#a2a9f8963286cd2e59fedc2c3e731835a" title="Backward pass for the OutputNode.">backward()</a> for the <a class="el" href="#a2a9f8963286cd2e59fedc2c3e731835a" title="Backward pass for the OutputNode.">backward</a> pass gradient propagation method.</dd></dl>
<dl class="section author"><dt>Author</dt><dd>Mgepahmge (<a href="https://github.com/Mgepahmge">https://github.com/Mgepahmge</a>)</dd></dl>
<dl class="section date"><dt>Date</dt><dd>2024/11/29 </dd></dl>

<p class="definition">Definition at line <a class="el" href="_nodes_8cuh_source.html#l00447">447</a> of file <a class="el" href="_nodes_8cuh_source.html">Nodes.cuh</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a25cd49675b51fcc993611dd9aec03b4d" name="a25cd49675b51fcc993611dd9aec03b4d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a25cd49675b51fcc993611dd9aec03b4d">&#9670;&#160;</a></span>OutputNode()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">NeuZephyr::Nodes::Standard::OutputNode::OutputNode </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_node.html">Node</a> *</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">explicit</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Constructor to initialize an <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code> with a given input node. </p>
<p>This constructor initializes an <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code> by accepting an input node. The <code>output</code> of this node will be set to the <code>output</code> of the provided input node during the forward pass. The <code>loss</code> is initialized to <code>0</code>, and the <code>type</code> is set to <code>"Output"</code>.</p>
<p>The <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code> class is designed to represent the output layer of a neural network, and it serves as the base class for loss function nodes. The <code><a class="el" href="#a953ccc48d72a5e23501a6bc265415bad" title="Forward pass for the OutputNode.">forward()</a></code> and <code><a class="el" href="#a2a9f8963286cd2e59fedc2c3e731835a" title="Backward pass for the OutputNode.">backward()</a></code> methods will be responsible for propagating data and gradients, respectively.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A pointer to the <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_node.html" title="Base class for nodes in a neural network or computational graph.">Node</a></code> that serves as the input to the <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code>. The <code>output</code> of this node will be used as the <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code>'s output.</td></tr>
  </table>
  </dd>
</dl>
<p>This constructor sets up the node with a reference to its input, allowing the <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code> to pass data from its input node and compute the loss during the forward and backward passes.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_input_node.html" title="Represents an input node in a computational graph.">InputNode</a></code> or any other node that provides the final output of the network can be passed to this constructor.</li>
<li>The <code>loss</code> member is initialized to <code>0</code> and can be updated by specific loss function implementations in derived classes.</li>
</ul>
</dd></dl>
<dl class="section author"><dt>Author</dt><dd>Mgepahmge (<a href="https://github.com/Mgepahmge">https://github.com/Mgepahmge</a>)</dd></dl>
<dl class="section date"><dt>Date</dt><dd>2024/11/29 </dd></dl>

<p class="definition">Definition at line <a class="el" href="_nodes_8cu_source.html#l00030">30</a> of file <a class="el" href="_nodes_8cu_source.html">Nodes.cu</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a2a9f8963286cd2e59fedc2c3e731835a" name="a2a9f8963286cd2e59fedc2c3e731835a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2a9f8963286cd2e59fedc2c3e731835a">&#9670;&#160;</a></span>backward()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void NeuZephyr::Nodes::Standard::OutputNode::backward </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Backward pass for the <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code>. </p>
<p>The <code><a class="el" href="#a2a9f8963286cd2e59fedc2c3e731835a" title="Backward pass for the OutputNode.">backward()</a></code> method for the <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code> sets the gradient of the output tensor to 1. If the input tensor of the <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code> requires gradients (i.e., it is part of the model parameters), the gradient of the input tensor is set to 1. This is a standard operation in the backward pass for the output layer, as it marks the start of the gradient propagation in the network.</p>
<p>This method does not perform any gradient calculations for the output node itself. Instead, it ensures that the gradient of the input node’s output is set to 1, which is necessary for the backpropagation process in the neural network.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The <code><a class="el" href="#a2a9f8963286cd2e59fedc2c3e731835a" title="Backward pass for the OutputNode.">backward()</a></code> method simply fills the gradient of the input tensor with 1. This is because the <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code> represents the output layer, where the gradient is typically set to 1 as the starting point of backpropagation.</li>
<li>This method ensures that the gradient for the input node’s <code>output</code> is available for further propagation through the network during the backward pass.</li>
</ul>
</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="#a953ccc48d72a5e23501a6bc265415bad" title="Forward pass for the OutputNode.">forward()</a> for the <a class="el" href="#a953ccc48d72a5e23501a6bc265415bad" title="Forward pass for the OutputNode.">forward</a> pass computation method.</dd></dl>
<dl class="section author"><dt>Author</dt><dd>Mgepahmge (<a href="https://github.com/Mgepahmge">https://github.com/Mgepahmge</a>)</dd></dl>
<dl class="section date"><dt>Date</dt><dd>2024/11/29 </dd></dl>

<p>Implements <a class="el" href="class_neu_zephyr_1_1_nodes_1_1_node.html#a41914155871c84330701f9d1649b39f3">NeuZephyr::Nodes::Node</a>.</p>

<p class="definition">Definition at line <a class="el" href="_nodes_8cu_source.html#l00040">40</a> of file <a class="el" href="_nodes_8cu_source.html">Nodes.cu</a>.</p>

</div>
</div>
<a id="a953ccc48d72a5e23501a6bc265415bad" name="a953ccc48d72a5e23501a6bc265415bad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a953ccc48d72a5e23501a6bc265415bad">&#9670;&#160;</a></span>forward()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void NeuZephyr::Nodes::Standard::OutputNode::forward </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Forward pass for the <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code>. </p>
<p>The <code><a class="el" href="#a953ccc48d72a5e23501a6bc265415bad" title="Forward pass for the OutputNode.">forward()</a></code> method for the <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code> sets the <code>output</code> member of the node to be the same as the <code>output</code> of its input node. This effectively passes the output from the input node to the <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code> without any modification. Since the <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code> does not perform any computation itself, it simply relays the input node's output during the forward pass, making it equivalent to its input node's output.</p>
<p>This method is typically used in the context of a neural network, where the <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code> represents the final layer, and it connects the output of the network to the loss function for loss computation and backpropagation.</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The <code><a class="el" href="#a953ccc48d72a5e23501a6bc265415bad" title="Forward pass for the OutputNode.">forward()</a></code> method does not alter the data from the input node; it merely sets the <code>output</code> of the <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code> to be the same as the input node's <code>output</code>.</li>
<li>This method is implemented as part of the <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code> class to conform to the interface defined by its base class <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_node.html" title="Base class for nodes in a neural network or computational graph.">Node</a></code>.</li>
</ul>
</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="#a2a9f8963286cd2e59fedc2c3e731835a" title="Backward pass for the OutputNode.">backward()</a> for the <a class="el" href="#a2a9f8963286cd2e59fedc2c3e731835a" title="Backward pass for the OutputNode.">backward</a> pass gradient propagation method.</dd></dl>
<dl class="section author"><dt>Author</dt><dd>Mgepahmge (<a href="https://github.com/Mgepahmge">https://github.com/Mgepahmge</a>)</dd></dl>
<dl class="section date"><dt>Date</dt><dd>2024/11/29 </dd></dl>

<p>Implements <a class="el" href="class_neu_zephyr_1_1_nodes_1_1_node.html#a64e42ba40199e35bfe453ef14b2d15c0">NeuZephyr::Nodes::Node</a>.</p>

<p class="definition">Definition at line <a class="el" href="_nodes_8cu_source.html#l00036">36</a> of file <a class="el" href="_nodes_8cu_source.html">Nodes.cu</a>.</p>

</div>
</div>
<a id="ab6ef4ccdda9297210927b2055b5fddfc" name="ab6ef4ccdda9297210927b2055b5fddfc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab6ef4ccdda9297210927b2055b5fddfc">&#9670;&#160;</a></span>getLoss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Tensor::value_type NeuZephyr::Nodes::Standard::OutputNode::getLoss </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Retrieves the loss value stored in the <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code>. </p>
<p>The <code><a class="el" href="#ab6ef4ccdda9297210927b2055b5fddfc" title="Retrieves the loss value stored in the OutputNode.">getLoss()</a></code> method returns the value of the loss that is stored in the <code>loss</code> member of the <code><a class="el" href="class_neu_zephyr_1_1_nodes_1_1_standard_1_1_output_node.html" title="Base class for loss function nodes in a computational graph.">OutputNode</a></code>. This value is typically updated by a derived class (e.g., a specific loss function class like Mean Squared Error or Cross-Entropy <a class="el" href="namespace_neu_zephyr_1_1_nodes_1_1_loss.html" title="Contains loss function nodes for computing various loss metrics in a machine learning model.">Loss</a>) during the forward pass. The <code>loss</code> represents the discrepancy between the predicted output and the actual target output in the context of a neural network.</p>
<p>The <code><a class="el" href="#ab6ef4ccdda9297210927b2055b5fddfc" title="Retrieves the loss value stored in the OutputNode.">getLoss()</a></code> function provides access to the computed loss value, which is essential for monitoring the network’s performance during training and optimization.</p>
<dl class="section return"><dt>Returns</dt><dd>The current loss value stored in the <code>loss</code> member, which is of type <code>Tensor::value_type</code>.</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>This method does not modify the loss value; it simply returns the current stored loss value.</li>
<li>The actual loss computation happens in the derived class, such as <code>MeanSquaredErrorNode</code> or <code>BinaryCrossEntropyNode</code>.</li>
</ul>
</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="#a953ccc48d72a5e23501a6bc265415bad" title="Forward pass for the OutputNode.">forward()</a> for the <a class="el" href="#a953ccc48d72a5e23501a6bc265415bad" title="Forward pass for the OutputNode.">forward</a> pass computation method where the loss might be updated.</dd></dl>
<dl class="section author"><dt>Author</dt><dd>Mgepahmge (<a href="https://github.com/Mgepahmge">https://github.com/Mgepahmge</a>)</dd></dl>
<dl class="section date"><dt>Date</dt><dd>2024/11/29 </dd></dl>

<p class="definition">Definition at line <a class="el" href="_nodes_8cu_source.html#l00046">46</a> of file <a class="el" href="_nodes_8cu_source.html">Nodes.cu</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>D:/C Program/Simple-CPP-DL-Framework/include/NeuZephyr/<a class="el" href="_nodes_8cuh_source.html">Nodes.cuh</a></li>
<li>D:/C Program/Simple-CPP-DL-Framework/src/<a class="el" href="_nodes_8cu_source.html">Nodes.cu</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.12.0
</small></address>
</div><!-- doc-content -->
</body>
</html>
